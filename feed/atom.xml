<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Julien Pauli PHP&#039;s life</title>
    <subtitle></subtitle>
    <link href="http://jpauli.github.io//feed/index.atom" rel="self" />
    <link href="http://jpauli.github.io//" />
        <id>http://jpauli.github.io//</id>
            <updated>2017-01-12T00:00:00+00:00</updated>
            <entry>
        <title>Threads and PHP</title>
                <id>http://jpauli.github.io//2017/01/12/threads-and-php.html</id>
                <updated>2017-01-12T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2017/01/12/threads-and-php.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>PHP and threads. Just this 3-word sentence, and we could write a book. As usual, we won't, but give informations and details to some degree about the subject</p>
<p>Let's start by some confusion many people fall in when it comes to such a subject. PHP is not a threaded language. PHP doesn't use threads itself into its heart, and PHP does not natively allow userland code to use threads as parallel mechanism, in any way.</p>
<p>So PHP is very far from other technologies, such as Java (for exemple). In Java, both the language itself is heavily threaded, and it also allows its users to make use of threads into their own programs. Not PHP. And this is for some reasons.</p>
<p>PHP's heart is not threaded, mainly for simplicity. When you'll read next chapter, you'll learn that threads is not "a magical technology that allows any program to run faster". Seems like a sales speech isn't it ? We are not sales, but technical , and so we know what we talk about. So PHP's engine does not use threads at the moment. It could in the future, but using threads introduce many many new difficulties in programming, for a result that could not be what you expect. The main difficulty is cross platform thread programming. The second one is shared resources and lock management, and the third one is that not every program can be turned to thread programming.
PHP's design was born mainly around year 2000, at this time, thread programming was not that spreaded and mature, and engineers behind PHP (mainly Zend) decided to create a full monolithic engine with no threads (also they did not have the resource to ship a stable crossplatform threaded engine).</p>
<p>Second point is that PHP userland code can't use threads, because it is not how PHP expects your code to run. PHP is a fire-and-forget language, you should treat your request as fast as possible, and release PHP so that it can treat the next-to-come request. PHP has been designed as a glue language : you don't compute complex tasks that could require the usage of threads, but instead you access fast-and-ready resources, glue all together, and send that back to the user. With PHP you do things, and whatever could take "more time than usual" should not be done in PHP. That's why we use "Queue based" system to async some heavy tasks in PHP (Gearman, AMQP, ActiveMQ etc...). Unix way of seeing things : "develop small self-contained tools and link them together". So PHP is not designed to allow massive parallelism but other specialized technologies are - use the right tool for the right problem.</p>
<h2 id="some-quick-words-on-threads">Some quick words on Threads<a href="#some-quick-words-on-threads" class="anchor">#</a></h2>
<p>Let's quickly remind souls about threads. Remember that we won't detail many things, and that you may find <a href="https://www.amazon.fr/Threads-Primer-Guide-Multithreaded-Programming/dp/0134436989">in books</a> or <a href="https://computing.llnl.gov/tutorials/pthreads/">on the Web</a> everything you ever wanted to know about threads, in deep.</p>
<p>Threads are light unit of work treatment that reside into processes. Note the ownership : a process can spawn threads, and a thread must be part of one process (and just one). Process is the base unit of work under an Operating System (OS). Processes are heavy units of work treatment. On multi-CPU machines (nowadays' machines), several CPUs will run in parallel and will compute some load o behalf of running tasks. If two processes A and B are ready to be scheduled, and two CPUs (or two CPU cores) are ready to take some load, then A and B should get scheduled in the same time. The machine will then effectively compute several things in one solo unique unit of time (time frame), we call that "parallelism".</p>
<p>A process :</p>
<p><img src="../../../img/threads-and-php/process_structure.png" alt="process_structure"></p>
<p>A thread : </p>
<p><img src="../../../img/threads-and-php/thread_structure.png" alt="thread_structure"></p>
<p>All together :</p>
<p><img src="../../../img/threads-and-php/process_thread.gif" alt="process_and_thread"></p>
<p>A and B previously were processes : full independant workloads. Threads are not processes. Threads are unit of executions that live into a process. That is, a process can decide to cut its job into several more little tasks, that could run concurrently. For example, process A and B could each spawn threads, A1, A2 and B1, B2. If the machine hosts several CPUs (8 CPUs for example), then A1, A2, B1 and B2 could be run in the same timeframe.</p>
<blockquote>
<p>Using threads, a programmer can decide to cut his process job into several more little tasks, that could run concurrently.</p>
</blockquote>
<p>Threads, are a way to cut a process job into several small jobs, that could be run in parallel (in the same timeframe). Threads are run barely the same way processes are : they own a state that the Kernel thread scheduler will use to manage them.</p>
<p><img src="../../../img/threads-and-php/threads_lifetime.gif" alt="threads_lifetime"></p>
<p>Threads are lighter than processes, they only need a stack and some registers, whereas a process needs many more things (a new VM frame from the kernel, a heap, some signal informations, some file descriptor informations, some locks informations etc...).</p>
<p>Processes memory is hardware managed by the Kernel and the MMU, whereas thread memory is software managed by the programmer and the threading library used.</p>
<blockquote>
<p>What you can memorize is that threads are lighter than processes and more easily manageable. If well used, they'll run faster than processes, as the OS Kernel is very less involved in thread management and scheduling that it would be with processes.</p>
</blockquote>
<h3 id="threads-memory-layout">Threads memory layout<a href="#threads-memory-layout" class="anchor">#</a></h3>
<p>As we've seen, threads have their own stack, that is when they access variables declared into a function, they own their own copy of such data.</p>
<p>But we can't say the same about the process heap : that latter is shared accross threads, so are global variables and file descriptors. This is an advantage, or a drawback. If you only read from global memory, you need to read at the right moment (after thread X and before thread Y for example). If you happen to write to it, you then need to make sure several threads don't try to write to the same memory area at the same time : they would corrupt that area and leave the memory in an unpredictable state; what we call a <strong>race condition</strong>. This is the main challenge behind thread programming.</p>
<p>For those concurrent access to happen, you need to incorporate into your code some programming technics such as reentrancy or synchronization routines.
Reentrancy prevents concurrency, whereas synchronization masters concurrency in a predictable way.</p>
<blockquote>
<p>Processes don't share any memory between them, the OS perfectly isolate them. Threads, however, share a <em>big amount</em> of the same process memory.</p>
</blockquote>
<p>Having a big part of the memory shared, there is a need to synchronize common memory access, technical tools are used such as semaphores or mutexes (the most common ones). Those are based on a "lock" concept, that is if the resource is locked and a thread tries to access it, it will (by default) block, waiting for the shared resource to be available.
And this is why using threads doesn't automatically mean your program will run faster. If you don't divide the tasks efficiently, and if you don't manage the shared memory locking efficiently, you'll end up having a program that takes more time to run than it would in one solo process with no threads : just because your threads keep waiting for each other (and I don't talk about dead locks, starvation, etc...).</p>
<p><strong>Thread programming is trully complex if you are not used to it</strong>. You'll need many many hours of practice, and tons of WTF moments to gain experience to work with threads.
Should you forget one little detail and your whole program will blow up at your face. Debugging threads is harder than debugging a thread-free program, as we are talking about real use cases of hundreds or thousands of threads running into a process. You get lost into your mind, and you quickly sink deep in the pool.</p>
<blockquote>
<p>Thread programming is hard. Good thread programming, and good program parallel computing is really a challenge that takes many time to master.</p>
</blockquote>
<p>As sharing memory that way is not always what we want, Thread Local Storage (TLS) appeared. TLS is mainly a concept of "globals owned by one thread and not shareable to others", those are memory areas that represent global state, but private to each thread (like in a process-only way).
To implement TLS, on thread creation, one must allocate some process heap memory, ask the thread library for a key and associate that key to that storage. Every further access will use the key to unlock the thread-specific storage. A destructor is needed at the end of thread life to destroy allocated resources (traditional heap usage here).</p>
<blockquote>
<p>An application is said "thread safe", when it fully masters every global resource access in a 100% predictable way. If not : you get bitten by the scheduler : random things start to happen and the game is over.</p>
</blockquote>
<h3 id="thread-libraries">Thread libraries<a href="#thread-libraries" class="anchor">#</a></h3>
<p>As you may have guessed, threads require some OS Kernel help. Threads have appeared in OS back in mid nineties, so that's quite a long time ago : they are mature and managed by OS Kernels since a long time.</p>
<p>But there still exists some crossplatform issues. Especially Windows against Unix worlds. Both have adopted different threading models, and different thread libraries.</p>
<blockquote>
<p>Programming with threads and supporting crossplatform is still a challenge as of nowadays.</p>
</blockquote>
<p>Under Linux, to create both a thread or a process, the Kernel system call is <code>clone()</code>. But that system call is extremely complex, thus as usual some C code have emerged around the syscalls to ease day to day programming using threads. Thread operations are not yet managed by the libc (C11 standard has started such a move), but by external libraries. Nowadays, under Unix flavors, <strong>pthread</strong> is used (though other libraries exist). Pthread stands for "Posix threads", which is a POSIX normalization of thread usage and behavior dating back from 1995. Hence, if you want to use threads in your program, you'll need to link it with libpthread, aka pass the <em>-lpthread</em> switch to GCC. Also, libpthread is a library. It is written in C, <a href="http://git.savannah.gnu.org/cgit/hurd/libpthread.git/tree/">open source</a>, and have its own version control and management.</p>
<p>So nowadays we mainly use the <strong>pthread</strong> library to program threads under Unix flavors. Not going into details again, pthread allows concurrency but parallelism is dependant on the OS and the machine.</p>
<p>Concurrency is multiple threads running on the same CPU out of order. Parallelism is multiple threads running at the same time on different CPUs.</p>
<p>Here is some concurrency :</p>
<p><img src="../../../img/threads-and-php/threads_concurrency.png" alt="threads_concurrency"></p>
<p>Here is some parallelism :</p>
<p><img src="../../../img/threads-and-php/threads_parallelism.png" alt="threads_parallelism"></p>
<h2 id="php-and-threads">PHP and Threads<a href="#php-and-threads" class="anchor">#</a></h2>
<p>What happens to PHP in there ?. Let's start by reminders :</p>
<ul><li>PHP is not a threaded language : its engine and its code don't manage threads to parallelize its own internal work.</li>
<li>PHP doesn't offer threads to users : You can't use threads with the PHP language natively. <a href="https://github.com/krakjoe">Joe Watkins</a>, PHP Core developper, created a nice library that adds threads to userland : <a href="http://pthreads.org/">ext/pthread</a>. It is a nice project, but I personnaly wouldn't use PHP for such tasks : it's not the right language for that, I'll go with C or Java for example.</li>
</ul><p>So, what about threads and PHP, what's the point ?</p>
<h3 id="how-php-treats-requests">How PHP treats requests<a href="#how-php-treats-requests" class="anchor">#</a></h3>
<p>It is all about how PHP will handle HTTP requests. To serve several clients at the same time, a webserver needs some concurrency (or some parallelism). You can't pause everyone as you are answering to just one client right ?</p>
<p>Thus, what servers usually do is they use multiple processes, or multiple threads , to answer clients.</p>
<p>Historically, under Unix, the process model is used. Simply because processes is the basic of Unix, once Unix was born, processes was born with the ability to create new ones (<code>fork()</code>), destroy them (<code>exit()</code>) and synchronize them (<code>wait()</code>, <code>waitpid()</code>). In such environnements, multiple PHP will serve multiple requests for clients, but <strong>each one will be in its own process</strong>.</p>
<p>If you remember the introduction chapters, in such a case, there is nothing to do into PHP code : processes are fully isolated between them, and process A treating request A about client data A will not be able to communicate (read or write) with process B treating request B about client B. And this is what we want.</p>
<p>Such models include <em>php-fpm</em>, and <em>Apache with mpm_prefork</em>. Usually in 98% of cases you use one of theses two architectures.</p>
<p>Things get more complicated under Windows, or under Unixes where your server uses threads.</p>
<p>Windows is a great operating system (true). It has just one drawback : its source code is closed. But many technical resources about its internal engine can be found on the Web or <a href="https://www.amazon.com/Windows-Internals-Part-Developer-Reference/dp/0735648735">into books</a>. Microsoft engineers <a href="https://technet.microsoft.com/en-us/">share many knowledge</a> about how Windows works into its heart.</p>
<p>Microsoft Windows has taken a different path from Unixes when it comes to concurrency or parallelism. Windows heavily relies on threads. In fact, creating a process in Windows is such an overkill heavy task that you usually don't do it. Under Windows you use threads, everywhere, everytime. Windows threads are order of magnitude more powerful that Linux ones ; yes they are.</p>
<p>So when you run PHP under Windows, the webserver (whatever it is, IIS , Apache, FooBarBaz) <strong>will treat different clients into threads, and not into processes.</strong>
That means that in such an environment, PHP will run into a thread ; and in that case; PHP must be extra carefull about thread specifications : <strong>it must be thread safe</strong>.</p>
<p>PHP must be thread safe, that is it must master the concurrency it hasn't itself created, but leaves in/with. As you may have guessed, that means PHP will have to find a way to protect its access to its own global variables ; and there are many of them into PHP's heart.</p>
<p>The layer that is responsible of such a protection is called <strong>Zend Thread Safety</strong>, aka ZTS.</p>
<p>Please, note that the same is true under Unix if you happen to use threads as the way of parallelize client request treatments, but that is a very uncommon situation as under Unix we are usually used to using classical processes for such a task, though using thread is still possible and may be an advantage in term of performances. Traditionaly a system can run many more threads that it could with processes : threads are lighter.
Also, if you happen to use a PHP extension that requires thread safety to be activated - such as ext/pthread - you will need a thread safe PHP.</p>
<h2 id="zend-thread-safety-internal-details">Zend Thread Safety internal details<a href="#zend-thread-safety-internal-details" class="anchor">#</a></h2>
<p>Ok here we go. ZTS is activated using the <em>--enable-maintainer-zts</em> switch. As said before, you usually don't need this switch, until you run PHP under Windows, or you run PHP with an extension that needs the engine to be thread safe (like ext/pthread for example).</p>
<p>To check against ZTS, you have several ways to achieve that. Use CLI and <code>php -v</code>, which tells you NTS (Not Thread Safe) or ZTS (Zend Thread Safe).</p>
<p><img src="../../../img/threads-and-php/php_cli.png" alt="zts_cli"></p>
<p>You can also ask <code>phpinfo()</code> :</p>
<p><img src="../../../img/threads-and-php/phpinfo_zts.png" alt="phpinfo_zts"></p>
<p>In your code, you can read the <code>PHP_ZTS</code> constant value from PHP.</p>
<pre><code>if (PHP_ZTS) {
    echo "You are running a thread safe version of the PHP engine";
}</code></pre>
<p>All PHP's heart is thread safe when compiled with ZTS. What could not be thread safe are extensions you activated. Official PHP extensions (distributed with PHP) are all thread safe, but for other third-party ones, who knows ? You will see in a few moment that mastering thread safety from PHP extensions needs some special programming API usage, and as always with threads : one miss and you risk to have your <strong>whole server</strong> blow at your face.</p>
<p>Remember that with threads, if you dont call reentrant functions (many from libc) or if you access a true global variable blindly, you are going to generate some weird behaviors <strong>in all the sibling threads</strong>. Translated to the PHP use-case : if you mess-up with threads in one of your extension, you are going to impact every client occupied in every other thread of the webserver! This is absolutely dramatic situation, as one client could corrupt every other clients data.</p>
<p>When designing PHP extensions, ultra care and very good knowledge of thread programming are necessary. If not, when running in a thread environment, you're gonna break the whole webserver in a very nasty random way that you won't be able to debug in reasonnable time.</p>
<blockquote>
<p>When designing PHP extensions, if you mess-up with threads, you are going to impact every client occupied in every other thread of the webserver. You could even not notice that, as bad thread programming usually leads to horrible random behaviors you can't reproduce easilly.</p>
</blockquote>
<h3 id="use-and-design-reentrant-functions">Use and design reentrant functions<a href="#use-and-design-reentrant-functions" class="anchor">#</a></h3>
<p>When designing a PHP extension, use <a href="https://en.wikipedia.org/wiki/Reentrancy_(computing)">reentrant functions</a>. Reentrant functions are functions that don't rely on any global state to work. This is simplified, the true definition is that reentrant functions are functions that can be called as they've not finished to be called yet. Think about functions that can be run in parallel in two or more threads. It then becomes obvious that if such functions use global state, they are not reentrant (but they could lock their global state, and thus be thread-safe either ;-)).
Many libc traditional functions are not reentrant, because they've been designed in a time where threads simply did not exist yet. So some libc (especially glibc) publish reentrant equivalent functions as functions suffixed by <code>_r()</code>. Also, the new C11 standard gives a big room to threads, and C11 libcs benefit from a rewrite with an s suffix : <code>_s()</code>  (<code>localtime_s()</code> for example).</p>
<p>Aka, <code>strtok()</code> => <code>strtok_r()</code>; <code>strerror()</code>, <code>strerror_r()</code>; <code>readdir()</code> => <code>readdir_r()</code>; or <code>gethostbyname()</code> => <code>gethostbyname_r()</code> etc...</p>
<p>PHP itself provides some of them mainly for crossplatforms purpose. <a href="https://github.com/php/php-src/blob/PHP-7.1/main/reentrancy.c">Have a look at main/reentrancy.c</a>.</p>
<p>Also, if you happen to write your own C functions, think about reentrancy. If you can pass your function everything it needs as arguments (on the stack or through registers so), and if that function doesn't use any global/static variables and any non-reentrant function; it is then reentrant.</p>
<h3 id="don-t-link-against-non-thread-safe-libraries">Don't link against non-thread safe libraries<a href="#don-t-link-against-non-thread-safe-libraries" class="anchor">#</a></h3>
<p>Still obvious, remember that thread programming is about the whole process memory image being shared, and the whole process memory image includes any linked libraries.</p>
<p>If your extension links against a known-to-not-be-thread-safe library, then you will have to develop you own thread safety tricks to protect access to global state into such a library. Something really common in C and thread programing, but that is easy to miss.</p>
<h3 id="zts-usage-and-details">ZTS usage and details<a href="#zts-usage-and-details" class="anchor">#</a></h3>
<p>ZTS is Zend Thread Safety. This is a layer of code that controls access to Thread global variables, using TLS as of PHP 7 (Thread Local Storage).</p>
<p>When we develop the PHP language, or as a PHP extension writer, we must differentiate between two kinds of globals in code.</p>
<p>We have <em>true globals</em>, those are plain traditionnal C global variables. As we have seen, such variables are not bad in design, but as we did not protect them against concurrency in threads, we are only allowed to read them when PHP is treating a request.
The case is that those variables (we call them "true globals") are created and written to <strong>before</strong> any thread is created yet. That step is called the <em>module init</em> step in PHP internal vocabulary , and we can clearly see it in PHP extensions, as they are hooked about it :</p>
<pre><code>static int val; /* true global */

PHP_MINIT(wow_ext) /* PHP Module initialization */
{
    if (something()) {
        val = 3; /* writing to a true global */
    }
}</code></pre>
<p>The above pseudo-code details what every PHP extension could look like. Extensions owns several hooks that get triggered throught PHP's life, the so-called MINIT() hook is about PHP initialization. During such a step, PHP is starting, and one can then write or read to a global variable safely, like its done in the example.</p>
<p>Then come the second important hook, RINIT(), or request initialization. This step is called on every extension for every new request to deal with. That is, RINIT() may be called thousands of times in an extension.</p>
<p>At this step, <strong>PHP already leaves in a thread</strong>. The webserver will have threaded the initial process, so in RINIT(), you <strong>must be thread safe</strong>.
As threads are created to handle several requests at the same time, this is perfectly logical. What one should keep in mind, is that <strong>you don't create the thread</strong>. PHP doesn't thread itself, never. This is the webserver that does it.</p>
<p>We use so called <em>globals</em>, or <em>thread globals</em>. Those are global variables, but that are thread protected by the ZTS layer. Like this :</p>
<pre><code>PHP_RINIT(wow_ext) /* PHP Request initialization */
{
    if (something()) {
        WOW_G(val) = 3; /* writing to a thread global */
    }
}</code></pre>
<p>To access thread globals, we used a macro, <code>WOW_G()</code> here. We will now detail what happens behind the scene of this macro.</p>
<h2 id="the-need-of-macros">The need of macros<a href="#the-need-of-macros" class="anchor">#</a></h2>
<p>Remember. When PHP is threaded, all the request-related global state must be protected in access. But when PHP is not threaded, the protection is not needed anymore, as each process got its own part of memory : nothing is shared.</p>
<p>So, the way of accessing a request-related global will differ by the environment (multitask engine used). That means that we had to find a way so that accessing a request-bound global is done apparently the same way, whatever the environment.</p>
<p>We used macros for that, as they are just dedicated to such tasks.</p>
<p>The <code>WOW_G()</code> macro above will resolve very differently according to the multitask engine PHP is running on (process or threads).
And that is something you change by recompiling your extension, this is why PHP extensions are not compatible between ZTS mode and non-ZTS mode : this is not binary compatible !</p>
<blockquote>
<p>Obviously ZTS is not binary compatible with NZTS. Extensions must be recompiled when switching from one mode to the other</p>
</blockquote>
<p>See it : the <code>WOW_G()</code> macro usually resolves something like this in a process mode :</p>
<pre><code>#ifdef ZTS
#define WOW_G(v) wow_globals.v
#endif</code></pre>
<p>And something like this in a threaded mode :</p>
<pre><code>#ifdef ZTS
#define WOW_G(v) wow_globals.v
#else
#define WOW_G(v) (((wow_globals *) (*((void ***) tsrm_get_ls_cache()))[((wow_globals_id)-1)])->v)
#endif</code></pre>
<p>Looks more complex for ZTS mode isnt it ?</p>
<p>In process mode, that is in NZTS (Non Zend Thread Safe), a true global is used, here it is named <em>wow_globals</em>. This variable represents a structure containing the global variables, and you access every member into it with the macro. <code>WOW_G(foo)</code> leads to <code>wow_globals.foo</code>.
Obviously, you'll need to declare such a variable, and eventually to zero it at startup. This is done using a macro as well (as the way to do that will differ in ZTS mode). You do it like this :</p>
<pre><code>ZEND_BEGIN_MODULE_GLOBALS(wow)
    int foo;
ZEND_END_MODULE_GLOBALS(wow)

ZEND_DECLARE_MODULE_GLOBALS(wow)</code></pre>
<p>The macros then resolves to</p>
<pre><code>#define ZEND_BEGIN_MODULE_GLOBALS(module_name) typedef struct _zend_##module_name##_globals {
#define ZEND_END_MODULE_GLOBALS(module_name) } zend_##module_name##_globals;

#define ZEND_DECLARE_MODULE_GLOBALS(module_name) zend_##module_name##_globals module_name##_globals;</code></pre>
<p>And that's it. Pretty easy in process mode.</p>
<p>In threaded mode, aka using ZTS, like you can spot, there is no C true global anymore but the globals declaration look the same. Look :</p>
<pre><code>#define ZEND_BEGIN_MODULE_GLOBALS(module_name) typedef struct _zend_##module_name##_globals {
#define ZEND_END_MODULE_GLOBALS(module_name) } zend_##module_name##_globals;

#define WOW_G(v) (((wow_globals *) (*((void ***) tsrm_get_ls_cache()))[((wow_globals_id)-1)])->v)</code></pre>
<p>Declaring our globals is done the same way in ZTS or NZTS.</p>
<p>But accessing them looks a lot different. In ZTS, there is a call to the function <code>tsrm_get_ls_cache()</code>. This is the call to the Thread Local Storage (TLS), that is it will return a memory area that is bound to the current specific thread. Like you can see, this memory area seem complex, as the first cast we perform to it is a (void ***) cast, which let us smell that there is a lot of complexity behind it.</p>
<h2 id="the-tsrm-layer">The TSRM layer<a href="#the-tsrm-layer" class="anchor">#</a></h2>
<p>ZTS is designed using what we call the TSRM layer. Thread Safe Resource Manager layer. This is just some plain C code, nothing more !</p>
<p>TSRM is a layer of code, that makes ZTS possible. It is mainly stuck <a href="https://github.com/php/php-src/tree/master/TSRM">into the /TSRM</a> folder of PHP source code. Have a look at it, it is interesting even if we'll detail it here.</p>
<p>TSRM is not a perfect layer, it is globally well designed and ages back from PHP 5 beginning era (~2004). It is able to deal with several low-level threading libraries : Gnu Portable Thread, Posix Threads, State Threads, Win32 Threads or BeThreads. The layer you want it to use can be chosen at configuration time (./configure --with-tsrm-xxxxx).</p>
<p>We will only deal with the pthreads implementation when analysing TSRM in deep.</p>
<h3 id="tsrm-boot">TSRM boot<a href="#tsrm-boot" class="anchor">#</a></h3>
<p>At PHP boot, that is at module initialization, PHP quickly calls for <code>tsrm_startup()</code>. As PHP doesn't know yet how many threads and resources to build a thread-safe protection for, it prepares thread tables with just one element into them. Those tables will later grow, they are then allocated using a traditionnal <code>malloc()</code>.</p>
<p>This startup step is also important as it is here that we create both the TLS key, and the TLS mutex we'll need to synchronize.</p>
<pre><code>static pthread_key_t tls_key;

TSRM_API int tsrm_startup(int expected_threads, int expected_resources, int debug_level, char *debug_filename)
{
    pthread_key_create( &tls_key, 0 ); /* Create the key */

    tsrm_error_file = stderr;
    tsrm_error_set(debug_level, debug_filename);
    tsrm_tls_table_size = expected_threads;

    tsrm_tls_table = (tsrm_tls_entry **) calloc(tsrm_tls_table_size, sizeof(tsrm_tls_entry *));
    if (!tsrm_tls_table) {
        TSRM_ERROR((TSRM_ERROR_LEVEL_ERROR, "Unable to allocate TLS table"));
        return 0;
    }
    id_count=0;

    resource_types_table_size = expected_resources;
    resource_types_table = (tsrm_resource_type *) calloc(resource_types_table_size, sizeof(tsrm_resource_type));
    if (!resource_types_table) {
        TSRM_ERROR((TSRM_ERROR_LEVEL_ERROR, "Unable to allocate resource types table"));
        free(tsrm_tls_table);
        tsrm_tls_table = NULL;
        return 0;
    }

    tsmm_mutex = tsrm_mutex_alloc(); /* Allocate a mutex */
}

#define MUTEX_T pthread_mutex_t *

TSRM_API MUTEX_T tsrm_mutex_alloc(void)
{
    MUTEX_T mutexp;
    mutexp = (pthread_mutex_t *)malloc(sizeof(pthread_mutex_t));
    pthread_mutex_init(mutexp,NULL);
    return mutexp;
}</code></pre>
<h3 id="tsrm-resources">TSRM Resources<a href="#tsrm-resources" class="anchor">#</a></h3>
<p>Now that TSRM layer is booted, it is time to add new <strong>resources</strong> to it. A TSRM resource, is a memory area that represents a set of global variables, usually dedicated to a PHP extension, and that must be own by the current thread or protected for access.</p>
<p>So, that memory area has a size, and would need some initialization (constructor) and deinitialization (destructor). Usually initialization is just about zeroing the area whereas deinit does nothing.</p>
<p>That memory area, which is called a TSRM resource, will be given a unique resource ID by the TSRM layer. The caller then should save such an ID, as it will need it later on to be given back the protected memory area from TSRM.</p>
<p>Here is the TSRM function that creates a new resource :</p>
<pre><code>typedef struct {
    size_t size;
    ts_allocate_ctor ctor;
    ts_allocate_dtor dtor;
    int done;
} tsrm_resource_type;

TSRM_API ts_rsrc_id ts_allocate_id(ts_rsrc_id *rsrc_id, size_t size, ts_allocate_ctor ctor, ts_allocate_dtor dtor)
{
    int i;

    tsrm_mutex_lock(tsmm_mutex);

    /* obtain a resource id */
    *rsrc_id = id_count++;

    /* store the new resource type in the resource sizes table */
    if (resource_types_table_size < id_count) {
        resource_types_table = (tsrm_resource_type *) realloc(resource_types_table, sizeof(tsrm_resource_type)*id_count);
        if (!resource_types_table) {
            tsrm_mutex_unlock(tsmm_mutex);
            TSRM_ERROR((TSRM_ERROR_LEVEL_ERROR, "Unable to allocate storage for resource"));
            *rsrc_id = 0;
            return 0;
        }
        resource_types_table_size = id_count;
    }
    resource_types_table[(*rsrc_id)-1].size = size;
    resource_types_table[(*rsrc_id)-1].ctor = ctor;
    resource_types_table[(*rsrc_id)-1].dtor = dtor;
    resource_types_table[(*rsrc_id)-1].done = 0;

    /* enlarge the arrays for the already active threads */
    for (i=0; i < tsrm_tls_table_size; i++) {
        tsrm_tls_entry *p = tsrm_tls_table[i];

        while (p) {
            if (p->count < id_count) {
                int j;

                p->storage = (void *) realloc(p->storage, sizeof(void *)*id_count);
                for (j=p->count; j<id_count; j++) {
                    p->storage[j] = (void *) malloc(resource_types_table[j].size);
                    if (resource_types_table[j].ctor) {
                        resource_types_table[j].ctor(p->storage[j]);
                    }
                }
                p->count = id_count;
            }
            p = p->next;
        }
    }
    tsrm_mutex_unlock(tsmm_mutex);

    return *rsrc_id;
}</code></pre>
<p>As you can see, this function requires a mutex lock. If it is called into a child thread (it will be, for every of them), it will then lock other threads for the time it needs to manipulate the global thread storage state.</p>
<p>Our new resource is added to the dynamic <code>resource_types_table[]</code> array and is given a unique identifier, <code>rsrc_id</code>, which keeps incrementing as we add resources.</p>
<h3 id="on-request-startup">On request startup<a href="#on-request-startup" class="anchor">#</a></h3>
<p>Now we are ready to treat requests. Remember that each request will be served into its own thread. So, what happens when a new request shows in ?
At the very beginning of every new request, the <code>ts_resource_ex()</code> function is called. This function reads the current thread id and tries to fetch the ressources allocated for this thread, aka the memory areas dedicated for globals for the current thread. If none found (new thread), then it will create the ressources for the current thread, based on the model it built at PHP Startup.
This is done using <code>allocate_new_resource()</code></p>
<pre><code>static void allocate_new_resource(tsrm_tls_entry **thread_resources_ptr, THREAD_T thread_id)
{
    int i;

    TSRM_ERROR((TSRM_ERROR_LEVEL_CORE, "Creating data structures for thread %x", thread_id));
    (*thread_resources_ptr) = (tsrm_tls_entry *) malloc(sizeof(tsrm_tls_entry));
    (*thread_resources_ptr)->storage = NULL;
    if (id_count > 0) {
        (*thread_resources_ptr)->storage = (void **) malloc(sizeof(void *)*id_count);
    }
    (*thread_resources_ptr)->count = id_count;
    (*thread_resources_ptr)->thread_id = thread_id;
    (*thread_resources_ptr)->next = NULL;

    /* Set thread local storage to this new thread resources structure */
    tsrm_tls_set(*thread_resources_ptr);

    if (tsrm_new_thread_begin_handler) {
        tsrm_new_thread_begin_handler(thread_id);
    }
    for (i=0; i<id_count; i++) {
        if (resource_types_table[i].done) {
            (*thread_resources_ptr)->storage[i] = NULL;
        } else
        {
            (*thread_resources_ptr)->storage[i] = (void *) malloc(resource_types_table[i].size);
            if (resource_types_table[i].ctor) {
                resource_types_table[i].ctor((*thread_resources_ptr)->storage[i]);
            }
        }
    }

    if (tsrm_new_thread_end_handler) {
        tsrm_new_thread_end_handler(thread_id);
    }

    tsrm_mutex_unlock(tsmm_mutex);
}</code></pre>
<h3 id="extensions-local-storage-cache">Extensions Local Storage cache<a href="#extensions-local-storage-cache" class="anchor">#</a></h3>
<p>In PHP 7, each extension may declare a local storage cache. That is each extension should read its own thread local storage area at every new thread startup, instead of iterating the list of storages at every global access.
This is not done magically, and requires several things.</p>
<p>First, you must compile PHP to support the cache : pass <strong>-DZEND_ENABLE_STATIC_TSRMLS_CACHE=1</strong> to your compilation line. This should be the default however.
Then, you should now use the <code>ZEND_TSRMLS_CACHE_DEFINE()</code> macro when you declare your extension globals :</p>
<pre><code>#define ZEND_TSRMLS_CACHE_DEFINE(); __thread void *_tsrm_ls_cache = ((void *)0);</code></pre>
<p>Like you can see, that declares a true C global, but with the special <em>__thread</em> declaration. This is used to <a href="https://gcc.gnu.org/onlinedocs/gcc-4.2.4/gcc/Thread_002dLocal.html">tell the compiler</a> that this variable will be thread specific.</p>
<p>Then now, what you must do is populate this void* storage with the storage reserved for your globals by the TSRM Layer.
You may use <code>ZEND_TSRMLS_CACHE_UPDATE()</code> in your globals constructor for that :</p>
<pre><code>PHP_GINIT_FUNCTION(my_ext)
{
#ifdef ZTS
    ZEND_TSRMLS_CACHE_UPDATE();
#endif
    /* Continue initialization here */
}</code></pre>
<p>Here is the macro expansion :</p>
<pre><code>#define ZEND_TSRMLS_CACHE_UPDATE() _tsrm_ls_cache = tsrm_get_ls_cache();</code></pre>
<p>And for pthread implementation :</p>
<pre><code>#define tsrm_get_ls_cache pthread_getspecific(tls_key)</code></pre>
<p>Finally you should better understand how globals are now accessed in extensions, using macros :</p>
<pre><code>#ifdef ZTS
#define MY_G(v) (((my_globals *) (*((void ***) _tsrm_ls_cache))[((my_globals_id)-1)])->(v))</code></pre>
<p>Like you can see, using the MY_G() macro to access globals, when using a thread environment, it will expand to probe the <code>_tsrm_ls_cache</code> area using the id of this extension : <code>my_globals_id</code>.</p>
<p><img src="../../../img/threads-and-php/php_extensions_resources.png" alt="php_extensions_resources"></p>
<p>As we've seen, every extension is considered a resource and is given some space for its globals. The id is used to get back the storage for this specific extension. TSRM will have created that storage for the current thread when a new request/thread is born.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h2>
<p>Thread programming is not an easy task. Here, I just showed you how PHP deals with program globals management : it isolates every global storage using a TLS that is created for each new thread at request startup, by the engine and the dedicated layer : TSRM.
It locks a mutex, creates the storage for the current thread globals, then releases the mutex.
That way, every extension and every part of PHP may access its own storage without having to lock the mutex on each access.</p>
<p>Everything is abstracted behind the TSRM layer : a layer of C code that ease globals management, especially for extension creators. You use a macro to access your global space, and if you run under ZTS, that macro will expand to the specific code to access only your little storage in the middle of every extensions.
Using the TSRM cache, you don't need a lookup for every global access but you are given a pointer to your specific storage, you cache it and use it back when you need access to a global.</p>
<p>Obviously, this is for request-bound globals. You may still use true C globals, but don't try to write to them as you are servinf a request : you'll mess up the entire colossus and experiment hard-to-debug strange behaviors, if not crashing the whole webserver.</p>]]></content>
    </entry>
        <entry>
        <title>On the C language, and performances</title>
                <id>http://jpauli.github.io//2016/11/30/on-c-performances.html</id>
                <updated>2016-11-30T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2016/11/30/on-c-performances.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>I recently gave a training to my co-workers, about the C language. Wasn't really a training, but an introduction. With attendies really used to high level programing language, such as PHP, it was not very easy to
teach some low level concepts, yet crucial to understand the power of information computation.
This is mainly because we don't cope with the same problems in low level languages, than in high.</p>
<p>But, how could one pretend to master a (high level) language, if one doesn't even know what the machine CPU does, how it does compute things, and if this way of computing things is efficient, or not ?
This is the main problem of nowadays 2017 high level programing languages (auto memory management for most of them) : many people come to them, without having achieved the first steps.
I still think that knowing the low level helps a lot designing high level programs that are efficient. This is because your brain knows - even barely - how things will be done, that you can build better
programs.</p>
<p>Many school courses still start by teaching some assembly and C : those are the knowledges I myself have been taught back in late nineties. This is crucial and not delivering such training will create half-knowledge people, that will for sure suffer from the lack of that kind of low level knowledge once in their career. It's a fact : high level changes a lot, very often ; but low level changes order of magnitude slower, and less often.</p>
<p>In my opinion, the future is full of low-level programing oportunities; because there will always be a need in low level, as everything starts by a begining, and there must be some people that build that
"begining", so that other people can continue stacking up things and layers, to end having a concrete thing that is both helpful and efficient.</p>
<p>Do you really think IOT items, will be developed using high level languages ? Future video codecs ? Future VR applications ? Future networks ? Future Operating Systems ? Future console operating systems, or games ? Future in-car systems, like auto-pilots,
colisions avoidance algorithms, and so many other things .... ?
All those are written using low level languages, like the C language or assembly directly.</p>
<p>We even start to see "new" architectures emerging, like the very interesting ARM one which equips 98% of the cellphones on the planet. If nowadays you can use Java to build android apps, this is because android is
an operating system which has been writen in Java and C++, should you know that the Java language itself - like 80% of modern high level languages - is written in C (or C++).</p>
<p>Eventually C meets some sibling languages, but staying in the imperative programming model, those are pretty uncommon or less mature. Fortran could beat C in performance in some specific domains, Fortan and C being about the same age. And for purely specific mathematic applications, some specialized languages beat C performances. But C stays by far the most used and general-purpose general-efficient low level language in the world.</p>
<h3 id="let-s-start">Let's start<a href="#let-s-start" class="anchor">#</a></h3>
<p>This blog post will use Linux under X86_64 CPU. It will show you a very simple C program, that can sum 1G of bytes from one file (roughly one billion of bytes, or eight billions of bits), in less than half a second. Try to do that with a high level language, whatever it is, you will never ever reach
this kind of performance, even with Java which is known to be pretty fast, with JIT, parallel computing aspects and a nice memory model if well used in userland.
As soon as the language is not directly turned to machine instructions, but to some intermediate form (that's high-level languages definition), they can't beat C, even with JIT. They can narrow the gap of performances - in some specific domains - but on a big average they are blown away by the performances C can bring.</p>
<p>We will detail our problematic using the C language, then we'll dive down to the generated X86_64 instructions and we'll optimize our program using what are called SIMD, a kind of instructions in modern CPUs allowing us to treat massive amounts of data in just one instruction of few cycles (few nano-seconds).</p>
<h2 id="a-simple-c-program">A simple C program<a href="#a-simple-c-program" class="anchor">#</a></h2>
<p>To demonstrate the true power of the C programing language, I'll just take a simple use case, but still a use case that will represent some load : open a file, read each byte from it, and sum them all compacting the sum in one unsigned byte (thus overflowing several times). That's all. Ah yes of course : try to do that in an efficient way (the fastest as possible).</p>
<p>Why do that ? Just for the matter of the exercise here, the goal is that you fully understand what happens given a very simple problem.</p>
<p>Let's go :</p>
<pre><code>#include < stdio.h>
#include < stdint.h>
#include < string.h>
#include < fcntl.h>
#include < unistd.h>

#define BUF_SIZE 1024

int main(int argc, char **argv)
{
    int f, i;
    ssize_t readed;

    unsigned char result = 0;
    unsigned char buf[BUF_SIZE] = {0};

    if (argc != 2) {
        fprintf(stderr, "Usage : %s <file_to_sum>\n", argv[0]);
        exit(-1);
    }

    f = open(argv[1], O_RDONLY);

    if (f == -1) {
        perror("Can't open file");
    }

    while ((readed = read(f, buf, sizeof(buf))) > 0) {
        for (i=0; i < readed; i++) {
            result += buf[i];
        }
    }

    close(f);

    printf("Read finished, sum is %u \n", result);

    return 0;
}</code></pre>
<p>The payload would be, for example a 1Gb file.
To create a 1Gb file of some random content on your disk, simply use <code>dd</code> :</p>
<pre><code>> dd if=/dev/urandom of=/tmp/test count=1 bs=1G iflag=fullblock</code></pre>
<p>Now we can use that file and pass it as an argument to our program (which we'll call 'file_sum') :</p>
<pre><code>> file_sum /tmp/file
Read finished, sum is 186</code></pre>
<p>There are tons of ways to achieve the goal, but if we want to add efficiency, then we'll have to understand to some degree :</p>
<ul><li>How our CPU works, and what it is able to do (what kind of computations it can perform)</li>
<li>How our system works, by the means of how the Operating System Kernel works</li>
</ul><p>In short : we'll have to have some notions about both the hardware we're gonna run code against, and the low-level software : the OS</p>
<h2 id="remember-about-your-kernel">Remember about your Kernel<a href="#remember-about-your-kernel" class="anchor">#</a></h2>
<p>This blog post obviously is not a kernel course, but remember that we will not ask our CPU chip to communicate with the disk our to-be-read file is stored. This is because in 2016, we build what are called "user space" programs, and one of the definition of user space programs is that they are NOT allowed to access the hardware, directly. At any time a user space program needs some hardware services (access memory, disk, network, card reader etc...), it will ask the OS to do that by the help of what are called <a href="https://filippo.io/linux-syscall-table/">system calls</a>.
System calls are OS published functions to userland programs. We won't ask for the disk if it is ready, place the disk-head where needed, read X sectors, move the content from the disk on-chip memory to main memory ... blahblahblah.
This is the job of the OS kernel, helped by its drivers.
If we would have wanted to take hand on such low level tasks, we then should have written a "kernel space" program : mostly a Kernel module.</p>
<p>Why that ? You should read the <a href="jpauli.github.io/2015/04/16/segmentation-fault.html">segmentation fault</a> article I once wrote. It explains that the Kernel is the master that allows several programs to run concurrently, never crashing the machine or letting it in an unrecoverable state. Whatever instructions run.
For that, the kernel turns the CPU mode into <a href="https://en.wikipedia.org/wiki/Protection_ring">protected mode ring 3</a> when it comes to run a user land program ; and guess what ? In ring 3, the program cannot access the hardware mapped memory, as any instruction doing that will throw an exception into the CPU, any memory access out of very specific bounds will also lead to a CPU exception. On CPU exception, the Kernel fires back in running the Exception code which will basically restore the CPU in a stable state, and end our program with a signal (probably SIGBUS).</p>
<p>Ring 3 is the weakest privilege mode : every userland program runs in this mode. You can probe it by reading the first two bits of the CS register in your X86 CPU.</p>
<pre><code>gdb my_file
(gdb) p /t $cs
$1 = 110011</code></pre>
<p>The first two bits (weakest) show the current ring level, here : this is effectively 3.</p>
<p>User processes run in a very limited sandbox set up by the OS Kernel, running itself in ring 0 (full privileges). This is why it is not possible for a userland process to leak memory after its been destroyed. All of the data structures that control such things cannot be touched directly by user code; but the kernel takes care of them when the userland process finishes.</p>
<p>So, back to our code : we will not have hand on the performance of the disk read, because this is the Kernel that will perform such a job, using low level FileSystems and hardware drivers.
The calls used here are <code>open()</code>/<code>read()</code> and <code>close()</code>.
I did not use the libC functions (<code>fopen()</code>, <code>fread()</code>, <code>fclose()</code>), mainly because those are wrappers around the system calls. Those wrappers could improve or degrade the overall performances. It all depends on the code hidden behind those functions and how they are used in the program. Believe me the <a href="https://sourceware.org/git/?p=glibc.git;a=tree;hb=HEAD">libc is very nicely designed and performant</a> (some of its critical functions are directly written in assembly language), but you should know that those "I/O" functions use a buffer (that you can control), and call <code>read()</code> whenever they feel it is time to. Not really what we want : we want full control of our program, so we'll use system calls directly.</p>
<p>Whenever a system call is issued, the kernel fires back in and will mainly issue a <code>read()</code> call on the filesystem, itself issuing an I/O command to the device driver.
All those calls can be seen using Linux tracers, like the <a href="http://www.brendangregg.com/perf.html">wonderful perf tool</a>. System calls are costly for the program, because they issue a <a href="https://en.wikipedia.org/wiki/Context_switch">context switch</a>. Going from userland to kernel land is what's called a context switch, and we should try to avoid them as they involve a lot of work for the kernel.
But we need such calls ! Here, <code>read()</code> is the slowest one. When the <code>read()</code> is issued, the process will likely be scheduled out of the CPU and will go from running to I/O-waiting state. When the I/O will be ready, the kernel will re-schedule our process on the CPU, and resume it. This can be controlled by <a href="http://man7.org/linux/man-pages/man2/open.2.html">flags passed to the open()</a> call.</p>
<p>As you may know, the Kernel implements a <a href="http://www.tldp.org/LDP/sag/html/buffer-cache.html">buffer cache</a>, that is it remembers chunks of files content it has recently read from disk, caching them to main memory. That means that if you run the same program several times, chances are that the first time will be the slowest, especially if the program is I/O intensive like ours. So to measure its taken time, we'll measure that from the say third, or fourth launch (or we could average times of several individual launches).</p>
<h2 id="get-some-knowledge-about-your-hardware-and-compiler">Get some knowledge about your hardware and compiler<a href="#get-some-knowledge-about-your-hardware-and-compiler" class="anchor">#</a></h2>
<p>So far so good, we know that we won't be able to finely control the 3 syscalls performance : <code>open()</code>, <code>read()</code> and <code>close()</code>. But let's trust Kernel-land developpers for those latter. Also, we nowadays most often use SSD technology, so
we may bet that the read of 1Gb contiguous space (for our example) from a SSD drive will be fast.</p>
<p>What else, could then take time in our code ?</p>
<p>Not hard to spot : the way we sum bytes. You may then say "hey but, that's a simple loop, summing. What could we do about it here ?"</p>
<p>The two answers are : know your compiler, and know your hardware CPU chip.</p>
<p>Let's try to naively compile this code, with no optimizations, and run it :</p>
<pre><code>> gcc -Wall -g -O0 -o file_sum file_sum.c</code></pre>
<p>Then profile it, with a simple <code>time</code> command :</p>
<pre><code>> time ./file_sum /tmp/big_1Gb_file
Read finished, sum is 186 

real    0m3.191s
user    0m2.924s
sys     0m0.264s</code></pre>
<p>Remember, launch it several times for the Kernel page cache to warm-up. After several times, on my machine, I end up summing 1Gb contiguous from an SSD, in 3.1 seconds.
My laptop CPU is an Intel(R) Core(TM) i5-3337U CPU @ 1.80GHz, I run Linux 3.16.0-4-amd64 so my architecture is a very traditional X86_64 arch, I used GCC 4.9.2 to compile the code.</p>
<p>What <code>time</code> teaches us, is that we spend most of our time in userland (about 90% of total time). See how systemland time is tiny ? Those are the times where the Kernel runs on our behalf : the time performing the system calls. In our example : the time opening, reading and closing from the disk. Pretty fast isn't it ?</p>
<p>Note that our read buffer is here 1Kb. That means for a 1Gb file that we'll call <code>read()</code> 1024*1024 times (1048576 times). What about increasing our buffer size, so that we call <code>read()</code> less often ?
Let's give it 1Mb, that should lead to 1024 calls to <code>read()</code>, 1024 times less than before.</p>
<p>Change, recompile, re-run several times while profiling :</p>
<pre><code>#define BUF_SIZE 1024*1024</code></pre>
<p>.</p>
<pre><code>> gcc -Wall -g -O0 -o file_sum file_sum.c
> time ./file_sum /tmp/big_1Gb_file
Read finished, sum is 186 

real    0m3.340s
user    0m3.156s
sys     0m0.180s</code></pre>
<p>Great, by calling <code>read()</code> much less times, we fall from about 264ms to 180ms. Be careful if you want to push the limits : <code>read()</code> has a hard limit, and our buffer is stack allocated. Remember that the maximum stack size under modern Linux defaults to 8Mb (changeable as user limits).</p>
<blockquote>
<p>Try to call for the Kernel as less as possible. Syscall intensive programs usually delegate I/O syscalls to a dedicated thread and/or program I/O for async.</p>
</blockquote>
<h1 id="faster-stronger-and-not-very-harder">Faster, stronger (and not very harder)<a href="#faster-stronger-and-not-very-harder" class="anchor">#</a></h1>
<p>Why the hell does summing those bytes take so long ? The answer is because we ask our CPU to sum them in a very inefficient way. Let's see how the CPU does, by disassembling the program.</p>
<p>Remember that the C language is nothing without a compiler. The C language, is just a human affordable language to program a machine; that means that whatever happens, you'll need a C compiler, to turn your C code into machine low level instructions. Nowadays, we mainly use C to program systems and low level tasks, because we want to be able to port our code from one CPU architecture to another, without rewriting all the code. This is why C was invented in 1972.</p>
<blockquote>
<p>The C language is nothing without a compiler. A bad compiler or a bad compiler usage will lead to bad performances. This is the same for other competitor languages that get compiled to machine code, like Fortran f.e.</p>
</blockquote>
<p>But the CPU - the computing power - runs some machine code that can be represented as instructions in what's called an <em>assembly language</em>. We can dump the assembly instructions from a C program very easily just by asking the compiler, or by using a debugger.</p>
<p>And no : assembly is not hard. It depends on the assembly language and in this blog post we'll only be interested in the most worldwide spreaded assembly : X86 (and in 2016 : X86_64).</p>
<p>X86_64 is not hard (let me insist). It is simply HUGE, horribly HUGE. When I started assembly (with <a href="https://en.wikipedia.org/wiki/Freescale_68HC11">Freescale 68HC11</a>), I used some dozens instructions, nowadays, X86_64 counts thousands of instructions. And the manuals are what they are, and what they've always been : cryptic, huge, and in the time PDF did not exist : so heavy to carry in your bag on your back when stepping to school (I remember).</p>
<p>Let's scare ourselves. <a href="https://software.intel.com/en-us/articles/intel-sdm#nine-volume">Here are Intel manuals about X86_64</a>. Thousands, and thousands of sheets. Yes, Kernel developpers, and very very low level developpers use that as their primary resource. So you thought PHP online manual could be improved huh ?</p>
<p>Ok, let's go back on earth : do you really think that a tiny program like ours would need the reading of thousands of Intel manuals ? No. No because like always : a bunch of instructions are used everywhere - the 80/20 rule applies here (80% of your program will be made with 20% of the total instructions, that's barely that).</p>
<blockquote>
<p>By the way, Intel's website and manuals are fascinating. If you can, you really should read some of them.</p>
</blockquote>
<p>Here is the C code, repeated, and the disassembly of the part that interest us (from the <code>while()</code> loop) compiled with GCC 4.9.2 without any optimization</p>
<pre><code>#define BUF_SIZE 1024

int main(int argc, char **argv)
{
    int f, i;
    ssize_t readed;

    unsigned char result = 0;
    unsigned char buf[BUF_SIZE] = {0};

    if (argc != 2) {
        fprintf(stderr, "Usage : %s <file_to_sum>\n", argv[0]);
        exit(-1);
    }

    f = open(argv[1], O_RDONLY);

    if (f == -1) {
        perror("Can't open file");
    }

    while ((readed = read(f, buf, sizeof(buf))) > 0) {
        for (i=0; i < readed; i++) {
            result += buf[i];
        }
    }

    close(f);

    printf("Read finished, sum is %u \n", result);

    return 0;
}

00400afc:   jmp 0x400b26 < main+198>
00400afe:   movl $0x0,-0x4(%rbp)
00400b05:   jmp 0x400b1b < main+187>
00400b07:   mov -0x4(%rbp),%eax
00400b0a:   cltq 
00400b0c:   movzbl -0x420(%rbp,%rax,1),%eax
00400b14:   add %al,-0x5(%rbp)
00400b17:   addl $0x1,-0x4(%rbp)
00400b1b:   mov -0x4(%rbp),%eax
00400b1e:   cltq 
00400b20:   cmp -0x18(%rbp),%rax
00400b24:   jl 0x400b07 < main+167>
00400b26:   lea -0x420(%rbp),%rcx
00400b2d:   mov -0xc(%rbp),%eax
00400b30:   mov $0x400,%edx
00400b35:   mov %rcx,%rsi
00400b38:   mov %eax,%edi
00400b3a:   callq 0x4005d0 < read@plt>
00400b3f:   mov %rax,-0x18(%rbp)
00400b43:   cmpq $0x0,-0x18(%rbp)
00400b48:   jg 0x400afe < main+158>
00400b4a:   mov -0xc(%rbp),%eax
00400b4d:   mov %eax,%edi
00400b4f:   callq 0x4005c0 < close@plt></code></pre>
<p>Can you see how inefficient this code is ? If not, because those are cryptic lines to you , let me quickly introduce you to X86_64 assembly, by commenting the above dump, and what it does exactly.</p>
<h3 id="x86-64-assembly-basics">X86_64 assembly basics<a href="#x86-64-assembly-basics" class="anchor">#</a></h3>
<p>We should stay in a short blog post and here again, we won't give a full X86_64 course. Please, try to <a href="http://www.cs.virginia.edu/~evans/cs216/guides/x86.html">find info</a>, <a href="https://www.lri.fr/~filliatr/ens/compil/x86-64.pdf">here</a> or <a href="http://www.agner.org/optimize/calling_conventions.pdf">there</a>, if you miss some of them.</p>
<blockquote>
<p>Think in bytes, think in powers of 2 and 16</p>
</blockquote>
<ul><li>Each instruction is stored at a specific address in memory, denoted by the left column</li>
<li>Each instruction is unique and has a name (a mnemonic) : LEA - MOV - JMP etc...  There exists several thousands of them in modern X86_64</li>
<li>X86_64 is a <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computing">CISC architecture</a>. One instruction can lead to several internal lower level instructions in the pipeline, each of these may eat several clock cycles to execute (1 instruction != 1 CPU cycle)</li>
<li>Each instruction can take 0, 1, 2, or 3 operands maximum. You will often see 1 or 2.</li>
<li>There exist two main model to represent assembly : AT&T (also called GAS), and Intel.
<ul><li>In AT&T, you read  INSTR SRC DEST</li>
<li>In Intel you read INSTR DEST SRC</li>
<li>There exist some other differences, it is not that hard to turn from one to the other when your brain is trained. They are just syntaxes ok, nothing more.</li>
<li>We usually use AT&T, some people prefer Intel. GDB defaults to AT&T syntax for X86. <a href="https://en.wikibooks.org/wiki/X86_Assembly/GAS_Syntax">Get used to AT&T here</a></li>
</ul></li>
<li>X86_64 is little-endian , prepare your brain to invert addresses as your eyes read them. Always group by bytes, it is easier to think like this (I notice)</li>
<li>X86_64 does not allow memory-to-memory operations. There must be a register somewhere to treat the data</li>
<li>$ means a static immediate value ($1 is the value '1', for example)</li>
<li>% means a register access (%eax : access the EAX register)</li>
<li>(parenthesis) is a memory access, the star of C to dereference a pointer ( (%eax) means access the memory zone which address was stored in EAX register)</li>
</ul><h4 id="registers">Registers<a href="#registers" class="anchor">#</a></h4>
<p>A register is a memory zone of a fixed size onto the CPU chip. This is not the RAM ! This is absolutely way faster than RAM. A RAM access is performed <a href="https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html">in about 100ns</a> (bypassing any Layer of cache) but registry access is performed in 0ns.
The main thing to understand in CPU programming is this scenario, which keeps repeating again, and again, and again :</p>
<ul><li>Load a info from RAM memory, to a register : now the CPU "owns" a value</li>
<li>Apply a treatment on the register (multiply its value by 3, for example)</li>
<li>Store back the value from that register, to RAM memory : the info is saved from the CPU to the memory</li>
<li>You could also move the register data, into another compatible register (of the same size), if you wanted to</li>
</ul><p>I recall you that X86_64 cannot make treatments from RAM memory to RAM memory. You have to transfer to a register first.</p>
<p>There exists dozens of registers, we can't detail all here. We usually use "general purpose" registers : registers to compute things.</p>
<p>In X86_64 (this is different from X86 : 32 bit mode) , we have those registers to do whatever we want to : a, b, c, d, di, si, 8, 9, 10, 11, 12, 13, 14 and 15.</p>
<p>Each register is 64bit size (8 bytes), BUT, they can be accessed in 64bit mode, in 32bit mode, in 16bit mode or in 8bit mode. It all depends what you need.</p>
<p>Register A. Access in 64bits : RAX, access in 32bits : EAX, access in 16bits : AX. Access in 8bits, Low part : AL, High part : AH.</p>
<p>That's all. You see how easy it is ? A CPU is a very silly piece of silicon : it does only perform very simple operations, on very small parts of a byte. With general purpose registers, you can't access a bit, but at minima a byte. We usually access more than that : </p>
<ul><li>A byte, are 8 bits, this is the smallest part of information you can access. That's a BYTE</li>
<li>A double-byte, are 16 bits, and we call that a WORD</li>
<li>A double-double-byte, are 32 bits, we call that a DWORD (double word)</li>
<li>8 contiguous bytes, are 64 bits, we call them a QWORD (quad word, 4 times a 16bits word)</li>
<li>16 contigous bytes, that's 128 bits, we call them a DQWORD (a double-quad-word)</li>
</ul><p>OK for the vocabulary ? Let's continue then, but before a picture that sums all :</p>
<p><img src="../../../img/c-asm/register.png" alt="registers"></p>
<blockquote>
<p>Get more information about X86 at <a href="http://sandpile.org/"></a><a href="http://sandpile.org/">http://sandpile.org/</a> or from Intel/AMD/Microsoft websites. Take care : X86_64 works a little bit differently from X86 (32 bits mode). Also, read Intel manuals. No need to read from sheet 1 to 18625342 ... Grep the infos you are interested in.</p>
</blockquote>
<h3 id="x86-64-code-analysis">X86_64 Code analysis<a href="#x86-64-code-analysis" class="anchor">#</a></h3>
<pre><code>00400afc:   jmp 0x400b26 <main+198></code></pre>
<p>JMP is an unconditionnal jump. Ok, Let's jump to address 0x400b26</p>
<pre><code>00400b26:   lea -0x420(%rbp),%rcx
00400b2d:   mov -0xc(%rbp),%eax
00400b30:   mov $0x400,%edx
00400b35:   mov %rcx,%rsi
00400b38:   mov %eax,%edi
00400b3a:   callq 0x4005d0 < read@plt></code></pre>
<p>This code is the call to <code>read()</code>; <code>read()</code> is a system call, and if you dive deeper in <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#x86-64_calling_conventions">X86_64 calling convention</a>, you will see that most parameters are not passed by the stack anymore, but by registers.
This improves performance of every function call under X86_64 Linux, compared to 32 bits mode where the stack would have to be used for any call.</p>
<p>The <a href="https://www.cs.utexas.edu/~bismith/test/syscalls/syscalls64_orig.html">Kernel syscall table</a> teaches us that for <code>read(int fd, char *buf, size_t buf_size)</code>, the first parameter (file descriptor) must be passed in RDI, the second (buffer to fill) in RSI and the third (size of the buffer to fill) in RDX.</p>
<p>This is what the code above does. It uses RBP , which stands for "Register Base Pointer". RBP memorize the very beginning of the current stack space, whereas RSP ("Register Stack Pointer") memorize the current stack top if we would need to play with the stack. The stack is nothing more than one big memory zone dedicated for us, it contains local function variables, <code>alloca()</code> variables, the return address and can contain function arguments if there are several of them.</p>
<p>Into the stack are stored the local variables of the <code>main()</code> function we are in.</p>
<pre><code>00400b26:   lea -0x420(%rbp),%rcx</code></pre>
<p>Load Effective Address stored at RBP minus 0x420, to RCX. This is our buffer variable : <code>buf</code>. Note that LEA doesn't read the value behind the address, but the address itself. Under GDB, you can print any value, and compute maths :</p>
<pre><code>> (gdb) p $rbp - 0x420
$2 = (void *) 0x7fffffffddc0</code></pre>
<p>You can also display every register, with <code>info registers</code></p>
<pre><code>> (gdb) info registers
rax            0x400a60 4196960
rbx            0x0      0
rcx            0x0      0
rdx            0x7fffffffe2e0   140737488347872
rsi            0x7fffffffe2c8   140737488347848
... ...</code></pre>
<p>Continuing</p>
<pre><code>00400b2d:   mov -0xc(%rbp),%eax</code></pre>
<p>Move the value at the address pointed by RBP minus 0xc, into EAX. This is likely to be our <code>f</code> variable. This can be confirmed easily :</p>
<pre><code>> (gdb) p $rbp - 0xc
$1 = (void *) 0x7fffffffe854
> (gdb) p &f
$3 = (int *) 0x7fffffffe854</code></pre>
<p>Continuing.</p>
<pre><code>00400b30:   mov $0x400,%edx</code></pre>
<p>Move the value 0x400 (1024 in decimal) into EDX. This is <code>sizeof(buf)</code> : 1024 , the third parameter for <code>read()</code>.</p>
<p>Continuing</p>
<pre><code>00400b35:   mov %rcx,%rsi
00400b38:   mov %eax,%edi
00400b3a:   callq 0x4005d0 < read@plt></code></pre>
<p>Move the content of RCX into RSI. RSI is the second parameter to <code>read()</code>. Move the content of EAX into EDI. EDI is the third parameter for <code>read()</code>.
Then : call the <code>read()</code> function.</p>
<p>Every system call returns its value into register A (sometimes also in D). As <code>read()</code> returns a <code>ssize_t</code>, this weight 64 bits, thus to read the return value we need to probe the whole A register : we use RAX (64 bits read of registry A). So :</p>
<pre><code>00400b3f:   mov %rax,-0x18(%rbp)
00400b43:   cmpq $0x0,-0x18(%rbp)
00400b48:   jg 0x400afe < main+158></code></pre>
<p>Move the return value of <code>read()</code> which is in RAX, in the address pointed by RBP minus 0x18.
A quick watch confirms this is our <code>readed</code> variable from C code.</p>
<p>CMPQ : Compare Quad-Word. Compare the value of <code>readed</code> with the value 0.</p>
<p>JG : Jump if greater, to 0x400AFE. This is just the comparison in the <code>while()</code> loop from the C code.</p>
<p>We keep reading our buffer, so, let's jump to 0x400AFE, it should be the beginning of the <code>for()</code> loop.</p>
<pre><code>00400afe:   movl $0x0,-0x4(%rbp)
00400b05:   jmp 0x400b1b < main+187></code></pre>
<p>MOVL : Move a Long (32 bits) of value 0 to the address pointed by RBP minus 4. This is <code>i</code>. <code>i</code> is an integer in C, so 32 bits, or 4 bytes. It is then stored as the very first variable into the stack frame of <code>main()</code> (represented by RBP).</p>
<p>Then jump. Let's follow that at 0x400B1B , we should find the following of our <code>for()</code> loop.</p>
<pre><code>00400b1b:   mov -0x4(%rbp),%eax
00400b1e:   cltq 
00400b20:   cmp -0x18(%rbp),%rax
00400b24:   jl 0x400b07 <main+167></code></pre>
<p>Move the value pointed by address in RBP minus 4 (likely an integer) into EAX.</p>
<p>CLTQ : Convert Long To Quad. CLTQ acts on register A. It sign extends EAX to a 64 bits integer, fetchable by RAX.</p>
<p>CMP : Compare value in RAX with value pointed by address into RBP minus 0x18. This compares our <code>i</code> variable from the <code>for()</code> loop, with the variable <code>readed</code>.</p>
<p>JL : Jump if Lower, to 0x400B07. We are at the first step into the <code>for()</code> , so yes : we will jump.</p>
<pre><code>00400b07:   mov -0x4(%rbp),%eax
00400b0a:   cltq 
00400b0c:   movzbl -0x420(%rbp,%rax,1),%eax
00400b14:   add %al,-0x5(%rbp)
00400b17:   addl $0x1,-0x4(%rbp)
00400b1b:   mov -0x4(%rbp),%eax
00400b1e:   cltq 
00400b20:   cmp -0x18(%rbp),%rax
00400b24:   jl 0x400b07 < main+167></code></pre>
<p>Here is the most interesting part.</p>
<p>MOV <code>i</code> in EAX (<code>i</code> is -0x4(%rbp) as told before). Then, CLTQ : sign-extend it to 64 bits.</p>
<p>MOVZBL : MOV Zero-extend Byte to Long, stored at (1*RAX+RBP) minus 0x420 into EAX. This seems complex, but those are just maths ;-) This is <code>buf[i]</code> computation, in just one instruction. This is the power of C pointers : <code>buf[i]</code> is <code>buf + i*sizeof(buf[0])</code> bytes. The resulting address is then easily computable in assembly and compilers have just a bunch of maths to do to generate such an instruction.</p>
<p>Now that we loaded that into EAX, we add this value to <code>result</code> :</p>
<pre><code>00400b14:   add %al,-0x5(%rbp)</code></pre>
<p>Remember : AL, is the lower byte of the 8-byte-large RAX (RAX and AL represent both the A register), this is <code>buf[i]</code>, as <code>buf</code> is of char type and then weigths one byte. <code>result</code> is at -0x5(%rbp) : that is one byte after <code>i</code>, being at 0x4 from RBP : yes, that confirms that <code>result</code> is effectively a char, weighting one byte.</p>
<pre><code>00400b17:   addl $0x1,-0x4(%rbp)</code></pre>
<p>ADDL : Add a long (32 bits). This adds 1 to <code>i</code></p>
<p>And go back to the  00400b1b instruction : the <code>for()</code> loop.</p>
<h3 id="a-quick-summary">A quick summary<a href="#a-quick-summary" class="anchor">#</a></h3>
<p>You look tired ? This is because your not used to assembly. And like you've seen by decrypting assembly (X86_64) with me : this is just first-level school maths : add, sub, multiply. Please, don't say it is hard, as adding, substracting etc... are really not hard operations and your brain, when well trained, can perform them very quickly ;-)</p>
<blockquote>
<p>Assembly is really easy maths operations : add/sub/mul/div. Assembly languages are easy. But yes : they are very verbose. Feel the diff between "verbose" and "hard" ?</p>
<p>I once said : "If you want your child to further become a good programmer, don't make the mistake to have him learn maths only by base (radix) 10. Train his brain to switch from one base to another. Fundamental algebra are fully understood only when one can represent any quantity, in any radix, especially basis 2, 8 and 16". Use a <a href="https://en.wikipedia.org/wiki/Soroban">Soroban</a>, like Japanese people do.</p>
<p>If you feel lost with maths, this is just because of one thing : your brain has always been trained in base 10. Switching from 10 to 2 is hard, because those bases are not multiples in their powers. But switching from base 2 to 16, or 8, is an easy step. With some training, you manage to compute most addresses by head.</p>
</blockquote>
<p>So, our <code>for()</code> loop is poor : it needs 6 memory accesses, and was translated as-is from the C source code : it will effectively loop <strong>for each byte</strong> to sum, and sum it. For each byte - in a file of 1GB - that will make it loop 0x40000000 times, sorry 1073741824 decimal times.</p>
<p>Even at 2Ghz, (remember that in CISC, one instruction != one cycle) looping 1073741824 times takes time. We end up running all the code in about 3 seconds, because this way of computing things (summing bytes one by one from a read file) is awfully inefficient.</p>
<h2 id="let-s-vectorize-all-that-by-using-simd">Let's vectorize all that by using SIMD<a href="#let-s-vectorize-all-that-by-using-simd" class="anchor">#</a></h2>
<p>SIMD. Single Instruction Multiple Data. All is said.</p>
<blockquote>
<p>SIMD are special instructions that allows the CPU to work not with one byte, or one word, or one Double-word...  But with <strong>several of them</strong>, in one single instruction.</p>
</blockquote>
<p>Please, Welcome SSE : Streaming SIMD Extensions. You know SSE, SSE2 , SSE4, SSE4.2 and MMX, or 3DNow!  Because (I hope) you heard those terms when you were about to buy a CPU on the market. SSE are SIMD instructions. And if one CPU can work with many data at a given time : it should oviously decrease the overall computation time. And that is the case : drastically !</p>
<p><img src="../../../img/c-asm/SIMD-operation.png" alt="SIMD-operation"></p>
<blockquote>
<p>Do not only look at the number of cores, the cache sizes or the frequency when you buy a CPU. Look also at the instruction sets supported. You prefer adding one byte to one byte, every nanosecond , or adding 8 bytes to 8 bytes, every 2 nanoseconds ?</p>
</blockquote>
<p>SIMD are the instructions that allow very intensive calculus into the CPU. SIMD are used everywhere parallel information processing is allowed. Fields of application :</p>
<ul><li>Matrix maths (add, transpo, etc...), so the basics of every graphical computing (but GPU are order of magnitude better at doing that).</li>
<li>Data compression, where several bytes gets processed at once (LZ, GZ, but also MP3, Divx, H264/5, JPEG FFT and so many others)</li>
<li>Cryptographic applications
*Speech or music recognition (like the one used in your cellphone, which embeds a very powerful SIMD based processor, probably ARM architecture)</li>
<li>etc...</li>
</ul><p>Want a quick overview ? <a href="https://software.intel.com/en-us/articles/motion-estimation-with-intel-streaming-simd-extensions-4-intel-sse4">Motion Estimation with Intel Streaming SIMD Extensions 4</a>. Motion estimation is a crucial algorithm used in every modern video codec. It allows a frame F+1 to get predicted from motion vectors computed from a base frame F, so that we only code the movement of pixels from one picture to the other, instead of encoding both pictures at full sizes. H264 and H265 codecs are wonderful, and open source. Read their code and learn ! (Step to the MPEG norm before)</p>
<p>Make a test :</p>
<pre><code>> cat /proc/cpuinfo
processor   : 2
vendor_id   : GenuineIntel
cpu family  : 6
model       : 58
model name  : Intel(R) Core(TM) i5-3337U CPU @ 1.80GHz
(...)
flags       : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm ida arat epb xsaveopt pln pts dtherm tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms</code></pre>
<p>See all those flags ? Those are mainly supported instructions and instruction sets on my laptop CPU.</p>
<p>We can spot from here : sse, sse2, sse4_1, sse4_2, aes, avx  among all.</p>
<p>AES allows to compute AES crypto ! Directly into the CPU, in a bunch of specialized instructions.</p>
<p>SSE4.2 allows to compute a CRC32 sum in one instruction. It also allows to compare strings, in a few instructions. The latest libC <code>str()</code> functions <a href="https://www.strchr.com/strcmp_and_strlen_using_sse_4.2">are based on SSE4.2</a>, and if you can grep a word in a huge text so rapidly, where do you think the power comes from ?</p>
<h3 id="simd-to-help-us">SIMD to help us<a href="#simd-to-help-us" class="anchor">#</a></h3>
<p>Now is time to patch our C program, to make it use SIMD, and see if it goes faster.</p>
<p>It all began with MMX, which  used to add 8 new registers, from MM0 to MM7 ; being 64 bits large. MMX appeared in late nineties, I still remember that time. Pentium 2 and Pentium 3 were very expensive in their time, especially because of MMX.</p>
<p>MMX is now obsoleted by SSE.</p>
<p>SSE, from SSE to latest SSE4.2, have been added to CPUs from 2000 to 2010 (roughly). If one supports SSE version X, it must support all preceding versions.</p>
<p><img src="../../../img/c-asm/SSE-evolution.png" alt="SSE-evolution"></p>
<p>SSE4.2 is nowadays most spreaded SSE. Supporting SSE4.2 means also supporting all preceding versions of SSE. SSE4.2 adds 16 new registers (in X86_64) : XMM0 to XMM15 , and they are 128 bits large ! 128 bits are 16 bytes.
That means that if you feed an SSE register, and perform some computation with it, you will treat 16 bytes alltogether.</p>
<p><img src="../../../img/c-asm/SSE-3264.gif" alt="SSE-3264registers"></p>
<p>And if you feed 2 SSE registers, you can compute maths on 32 bytes at a time... This starts to be really interesting.</p>
<p>So, with 16 bytes per register, you can store (LP64 sizes):</p>
<ul><li>16 bytes : sixteen C chars</li>
<li>Two 8-byte values : Two C longs, or two C doubles (double precision float)</li>
<li>Four 4-byte values : four C ints, or four C floats (single precision float)</li>
<li>Eight 2-byte values : eight C shorts</li>
</ul><p>Like this :</p>
<p><img src="../../../img/c-asm/SSE-registers.png" alt="SSE-registers"></p>
<blockquote>
<p>SIMD are also called "vector" instructions, as they act on a "vector", that is one area full of different smallest items. A "vector instruction" acts on several data at the same time, whereas a "scalar instruction" acts only on one single piece of data.</p>
</blockquote>
<p>There exists two ways to achieve that in our demo program :</p>
<ul><li>Directly write the assembly that plays with those registers</li>
<li>Use Intel Intrinsics : an Intel API allowing to write C code that will get (for sure) translated in compilation to SSE instructions</li>
</ul><p>I chose to show you the second option, and I will let you do the first option as an exercise, right ?</p>
<p>Let's patch the code :</p>
<pre><code>#include < stdio.h>
#include < stdint.h>
#include < string.h>
#include < fcntl.h>
#include < unistd.h>
#include < tmmintrin.h>

#define BUF_SIZE 1024

int main(int argc, char **argv)
{
    int f, i;
    ssize_t readed;
    __m128i r  = _mm_set1_epi8(0);

    unsigned char result = 0;
    unsigned char buf[BUF_SIZE] __attribute__ ((aligned (16))) = {0};

    if (argc != 2) {
        fprintf(stderr, "Usage : %s <file_to_sum>\n", argv[0]);
        exit(-1);
    }

    f = open(argv[1], O_RDONLY);

    if (f == -1) {
        perror("Can't open file");
    }

    while ((readed = read(f, buf, sizeof(buf))) > 0) {
        for (i=0; i < readed; i+=16) {
            __m128i a = _mm_load_si128((const __m128i *)(buf+i));
            r = _mm_add_epi8(a, r);
        }
        memset(buf, 0, sizeof(buf));
    }

    for (i=0; i<16; i++) {
        result += ((unsigned char *)&r)[i];
    }

    close(f);

    printf("Read finished, sum is %u \n", result);

    return 0;
}</code></pre>
<p>You see that new header, <em>tmmintrin.h</em> ? This is Intel API. And this API has a nice documentation !! <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel intrinsics guide</a></p>
<p>So, I chose to use only one SSE register to store the result of the sum (accumulator), and on SSE register to load a line from memory. You can do diffrently, and use for example 4 registers at a time, or even all of them. You'll end up summing 256 bytes in 16 operations :D  Crazy.</p>
<p>Remember SSE register sizes ? Our exercise tries to sum bytes. Bytes. That means that we'll use the sixteen individual bytes into the register.
If you read the documentation, or the intrinsics, you will see that there are many functions to "pack" and "unpack" values into the registers. We won't use them. We will not need, at any moment, to turn our sixteen bytes into eight words, or four double words. We'll keep summing bytes. SIMD are much more powerful than what will be shown in this blog post, believe me.</p>
<p>The difference with the previous classical C program is that now, we will sum bytes sixteen by sixteen, instead of one by one.</p>
<p>We are going to treat massively more data in one instruction.</p>
<pre><code>__m128i r  = _mm_set1_epi8(0);</code></pre>
<p>The statement above prepares an XMM register (16 bytes), and fill it with zeroes.</p>
<pre><code>for (i=0; i < readed; i+=16) {
    __m128i a = _mm_load_si128((const __m128i *)(buf+i));
    r = _mm_add_epi8(a, r);
}</code></pre>
<p>Every <code>for()</code> loop should now increase the buffer not by one byte, but by sixteen. So, <code>i+=16</code>.</p>
<p>Now, we access the memory buffer, <code>buf+i</code>, and cast it to a <code>__m128i*</code> pointer. We so access the memory zone 16 bytes by 16 bytes.
And we load those 16 bytes into the <code>a</code> variable, using <code>_mm_load_si128()</code> , which loads those 16 bytes as 16 * one byte, into a XMM register.</p>
<p>Now, just add this 16-byte vector to our accumulator <code>r</code>. This is done using <code>_mm_add_epi8()</code>. And loop, loop, loop ; 16 by 16 bytes.</p>
<p>At the end of the loop, it stays the last bytes in the register. Unfortunately, there is no easy way to horizontal add them all. This can be done for words, double words, etc... but not for bytes ! Look at <code>_mm_hadd_epi16()</code> for example.</p>
<p>So, what we do, is simply to that by hand :</p>
<pre><code>for (i=0; i<16; i++) {
    result += ((unsigned char *)&r)[i];
}</code></pre>
<p>And we are done.</p>
<p>Compile, and profile :</p>
<pre><code>> gcc -Wall -g -O0 -o file_sum file_sum.c
> time ./file_sum /tmp/test 
Read finished, sum is 186 

real    0m0.693s
user    0m0.360s
sys 0m0.328s</code></pre>
<p>roughly 700ms. We fall from 3000 ms with some classical C suming byte-per-byte, to 700ms suming 16byte-by-16byte.</p>
<p>Should we be suprised ? No.</p>
<p>What happens in there ? Let's disassemble the code for the <code>while()</code> loop , as the other code shouldn't have changed :</p>
<pre><code>00400957:   mov -0x34(%rbp),%eax
0040095a:   cltq 
0040095c:   lea -0x4d0(%rbp),%rdx
00400963:   add %rdx,%rax
00400966:   mov %rax,-0x98(%rbp)
0040096d:   mov -0x98(%rbp),%rax
00400974:   movdqa (%rax),%xmm0
00400978:   movaps %xmm0,-0x60(%rbp)
0040097c:   movdqa -0xd0(%rbp),%xmm0
00400984:   movdqa -0x60(%rbp),%xmm1
00400989:   movaps %xmm1,-0xb0(%rbp)
00400990:   movaps %xmm0,-0xc0(%rbp)
00400997:   movdqa -0xc0(%rbp),%xmm0
0040099f:   movdqa -0xb0(%rbp),%xmm1
004009a7:   paddb %xmm1,%xmm0
004009ab:   movaps %xmm0,-0xd0(%rbp)
004009b2:   addl $0x10,-0x34(%rbp)
004009b6:   mov -0x34(%rbp),%eax
004009b9:   cltq 
004009bb:   cmp -0x48(%rbp),%rax
004009bf:   jl 0x400957 <main+545></code></pre>
<p>Should I detail all ? Can you spot those <code>%xmm0</code> and <code>%xmm1</code> ? The SSE registers. They are used ! What do we do with them ?</p>
<p>We MOVDQA into them : MOV Double Quad-word Aligned. We MOVAPS : MOV Aligned Packed Single-Precision. Those two instructions do the exact same thing : they move 128 bits (16 bytes). Why 2 instructions then ? I can't explain, as to explain that, we need to detail the CISC architecture, the superscalar execution engine and the internal pipeline. </p>
<p>And finally : we did it ! PADDB : Packed Add Bytes : We sum two 128 bit registers together, in one instruction !</p>
<p>Our goal is achieved.</p>
<h3 id="a-word-on-avx">A word on AVX<a href="#a-word-on-avx" class="anchor">#</a></h3>
<p>Advanced Vector eXtension are the future of SSE. Just another term, but think about AVX as beeing SSE++ , like SSE5 or SSE6.</p>
<p>AVX appeared with Intel Sandy Bridge architecture back in 2011, and as we are entering 2017 we can say that like SSE superseded MMX, now AVX superseded SSE. SSE has become an "old" technology, equipping CPUs from the 2000-2010 era. 2010-2020(?) SIMDs are AVX.</p>
<p>AVX extends the power of SIMD by extending the XMM registers to 256 bits, aka 32 bytes. Register XMM0, for example, can now be accessed as YMM0. It is then accessed as 256 bits. Those are not brand new registers, but extensions of the SSE existing ones.</p>
<p><img src="../../../img/c-asm/AVX-registers.png" alt="AVX-registers"></p>
<p>AVX instructions can be used with XMM registers from SSE, they will only act on the low 128bits of the YMM corresponding register. This allows nice migration of code from SSE to AVX.</p>
<p>AVX also introduces a new syntax where OPCodes can take up to three source arguments, for one destination; that is the destination can be different from the sources whereas in SSE the destination was one of the source, thus performing "destructive" computations (one would have to save a register content before performing computation with it if this latter would have been also the destination of an opcode). Like this :</p>
<pre><code>VADDPD %ymm0 %ymm1 %ymm2   : Add DoublePrecision floats from ymm1 to ymm2 and put the result into ymm0</code></pre>
<p>Also, AVX allows in the formula MNEMONIC DST SRC1 SRC2 SRC3 to have one of SRC or DST being a memory address (but not more). Hence, many AVX instructions (not all of them) can work directly from memory, preventing to load the data into a register before, and many of them can act with 3 sources, and not only 2.</p>
<p>Finally, AVX introduces great FMA instructions. FMA stands for Fused Multiply Add, and allows such maths to get computed as one instruction : A = (B * C) + D.</p>
<h3 id="a-word-on-avx2">A word on AVX2<a href="#a-word-on-avx2" class="anchor">#</a></h3>
<p>Let's continue, because Intel never stops !</p>
<p>AVX2 appeared recently : 2013, with Haswell CPU architecture. And guess what ? AVX2 allows to add bytes in 256 bits registers. Exactly what we need, for our example program. Unfortunately, AVX (AVX 1) doesn't allow that. AVX, when working with new 256 bits registers, can only perform operations on floats (half, single and double precision) and on integers ; but not on single bytes !</p>
<p>Though for our exercise, we would need to patch it to use AVX2 and the new VPADDB instruction, which adds bytes from YMM registers (so that add bytes in a 32-by-32 fashion). Do it yourself, because my actual CPU dates from before 2013, and doesn't support AVX2 ! I already asked to change my laptop, and got a new one to prepare with a Skylake CPU, so supporting AVX2 :-)</p>
<p>AVX and AVX2 Intel manuals <a href="https://software.intel.com/en-us/file/36945">are available here</a>.</p>
<h3 id="a-word-on-avx-512">A word on AVX-512<a href="#a-word-on-avx-512" class="anchor">#</a></h3>
<p>We never stop Intel I told you. AVX-512 is - as of end of 2016 - reserved to professionnal market Intel CPU : Xeon-Phi. Chances are that this instruction set will reach common market in the future (2018 ?).</p>
<p>AVX-512 extends once again the AVX registers, from 256 to 512 bits , aka 64 bytes ! And that's not all : AVX-512 adds 15 new SIMD registers growing their number to the impressive total of Thirty-two 512 bits registers. The upper 256 bits are accessed throught the new ZMM registers, that share their body with AVX YMM registers, themselves sharing half of their body with SSE XMM registers.</p>
<p><a href="https://software.intel.com/en-us/blogs/2013/avx-512-instructions">Intel informations here</a>.</p>
<p>I know why nowadays we can predict the weather with a window of something like 15 days ... <a href="https://en.wikipedia.org/wiki/Vector_processor">SuperVectorial CPUs</a> compute those kind of informations.</p>
<h3 id="simd-everywhere">SIMD everywhere ?<a href="#simd-everywhere" class="anchor">#</a></h3>
<p>Would be nice huh ? SIMD have drawbacks :</p>
<ul><li>SIMD requires a perfect memory alignment</li>
<li>Every code doesn't allow parallelism like this</li>
</ul><p>Alignement first. I can't detail but that's so logical. How could the CPU access a memory zone to load 16 bytes, if that address is not divisible by 16 ?
It simply can't (in one instruction, like MOV).</p>
<blockquote>
<p>Have you played lego (not the video game !) when you were a young child ? You should have. That develops brain capacities to understand the alignement of data in computer memory.</p>
</blockquote>
<p>Look :</p>
<p><img src="../../../img/c-asm/data-alignement.jpg" alt="data-alignement"></p>
<p>See the problem ? This is why I used that in the C code :</p>
<pre><code>unsigned char buf[BUF_SIZE] __attribute__ ((aligned (16))) = {0};</code></pre>
<p>To tell the compiler to store <code>buf</code> on the stack at an address divisible by 16.</p>
<p>You can use SIMD with unaligned data, but you pay a so big price that usually it is not worth using SIMD anymore.
You basically ask your CPU to load address X, then address Y, trash bytes from X, then from Y, then paste together the two memory zones. This is silly.</p>
<p>More on memory alignement <a href="http://www.songho.ca/misc/alignment/dataalign.html">here</a>, or <a href="https://www.ibm.com/developerworks/library/pa-dalign/">there</a>.</p>
<p>Note that aligning data in memory is also a really recommanded way of doing things with "classical" C. In PHP, for example, we use such technics; and in every strong C program, the programmer is aware of that and helps the compiler in generating better code. The compiler can sometimes "guess" things and align some buffers, but often dynamic memory (heap) is used and you then have to do things the right way if you don't want to pay performance penalties at every memory access.
This is especially true in C structure design.</p>
<p>Other problem of SIMD is that you need to have parallelisable data. You need to think your software in such a way that you can present parallel data to your CPU. If not, the compiler will generate classical registers and instructions, and will not use SIMD. Not every algorithm is parallelisable like that. Some tend to be more than others, like data compression for example.</p>
<p>SIMD come at a price, but that price is not that huge.</p>
<h2 id="let-s-fight-with-the-compiler-turn-optimizations-on-and-auto-vectorize-on">Let's fight with the compiler : turn optimizations on, and auto-vectorize on<a href="#let-s-fight-with-the-compiler-turn-optimizations-on-and-auto-vectorize-on" class="anchor">#</a></h2>
<p>Wait. In the introduction, I talked about half a second to sum bytes. We are still achieving 700ms, that's cheated not 500ms !</p>
<p>Yes, there is a trick.</p>
<p>Look back at how we compiled our C code. We disabled optimizations. Optimizations are a very very very long subject I can't detail, but <a href="http://jpauli.github.io/2015/03/05/opcache.html#opcache-compiler-s-optimizer">I gave some ideas in a PHP related article</a>, where I detailed how the OPCache extension can hook the PHP compiler and throw optimization passes to the generated code.</p>
<p>This is exactly the same here, but it is so complex... Try to have a look at GCC internals, you will quickly come back on earth, believe me.
The complexity of code optimization is high, and the subject is huge. Search-engine some terms, and get yourself some infos on the subject.</p>
<p>Simply, if we tell our compiler to generate optimized code, it will very likely generate a code that is more optimized and performs better, than what you poor human, can do. This is why we use an upper language (C here), and a compiler !</p>
<p>Because every program meets the same needs, just another <a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing-complete</a> <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton">Deterministic finite automaton</a>, so ...</p>
<p>We are in 2016. C compilers have existed since ~1970 ! They have been improved for nearly 50 years now, do you really think your poor brain could beat them ?
In fact, you could beat them, in some very rare cases ; it is usualy not worth the search knowing that to beat the compiler, you must basically store the HUGE Intel manuals all together into your brain (that is : have a <em>perfect</em> knowledge of the assembly)</p>
<p>What is worth however, is understanding how the compiler works, so that the C code you will present it, is optimizable. Don't write silly things, try to unalias your pointers, there exists many "C tricks for perf" that are just "C tricks for the compiler to generate better code". I can't list here; this blog post is already so huge, but <a href="http://www.agner.org/optimize/#manuals">you should start by reading here</a> for the subject.</p>
<p>Compile our bad program - the one summing bytes one-by-one with no intrinsics - with full optimizations.</p>
<pre><code>> gcc -Wall -g -O3 -o file_sum file_sum.c
> time ./file_sum /tmp/test 
Read finished, sum is 186 

real    0m0.416s
user    0m0.084s
sys     0m0.316s</code></pre>
<p>Can you believe that ? We take overall 416ms , and the computation of byte summing took 84ms whereas the syscalls and disk access took a horrible 316ms.</p>
<p>Yeah.</p>
<p>We can disassemble. The full disassembly can be watched here : <a href="https://godbolt.org/g/Hir2bF">https://godbolt.org/g/Hir2bF</a></p>
<p>Here are the interesting parts :</p>
<pre><code>00400688:   mov %rcx,%rdi
0040068b:   add $0x1,%rcx
0040068f:   shl $0x4,%rdi
00400693:   cmp %rcx,%rdx
00400696:   paddb 0x0(%rbp,%rdi,1),%xmm0
0040069c:   ja 0x400688 <main+136>
0040069e:   movdqa %xmm0,%xmm1
004006a2:   psrldq $0x8,%xmm1
004006a7:   paddb %xmm1,%xmm0
004006ab:   movdqa %xmm0,%xmm1
004006af:   psrldq $0x4,%xmm1
004006b4:   paddb %xmm1,%xmm0
004006b8:   movdqa %xmm0,%xmm1
004006bc:   psrldq $0x2,%xmm1
004006c1:   paddb %xmm1,%xmm0
004006c5:   movdqa %xmm0,%xmm1
004006c9:   psrldq $0x1,%xmm1
004006ce:   paddb %xmm1,%xmm0
004006d2:   movaps %xmm0,(%rsp)
004006d6:   movzbl (%rsp),%edx
(...) (...)     (...) (...)</code></pre>
<p>The analyse is left to you, but here, the compiler used a lot of tricks to make the program more efficient. It unrolled loops for example.
It also arranged bytes in the registers in a very specific way, feeding it byte per byte and shifting the others.</p>
<p>But it obviously generated some SIMD instructions, as it noticed that our loop can be what's called "vectorized" : turned into vector instructions, aka SIMD.</p>
<p>Try to analyze the code until its end (not showed here), and you will see how clever the compiler was. The compiler knows every single instruction, it knows how costly it is. It can arrange so that it generates the best code for the dedicated target. Here are the details of every single optimization added in every level in GCC : <a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html"></a><a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html</a>.</p>
<p>O3 is the heaviest level, it turns on "tree-loop-vectorize", "tree-slp-vectorize". It also <a href="https://en.wikipedia.org/wiki/Loop_unswitching">unswitches loops</a>.</p>
<p>By default, only O2 is used, because it is known that O3 could produce unexpected behaviors due to too aggressive optimizations. Should you know that compilers also have bugs, and <a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug">so CPUs do</a>. It can happen that the generated code bugs, or behaves unexpectedly, even in 2016.
I've never met the case myself, but we recently spoted a bug in GCC 4.9.2 that affects PHP with -O2, and I remember also <a href="http://www.exploringbinary.com/why-volatile-fixes-the-2-2250738585072011e-308-bug/">a bug in FPU management</a> in the past.</p>
<p>Take PHP as an example. Compile it with no optimizations -O0, and run a benchmark. Then compare against -O2 and -O3, the benchmark should melt as aggressive optimizations kick in.</p>
<p>However, -O2 does not activate auto-vectorization. So in theory, with -O2, GCC should not generate any SIMD. Depending on your Linux distributions, many packages may be only compiled as -O2. Many Linux flavors including Debian and clones mainly compile with -O2, and very rarely with -O3. Gentoo being the distribution known for optimizations where you compile yourself each piece of software with your own compiler flags. Also, some commercial Linux distributions may distribute highly compilation-optimized programs for the hardware they usually sell with ? IBM, Oracle and others do that.</p>
<p>And you are still free to compile from sources, and use -O3 or -O2 with some special flags of yours. I tend to use -march=native to produce an even more specialized code, even more performant, but way less portable. It can also become unstable, make your tests before production and prepare for some surprises.</p>
<p>Remember GCC documentation is online, and there exists also other compilers, like LLVM stack or ICC (from Intel). <a href="http://gcc.godbolt.org/"></a><a href="http://gcc.godbolt.org">http://gcc.godbolt.org</a> allows you to test all the three of them, online, in a very cool interface. Intel compiler is obviously known to generate the best code for Intel processors. They always step forward as they are the manufacturers ;-) But GCC and LLVM tend to catch up quickly, still you may get your own idea by testing different compilers, different scenarios and different code bases.</p>
<p>You are free, as you work with free softwares. Never forget it : no-one will drive you.</p>
<p>You don't "buy a super commercial program you don't know how its been compiled and if you disassemble it you'll get thrown to jail as this is a forbidden operation in most countires". Do you really do ? Ouch !</p>
<h2 id="php">PHP ?<a href="#php" class="anchor">#</a></h2>
<p>What about PHP here ?</p>
<p>No secret : We don't code PHP in assembly. We fully rely on the compiler to generate the code because like every C program, we want it to be portable under different architectures and OS.</p>
<p>However, we try to use well known tips so that the compiler generates more efficient code :</p>
<ul><li>A lot of data structure in PHP are aligned. The memory manager, that performs heap allocations, always align the buffer you ask for. <a href="http://lxr.php.net/xref/PHP-7.0/Zend/zend_alloc.h#31">See here</a></li>
<li>We make use of <a href="http://man7.org/linux/man-pages/man3/alloca.3.html">alloca()</a>, where it outperforms the heap only. We have our <a href="http://lxr.php.net/xref/PHP-7.0/main/alloca.c">own emulation</a> also, for pretty old systems that don't support alloca().</li>
<li>We use some GCC builtins. The most classical ones, like __builtin_alloca(), __builtin_expect() or __builtin_clz() and friends.</li>
<li>We hint the compiler about register usage for the Zend Virtual Machine main handlers. <a href="http://lxr.php.net/source/xref/PHP-7.0/Zend/zend_execute.c#2634">Look here</a></li>
</ul><p>We don't use JIT into PHP (not developped yet). Still planed though. JIT - to be clear - is a way of generating assembly "on the fly", as some machine instructions are running. JIT improves performances of software virtual machines like the PHP one (Zend), but it only improves repeated computable patterns. The more you have repeated low level patterns, the more JIT shows power. As a PHP program nowadays consists of many PHP instructions of different kinds, JIT will only optimize the heavy processes that treat amounts of data per second, for a long time. This is not the default PHP behavior, where PHP treats a request as fast as possible and delegates "heavy" tasks to other processes (async). So I bet PHP would benefit from JIT, but by its nature not as many as Java for example, does. At least not as a web technology, but when used as CLI. CLI scripts will see a massive improvement, but not Web PHP.</p>
<p>Also in PHP development, we rarely look at generated assembly, because that is the way things are done today ! But, it happens sometimes we look at it, especially when we meet an "unexpected behavior" which clearly is not a C one (C is known for that). That means probably a compiler bug and we then have a look at it.</p>
<p>Now, how could I forget about <a href="https://github.com/krakjoe/SIMD">Joe's PHP SIMD extension</a>. Don't rush : this is a POC, but a nice POC.</p>
<p>I myself got many ideas as PHP extension dedicated to SIMD. I would like, for example, to port some parts of <a href="https://github.com/markrogoyski/math-php">such a Github project "math-php"</a> into C, and SIMD. I have some ideas of a PHP extension to publish structures that would allow a PHP user to use SIMD for Linear Algebra. Would this allow one to build a full video game using the PHP language ? Could be, but Oh Nohhhh.</p>
<h1 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h1>
<p>What can we conclude ?</p>
<p>We started building a simple C demo program. We saw that compiling it with zero optimizations led to a very understandable and GDB friendly assembly code, but awfully inefficient. We noticed that GCC's default level 2 optimizations don't activate auto-vectorization and thus should not generate SIMD instructions. Then with -O3, GCC beated us, it beated our own SIMD implementation and gave some better results.</p>
<p>We saw also that our SIMD implementation was just a POC (Proof Of Concept). We could have used AVX, and some other registers to improve performances even more. We also could have <code>mmap()</code>ed our file access, but that wouldn't have changed anything on modern Kernels.</p>
<p>When writing some C, you let your compiler do the job because it is better than you, just accept it. In some specific cases, you can take hand and write yourself the assembly you want, directly or by using Intel intrinsics API like we did. Also every compiler accept "extensions" from the C language some allowing to hint about the code one want to see generated. <a href="https://gcc.gnu.org/onlinedocs/gcc/C-Extensions.html">GCC extensions are listed here</a>.</p>
<p>Intel intrinsics are what they are. Some people appreciate them, some others prefer writing the assembly directly by hand and think that's an easier step. Obviously once you're used to assembly languages, that's an advice. It is not hard to write some assembly instructions into a C program, every C compiler allows that, or you can also benefit from the compilation unit and write one file of your project in assembly, others in C. Kernels do that for example.</p>
<p>C is a really cool language. It is old and has very little changed in 45 years, proving its robustness and proving that the hardware is really based on very solid fundations. C language has "competitors", like Fortran or others; but we are in a 90/10 percent market share. C builds all the low level systems we rely on today.
CPUs have always fascinated me. I started high school courses discovering them back in 1999, and discovered the C language back in 2000. Pretty late in history.</p>
<blockquote>
<p>The C language is used to build all the low level systems we rely on today.</p>
</blockquote>
<p>Now I mainly work in a Web environment, a little bit far from all that but... I'm happy when I read source codes here and there, that everything hasn't "changed" since I first learnt computer sciences.
Yes we now use more threads, we have several CPU cores and other problems like NUMA have appeared but ... a CPU still treats data the same it did before, simply the absolutely crazy talented Intel and AMD engineers managed to push the limits following Moore Law : we now can play with very specialized instructions, acting on so many data at the same time. Don't fear the price of a CPU, as CPUs concentrate a big part of the humanity knowledge in sciences, in general.</p>
<p>I look forward in the next Intel CPU generations, and I could start discovering other platforms like the exciting ARM as well.</p>
<p>I wrote this blog post, because today I meet many talented people, that <em>totally</em> ignore all that's written here in this article. That hurts me. That makes me think those people are really missing a big part of the cake. Do they even realize that ? I don't blame, but prefer then sharing my knowledge and showing how things work at the very low level of computation - without crossing the complex electronics barrer (That's another domain I know a lot about as well !).</p>
<p>As a high level language user, never forget that you build on top of millions of C lines, and billions of CPU instructions. Never forget that a problem you may meet at high level layers, could find a solution in the low level ones. A CPU doesn't lie, it is a pure deterministic finite automaton, it cannot lie as soon as it is not buggued, and it evolves in the right environment. It is pretty idiot as it performs so easy things and little steps, but at a speed and way of computing informations so high from what your human brain can do... That will continue fascinating me for years !</p>
<p><a href="http://www.polyhedron.com/web_images/intel/productbriefs/3a_SIMD.pdf">Intel : The significance of SIMD, SSE and AVX</a></p>
<p><a href="http://www.nasm.us/">NASM</a></p>
<p><a href="https://gcc.gnu.org/onlinedocs/gcc-4.9.2/gcc/i386-and-x86-64-Options.html#i386-and-x86-64-Options">GCC SIMD switches</a></p>
<p><a href="http://gcc.godbolt.org/">Online JS based X86 compilers</a></p>
<p><a href="https://www.arm.com/products/processors/instruction-set-architectures/index.php">ARM Processor Architecture</a></p>
<p><a href="https://www.amazon.com/Modern-X86-Assembly-Language-Programming/dp/1484200659">Modern X86 Assembly Language Programming: 32-bit, 64-bit, SSE, and AVX</a></p>
<p><a href="http://ref.x86asm.net/index.html">X86 Opcode and Instruction Reference</a></p>
<p><a href="https://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811">Dragon Book</a></p>
<p><a href="http://git.videolan.org/?p=x264.git;a=tree;f=common/x86;h=844b5cdfe4326c51783a74b06c37c334e4d7dfd8;hb=HEAD">X264 Assembly with SIMD</a></p>
<p><a href="http://lame.cvs.sourceforge.net/viewvc/lame/lame/libmp3lame/vector/xmm_quantize_sub.c?revision=1.10&view=markup">LAME MP3 quantizer SIMD</a></p>
<p><a href="http://nullprogram.com/blog/2015/07/10/">Mandelbrot Set with SIMD Intrinsics</a></p>
<p><a href="https://github.com/dherman/asm.js/">ASM.js</a></p>
<p><a href="https://github.com/krakjoe/SIMD">Joe's PHP SIMD</a></p>]]></content>
    </entry>
        <entry>
        <title>PHP 7 magic function call trampoline</title>
                <id>http://jpauli.github.io//2016/09/16/php-7-magic-function-call-trampoline.html</id>
                <updated>2016-09-16T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2016/09/16/php-7-magic-function-call-trampoline.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>This article will detail an optimization that's been added to PHP 7 virtual machine executor (Zend VM). We'll get back a minute into theorical concepts about function call trampolines, then we'll detail how those work into PHP 7.
It is better - if you want to fully understand - to have a nice overview on how the Zend VM works. I suggest you <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">follow this article</a> which details the internals of PHP 5 VM. Here, we'll talk about PHP 7. Although PHP 7 VM has been reworked, it barely works the same way as PHP 5's ; so understanding PHP 5's VM is a huge step forward to understand PHP 7's one.</p>
<h2 id="it-s-all-about-recursion">It's all about recursion<a href="#it-s-all-about-recursion" class="anchor">#</a></h2>
<p>If you've never heard about a trampoline, chances are you've never touched languages such as Haskell or Scala. Even not touching such languages, function call trampolines is a programmer trick usually learnt in deep-level programming courses. The goal of a trampoline is to prevent recursion in function calls. This is the theory mainline; there exists many ways of implementing such a mechanism in programs.</p>
<p>You know about recursion. If you don't, I suggest you start by learning what recursion is... Easy one ;-).
So, let's start by a quick and simple example :</p>
<pre><code>function factorial($n)
{
    if ($n == 1) {
        return $n;
    }
    return $n * factorial($n-1);
}</code></pre>
<p>Yeah, everyone knows about this function. The factorial function is the easiest one to understand recursion. It got very few instructions, and above all : it calls itself.</p>
<p>You know that every time a function is called, many things happen. At the low level, the compiler must use a <a href="https://en.wikipedia.org/wiki/Calling_convention">function calling convention</a> to prepare such a call. Basically, it will push on the stack the arguments and the return address; then issue a <em>CALL</em> Opcode, branching the CPU into the first instruction of the function body. When this latter terminates, a <em>RETURN</em> is used (or generated by the compiler if none was found into the function body), telling the CPU to get rid of the arguments stack (resets the stack pointer) and get back to return address. Nice.</p>
<p>Low level recursion is not very disturbing, because at low level the CPU is pretty fast and the code well optimized. Under X86_64 Linux, the stack is nearly not used anymore, as many parameters are passed using CPU registers directly. Also, the stack is a contiguous piece of memory which will be prefetched and loaded into CPU caches, and thus accessing the stack space is very very fast.</p>
<p>However, when it comes to play with high level languages like PHP, things are pretty different. We use a virtual machine in high level languages, that means that we have to write ourselves a stack, a stack management etc... we have to virtualize those concepts as obviously high level languages are not low level languages, and thus can't benefit from the low level speed.</p>
<p>In a word, recursion in not that of a problem in low level (C or assembly), but becomes one in high level virtual-machine-based languages like PHP, where we would thus like to avoid it as much as possible.</p>
<h3 id="preventing-recursion">Preventing recursion<a href="#preventing-recursion" class="anchor">#</a></h3>
<p>There exists several ways to prevent recursion in function calls. We'll use the PHP language to study simple ones and a more generic one using what's called a trampoline function. We'll then get back to PHP sources to explain how those concepts have been added into PHP 7 heart.</p>
<h4 id="tail-call-functions-and-loops">Tail-call functions and loops<a href="#tail-call-functions-and-loops" class="anchor">#</a></h4>
<p>A recursion is a kind of loop : 'as long as XXX, call myself'. That's a sort of loop, and thus a recursive function can be rewritten using a loop (sometimes more than one), without calling itself anywhere.
Be warned however that such an exercise is not easy, depending on your function, how many times it calls back itself, and how it does so.</p>
<p>Fortunately, the factorial function is really easy to "un-recurse". There exists theoretical ways to do that, we'll use the tail-call tranformation to achieve that.
The factorial function can be unrolled by turning it into a tail-call recurse function, and applying some theorem. Let's turn it into a tail-call function first :</p>
<pre><code>function tail_factorial($n, $acc = 1)
{
    if ($n == 1) {
        return $acc;
    }
    return tail_factorial($n-1, $n * $acc);
}</code></pre>
<p>We use what's called an accumulator to perform that. The goal is to end having a tail-call function.
As a reminder, a tail-call function is a function in where it comes to return itself, does return itself alone, with no other operation. That is the return statement is passed <strong>only</strong> the recursion call with no other operation at all. It must be single-instruction reentrant. That way a compiler can optimize the last call, because the function returns the return of itself, hence it can simplify the stack creation by simply reusing the current stack frame for the last call instead of creating a new one.</p>
<blockquote>
<p>Tail Call optimization is a very old compiler optimization trick, used in many compilers. If you are interested in the subject, I suggest books, like <a href="https://www.amazon.com/Advanced-Compiler-Design-Implementation-Muchnick-ebook/dp/B003VM7GGK/">Advanced Compiler Design and Implementation</a> for example.</p>
</blockquote>
<p>Also, we may now transform this tail-call function whose body simply represents a loop. What we need to do instead of calling back ourselves with changed arguments, is to jump back on the top of the function (like a recurse call would have done), but in between change the arguments, so that the next loop will run with the right argument values (what a recursive function does). That gives :</p>
<pre><code>function unrolled_factorial($n)
{
    $acc = 1;
    while ($n > 1) {
        $acc *= $n--;
    }
    return $acc;
}</code></pre>
<p>This function does the exact same as the original <code>factorial()</code> function, but it does not call itself anymore. It is way more performant that the recursive alternative at runtime.</p>
<p>We also could have used a goto branch :</p>
<pre><code>function goto_factorial($n)
{
    $acc = 1;
f:
    if ($n == 1) {
        return $acc;
    }
    $acc *= $n--;
    goto f;
}</code></pre>
<p>This is exactly the same : no more recursion.</p>
<p>Try it. Try to run <code>factorial()</code> with a huge number : you'll run out of stack space and hit a memory limit of the engine (as the stack frames into the VM are allocated on the heap). If you disable the limit (<em>memory_limit</em>), then PHP will crash because you may know that PHP and the Zend VM have absolutely no guard against infinite recursion, hence the process crashes.
Now with the same argument try to run the unrolled one, <code>unrolled_factorial()</code> or even the <code>goto_factorial()</code>. It will not crash. Eventually it could take time to run, but won't crash, won't exhaust the stack space (heap allocated in PHP) and will run way faster than the recursive one.</p>
<h4 id="trampoline-controlling-tail-call-functions">Trampoline controlling tail-call functions<a href="#trampoline-controlling-tail-call-functions" class="anchor">#</a></h4>
<p>However, it happens that sometimes it is not that easy to unrecurse a function. Factorial is the simplest example, but some other are not.
Think about a function calling itself at different places, with different conditions, etc... (like a simple <code>bsearch()</code> implementation f.e).</p>
<p>In such cases, we may need to use what's called a <a href="https://en.wikipedia.org/wiki/Trampoline_(computing)">function trampoline</a> to master the recursion. The base recursive function will need to be rewritten (like when we un-recurse it), but it can keep the calls to itself this time. Simply, we will decorate such calls, and call base recursive function using a trampoline instead of invocating it directly.
That way, the recursion will be unrolled by having a control flow (a trampoline) mastering each call of our subject. There is no more need to deeply think about how to un-recurse such a complex function, simply wrap it, and don't launch it by itself but instead, launch it through some control code, called a trampoline.</p>
<p>Let's see an example of that using the PHP language. The idea is to transform our function, so that its caller can detect when it recurses, or when it leaves.
If it performs a recursive call to itself, the trampoline will control its stack by becoming its callee. If it returns its result, the trampoline should notice it and stop.</p>
<p>Like this :</p>
<pre><code>function trampo_factorial($n, $acc = 1)
{
    if ($n == 1) {
        return $acc;
    }
    return function() use ($n, $acc) { return trampo_factorial($n-1, $n * $acc); };
}</code></pre>
<p>You see here that this function still calls itself. However, it doesn't directly call itself, but it wraps its recursive call into a closure.
This is because now we won't launch our recursive function directly, but using a trampoline. When the trampoline sees a closure returned : it launches it, when it sees a non-closure, it returns; hence the "trampoline" wording.</p>
<pre><code>function trampoline(callable $c, ...$args)
{
    while (is_callable($c)) { $c = $c(...$args); } return $c;
}</code></pre>
<p>And we are done.
Use it like this :</p>
<pre><code>echo trampoline('trampo_factorial', 42);</code></pre>
<p>The trampoline is a generic solution to recursion. If you can't refactor your function to eliminate recursive calls, then tranform it to a tail-call function that can be launched through a trampoline. Of course, trampoline only works with tail-call functions, how could it be otherwise ?</p>
<p>With a trampoline in action, this one will take some callables and launch them as often as needed, preventing those callables from calling themselves recursively, the trampoline being the callee.
Here again, we solved the recursion problem, in a much more generic way that can be applied to every recursive function.</p>
<p>Be warned however that I used the PHP language here for you to understand the concepts (as I guess you use PHP often if you read those lines ?). But, I would not recommand creating trampolines in PHP, PHP is a high level language and such constructs shouldn't be needed to PHP developpers in their daily jobs. You may not need that much of recursive functions using PHP, and having a loop with an <code>is_callable()</code> call into it is not that light.</p>
<p>However, lets now dive into the PHP engine and see how trampolines have been implemented to prevent stack recursion into the main PHP VM dispatch loop.</p>
<h3 id="recursion-in-the-zend-vm-executor">Recursion in the Zend VM Executor<a href="#recursion-in-the-zend-vm-executor" class="anchor">#</a></h3>
<p>So, let's go !
I hope you remember about the <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html#a-giant-loop">dispatch loop</a> of the executor right ?</p>
<p>Let me refresh your mind.
Any virtual machine is built on the same big principles, among what the "dispatch loop".
An infinite loop is run, and at every step, one single VM instruction (<code>opline</code>) is run (<code>handler()</code>). Into this instruction, many things can happen, but at the end of each instruction is a command to the loop, usually "goto next instruction". It could also be "return from the infinite loop", or "jump to this operation".</p>
<p>The engine VM default dispatch loop is stored into the <code>execute_ex()</code> function.
Here it is, as a reminder, but for PHP 7, and with the optimizations related to my machine (IP and FP registers used) :</p>
<pre><code>#define ZEND_VM_FP_GLOBAL_REG "%r14"
#define ZEND_VM_IP_GLOBAL_REG "%r15"

register zend_execute_data* volatile execute_data __asm__(ZEND_VM_FP_GLOBAL_REG);
register const zend_op* volatile opline __asm__(ZEND_VM_IP_GLOBAL_REG);

ZEND_API void execute_ex(zend_execute_data *ex)
{
    const zend_op *orig_opline           = opline;
    zend_execute_data *orig_execute_data = execute_data;
    execute_data                         = ex;
    opline                               = execute_data->opline;
    while (1) {
        opline->handler();
        if (UNEXPECTED(!opline)) {
            execute_data = orig_execute_data;
            opline       = orig_opline;
            return;
        }
    }
    zend_error_noreturn(E_CORE_ERROR, "Arrived at end of main loop which shouldn't happen");
}</code></pre>
<p>So you can notice the <code>while(1)</code> structure. What about recursion ? What's the matter ?</p>
<p>Well it is easy to spot. You run the <code>while(1)</code> loop, as part of the <code>execute_ex()</code> function. What happens if one instruction in there (<code>opline->handler()</code>) runs itself <code>execute_ex()</code> ? Well we are in a recursion case. Is it bad ? Well as usual : yes, if many levels of recursion happen to stack up.</p>
<p>In which case <code>execute_ex()</code> calls <code>execute_ex()</code> ? I can't go too deep into the VM engine here because you may miss many important informations to fully understand, but we could think that a PHP function call, calls for <code>execute_ex()</code>. It is the case.</p>
<p>Any time you perform a PHP function call, it creates a new stack frame at the C level, and runs a new version of the dispatch loop by re-entring into a new <code>execute_ex()</code> call, with new instructions to be run. When that loop exits, that is when the PHP function call ends, it leads to the "return" case in the code, and thus it ends the current loop of the current frame onto the stack, resuming the preceding one.
Take care however, this happens only for userland PHP functions. Because user-defined PHP functions are OPCodes to be run into the loop when launched. But, internal PHP functions (PHP functions designed in C, into the core or into PHP extensions) do not need to run opcodes, they are plain C instructions, thus they don't create another dispatch loop and another frame.</p>
<h3 id="the-call-use-case">The __call() use case<a href="#the-call-use-case" class="anchor">#</a></h3>
<p>Now I will explain you the <code>__call()</code> use case. What is <code>__call()</code> ? A userland PHP function. So ? So when it is run, it will lead to a new <code>execute_ex()</code> call, like any userland PHP function.
The specific problem of <code>__call()</code> is that is may be called many times, stacking up a lot of frames into the engine. Any time an unknown method is called on an object with an <code>__call()</code> defined in its class.</p>
<p>As of PHP 7, the engine has been optimized with the addition of a trampoline mastering <code>__call()</code> calls, and preventing recursive calls to <code>execute_ex()</code> in the <code>__call()</code> use-case.</p>
<p>This is <code>__call()</code>'s stack in PHP 5.6 :</p>
<p><img src="../../../img/php7-call-trampoline/56-call-stack.png" alt="php5-__call-stack"></p>
<p>If you count the number of <code>execute_ex()</code> calls, you will see 3 of them. It is taken from a PHP script which invokes an unknown method on an object itself calling an unknown method on another object (whose classes obviously both contain <code>__call()</code>s. So, the first <code>execute_ex()</code> is the main script execution (position 6 in the call stack), and then on top of it we can count 2 other calls to <code>execute_ex()</code>.</p>
<p>Now, the same script run under PHP 7 :</p>
<p><img src="../../../img/php7-call-trampoline/70-call-stack.png" alt="php7-__call-stack"></p>
<p>The difference is obvious : the stack frame is much more thin, and there is only one call to <code>execute_ex()</code>, that is there is only one dispatch loop, dispatching every instruction including <code>__call()</code> calls.</p>
<h3 id="turning-call-calls-to-trampoline-calls">Turning __call() calls to trampoline calls<a href="#turning-call-calls-to-trampoline-calls" class="anchor">#</a></h3>
<p>In PHP 5, we used to call <code>execute_ex()</code> in <code>__call()</code> context. That is, we prepare a new dispatch loop to run the currently asked <code>__call()</code> OPCodes. But the method run, was the method called, for example <code>fooBarDontExist()</code>, so we had to fake its name as well. We had to allocate some structures, and perform a classic userland function call. Something like that (simplified) :</p>
<pre><code>ZEND_API void zend_std_call_user_call(INTERNAL_FUNCTION_PARAMETERS)
{
    zend_internal_function *func = (zend_internal_function *)EG(current_execute_data)->function_state.function;
    zval *method_name_ptr, *method_args_ptr;
    zval *method_result_ptr = NULL;
    zend_class_entry *ce = Z_OBJCE_P(this_ptr);

    ALLOC_ZVAL(method_args_ptr);
    INIT_PZVAL(method_args_ptr);
    array_init_size(method_args_ptr, ZEND_NUM_ARGS());
    /* ... ... */
    ALLOC_ZVAL(method_name_ptr);
    INIT_PZVAL(method_name_ptr);
    ZVAL_STRING(method_name_ptr, func->function_name, 0); /* Copy function name */

    /* Perform a new dispatch loop call : this will call execute_ex() */
    zend_call_method_with_2_params(&this_ptr, ce, &ce->__call, ZEND_CALL_FUNC_NAME, &method_result_ptr, method_name_ptr, method_args_ptr);

    if (method_result_ptr) {
        RETVAL_ZVAL_FAST(method_result_ptr);
        zval_ptr_dtor(&method_result_ptr);
    }

    zval_ptr_dtor(&method_args_ptr);
    zval_ptr_dtor(&method_name_ptr);

    efree(func);
}</code></pre>
<p>This used to be a lot of work to perform such calls. That is why we used to hear "try to avoid using __call() for performance reasons" (among other reasons). This wasn't false.</p>
<p>Now in PHP 7. Remember the trampoline theory ? It will be more or less the same here.
What we want to avoid is recursively calling <code>execute_ex()</code>. To avoid that, we must un-recurse that, that is we must stay in the same <code>execute_ex()</code> context, and rebranch from it to its top, changing the arguments needed. Let's see that <code>execute_ex()</code> again :</p>
<pre><code>ZEND_API void execute_ex(zend_execute_data *ex)
{
    const zend_op *orig_opline           = opline;
    zend_execute_data *orig_execute_data = execute_data;
    execute_data                         = ex;
    opline                               = execute_data->opline;
    while (1) {
        opline->handler();
        if (UNEXPECTED(!opline)) {
            execute_data = orig_execute_data;
            opline       = orig_opline;
            return;
        }
    }
    zend_error_noreturn(E_CORE_ERROR, "Arrived at end of main loop which shouldn't happen");
}</code></pre>
<p>So, the variables we need to change to prevent recursion calls are at least <code>opline</code>, and also <code>execute_data</code> (which contains the next OPCodes, opline is the "current" OPCode to run).
Hence, once <code>__call()</code> is met, we change <code>opline</code> and <code>execute_data</code>, then we return, we return back to the <strong>current</strong> dispatch loop, make it continue to our freshly changed new OPCodes, and at the end make it return to where it was (this is why we have also <code>orig_opline</code> and <code>orig_execute_data</code> ; a virtual machine dispatcher should always remember where it comes from so that it can branch back to here from anywhere).</p>
<p>Well, this is exactly what the new <code>ZEND_CALL_TRAMPOLINE</code> OPCode does. This new PHP 7 OPCode is used anywhere <code>__call()</code> calls must be performed.
Let's have a look at a simplified version :</p>
<pre><code>#define ZEND_VM_ENTER() execute_data = (executor_globals.current_execute_data); opline = ((execute_data)->opline); return
static ZEND_OPCODE_HANDLER_RET ZEND_FASTCALL ZEND_CALL_TRAMPOLINE_SPEC_HANDLER(ZEND_OPCODE_HANDLER_ARGS)
{
    zend_array *args;
    zend_function *fbc = EX(func);
    zval *ret = EX(return_value);
    uint32_t call_info = EX_CALL_INFO() & (ZEND_CALL_NESTED | ZEND_CALL_TOP | ZEND_CALL_RELEASE_THIS);
    uint32_t num_args = EX_NUM_ARGS();
    zend_execute_data *call;

    /* ... */

    SAVE_OPLINE();
    call = execute_data;
    execute_data = EG(current_execute_data) = EX(prev_execute_data);

    /* ... */

    if (EXPECTED(fbc->type == ZEND_USER_FUNCTION)) {
        call->symbol_table = NULL;
        i_init_func_execute_data(call, &fbc->op_array,
                ret, (fbc->common.fn_flags & ZEND_ACC_STATIC) == 0);
        if (EXPECTED(zend_execute_ex == execute_ex)) {
            ZEND_VM_ENTER();
        }
    /* ... */</code></pre>
<p>We can spot here that the <code>execute_data</code> and <code>opline</code> variables are effectively changed, by the <code>ZEND_VM_ENTER()</code> macro.
The next <code>execute_data</code> are prepared in the <code>call</code> variable, and the function <code>i_init_func_execute_data()</code> bind them. Then, a new turn of the current dispatch loop is performed with <code>ZEND_VM_ENTER()</code> which switches the variables for the next loop, and instruct to enter into it with a "return" (of the current loop).</p>
<p>The circle is complete, we are done.</p>
<p>How to reach back the main loop then ? Well this is done in the <code>ZEND_RETURN</code> OPCode which ends every user-defined function call whatever it is.</p>
<pre><code>#define LOAD_NEXT_OPLINE() opline = ((execute_data)->opline) + 1
#define ZEND_VM_LEAVE() return

static ZEND_OPCODE_HANDLER_RET ZEND_FASTCALL zend_leave_helper_SPEC(ZEND_OPCODE_HANDLER_ARGS)
{
    zend_execute_data *old_execute_data;
    uint32_t call_info = EX_CALL_INFO();

    if (EXPECTED(ZEND_CALL_KIND_EX(call_info) == ZEND_CALL_NESTED_FUNCTION)) {
        zend_object *object;

        i_free_compiled_variables(execute_data);
        if (UNEXPECTED(EX(symbol_table) != NULL)) {
            zend_clean_and_cache_symbol_table(EX(symbol_table));
        }
        zend_vm_stack_free_extra_args_ex(call_info, execute_data);

        old_execute_data = execute_data;
        execute_data = EG(current_execute_data) = EX(prev_execute_data);

        /* ... */

        LOAD_NEXT_OPLINE();
        ZEND_VM_LEAVE();
    }
    /* ... */</code></pre>
<p>Like we can see, on returning from a user-defined function call, we hit a <code>ZEND_RETURN</code> which replaces the next-to-be-run instructions by the previous ones, from the previous call : <code>prev_execute_data</code>. It then loads the opline, and returns to the main dispatch loop.</p>
<h3 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h3>
<p>We've detailed the theory which resides behind the unrolling of recursive function calls. Any recursive call can be flatten, but it may happen to be very hard to do. A more generic solution is to design a trampoline : a system that takes care of launching every step of a recursive function, preventing that letter from calling itself and thus blowing up the stack frame.
Some code, known as the trampoline code, sits in place of the dispatcher and plays with it to prevent recursion to happen.</p>
<p>We've seen a generic implementation in PHP, and also how trampolines have been implemented into the new Zend Engine 3, part of PHP 7.
Do no fear <code>__call()</code> calls anymore in PHP 7, they are faster than PHP 5's, they don't create a new stack frame (at the C level) on every call, and are part of many improvements added to the PHP 7 engine.</p>]]></content>
    </entry>
        <entry>
        <title>PHP 7 Arrays : HashTables</title>
                <id>http://jpauli.github.io//2016/04/08/hashtables.html</id>
                <updated>2016-04-08T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2016/04/08/hashtables.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>HashTables are used everywhere, in every C strong program. Basically, they allow the programmer to store values into an "array" by indexing this latter using strings, whereas the C language only allow integers as C-array keys. A hashtable structure is then built, the string key is hashed and reduced to the hashtable size space. Collisions may then happen, thus a collision resolution algorithm must be used. Several of them exist, PHP chose the linked-list strategy.</p>
<p>If you want to know more about hashtables and their different implementations, you can find great articles about them on the Web as they are a very commonly used structure. <a href="http://preshing.com/"></a><a href="http://preshing.com/">http://preshing.com/</a> is a good start, with lots of detailed articles. Be warned however, there exists tons of ways to design hashtables, none is perfect, all those strategies are tradeoff : wether they optimize CPU cycles, memory footprint, or they scale well in threaded environment... Some are better at insertion, others at finding and probing etc...
Depending on the factor you want to push, you'll end up with very different HashTables implementations.</p>
<blockquote>
<p>There exists many ways to design HashTables, depending on what factor you want to promote.</p>
</blockquote>
<p>PHP 5 Hashtables are detailed in <a href="http://www.phpinternalsbook.com/hashtables/basic_structure.html">phpinteralsbook</a> I wrote together with <a href="http://nikic.github.io">Nikic</a>, who himself <a href="http://nikic.github.io/2014/12/22/PHPs-new-hashtable-implementation.html">wrote a nice PHP 7 HashTable article</a> you may find interesting (dating from before PHP 7 release, some little things changed).</p>
<p>This article will detail how hashtables have been designed <strong>in PHP 7</strong>, how you can deal with them from the C point of view and how you can manipulate them using the PHP language (using the so-called PHP <em>"array"</em> structure). The source code is available in <a href="http://lxr.php.net/xref/PHP_7_0/Zend/zend_hash.c">zend_hash.c</a> mainly.
Remember that into PHP 7 source code, we use hashtables everywhere (mainly as dictionnaries), thus we may design them so that they are fast in term of CPU usage and have a good memory footprint. This is a critical structure in PHP's overall performances (the most critical one IMO), as PHP arrays are really not the only place where such a structure is used.</p>
<h2 id="hashtable-layout">HashTable Layout<a href="#hashtable-layout" class="anchor">#</a></h2>
<p>Here are some statements, we'll detail them through the article :</p>
<ul><li>The key may be an integer or a string. If a string is used, a <code>zend_string</code> structure is used, for ints : a <code>zend_ulong</code> (which in a platform unsigned extended long).</li>
<li>The hashtable must always remember the order the elements are inserted.</li>
<li>The hashtable is auto-resizable, that is it auto-grows when needed and can shrink under some circumstances.</li>
<li>Internally, the table size is always a power of two, for performance point and memory alignment purpose.</li>
<li>Any value stored into the hashtable is stored into a <code>zval</code> structure, it can't be anything else. <code>zval</code>s can embed any type of data.</li>
</ul><p>Let's go for the <code>HashTable</code> structure :</p>
<pre><code>struct _zend_array {
    zend_refcounted_h gc;
    union {
        struct {
            ZEND_ENDIAN_LOHI_4(
                zend_uchar    flags,
                zend_uchar    nApplyCount,
                zend_uchar    nIteratorsCount,
                zend_uchar    reserve)
        } v;
        uint32_t flags;           /* 32 available flags */
    } u;
    uint32_t     nTableMask;       /* mask is -nTableSize */
    Bucket      *arData;           /* useful data storage */
    uint32_t     nNumUsed;         /* next slot available in arData */
    uint32_t     nNumOfElements;   /* total num of busy elements in arData */
    uint32_t     nTableSize;       /* table size, always a power of two */
    uint32_t     nInternalPointer; /* Used for iteration */
    zend_long    nNextFreeElement; /* next integer-based key available */
    dtor_func_t  pDestructor;      /* data destructor */
};</code></pre>
<p>Some fields are rarely used, and we won't talk about them but about the real load.</p>
<p>This structure weights <strong>56 bytes</strong> (under LP64).</p>
<p>The main interesting data field is <code>arData</code>, it is of type pointer to a <code>Bucket</code> chain memory area. A <code>Bucket</code> is one slot into the array :</p>
<pre><code>typedef struct _Bucket {
    zval              val; /* value */
    zend_ulong        h;   /* hash value (or numeric index)   */
    zend_string      *key; /* string key or NULL for numerics */
} Bucket;</code></pre>
<p>You may spot that into the <code>Bucket</code> structure will be stored the <code>zval</code> which represents the PHP useful value. Notice that we don't use a pointer to a zval, but a <code>zval</code> structure itself : this is because in PHP 7, zvals are never heap allocated anymore (compared to PHP 5), but the target value may be heap allocated and stored as a pointer into the zval structure (a PHP string for example).</p>
<p>So let's go for a picture that details how things are stored into memory :</p>
<p><img src="../../../img/php7-hashtables/simple_hash.png" alt="simple_hash"></p>
<p>We see there that the data inserted into the hashtable is stored in a contiguous piece of memory : <code>arData</code></p>
<h3 id="adding-elements-while-keeping-the-order-of-things">Adding elements while keeping the order of things<a href="#adding-elements-while-keeping-the-order-of-things" class="anchor">#</a></h3>
<p>PHP must keep the order data are inserted into an array. When you <code>foreach()</code> an array in PHP, you get back data in the exact same order you inserted them  in the array. Whatever their key :</p>
<pre><code>$a = [9 => "foo", 2 => 42, []];
var_dump($a);

array(3) {
    [9]=>
    string(3) "foo"
    [2]=>
    int(42)
    [10]=>
    array(0) {
    }
}</code></pre>
<p>This fact is important, and it has pushed some constraints into how hashtables are implemented.
All the data are contiguous in memory, they are stored in <code>zval</code>s themselves packed into <code>Bucket</code>s allocated as the <code>arData</code> C-array field. Something like that :</p>
<pre><code>$a = [3 => 'foo', 8 => 'bar', 'baz' => []];</code></pre>
<p><img src="../../../img/php7-hashtables/simple_hash_data_1.png" alt="simple_hash_data"></p>
<p>Thus iterating over the hashtable is really easy, one must simply iterate over the <code>arData</code> C array, this is a contiguous memory scanning, which is very fast and very CPU cache friendly as the CPU cache line 1 may have loaded the full <code>arData</code>, accessing each cell in about one nanosecond. Note that <code>arData</code> is 64bits aligned to maximize CPU cache transfer and storage (as well as optimizing alignement over 64bit workload full instructions).
Some code to iterate over the hashtable could look like this :</p>
<pre><code>size_t i;
Bucket p;
zval val;

for (i=0; i < ht->nTableSize; i++) {
    p   = ht->arData[i];
    val = p.val;
    /* do something with val */
}</code></pre>
<p>Like you can see, things are ordered and pushed into the next slot of <code>arData</code>. To accomplish that, we simply keep in memory the next available slot into <code>arData</code>. It is kept in the <code>nNumUsed</code> field.</p>
<p>Everytime a new value is added, we store it at <em>ht->nNumUsed++</em> (notice the incrementation). When <code>nNumUsed</code> reaches the number of elements in the hashtable (<code>nNumOfElements</code>), we launch a "compact or grow" algorithm that is detailed later.</p>
<p>This is a simplified view of how elements are added to the hashtable, assuming a string key has been used :</p>
<pre><code>idx = ht->nNumUsed++; /* take the next avalaible slot number */
ht->nNumOfElements++; /* increment number of elements */
/* ... */
p = ht->arData + idx; /* Get the bucket in that slot from arData */
p->key = key; /* Affect it the key we want to insert at */
/* ... */
p->h = h = ZSTR_H(key); /* save the hash of the current key into the bucket */
ZVAL_COPY_VALUE(&p->val, pData); /* Copy the value into the bucket's value : add operation */</code></pre>
<p>So elements are added at the end of the <code>arData</code>. They are pushed, and middle "holes" (empty deleted slots) are not filled back. We'll detail that.</p>
<h3 id="deleting-values">Deleting values<a href="#deleting-values" class="anchor">#</a></h3>
<p>When a value is deleted, the <code>arData</code> C array is not narrowed nor are the data rearranged into it.
If we would do that for every item deletion, performances would drop drastically as we would keep moving memory areas for data reorganization.
What we do when we delete an item from the hashtable, is just flaging the corresponding <code>arData</code> slot by a special value that says "there is nothing in here". This value is an <em>UNDEF</em> <code>zval</code>.</p>
<p>Something like that :</p>
<p><img src="../../../img/php7-hashtables/hash_deletion_undef.png" alt="hash_deletion"></p>
<p>Hence, the iteration code must be reworked a little bit to take care of such possible "empty" holes :</p>
<pre><code>size_t i;
Bucket p;
zval val;

for (i=0; i < ht->nTableSize; i++) {
    p   = ht->arData[i];
    val = p.val;
    if (Z_TYPE(val) == IS_UNDEF) { /* empty hole ? */
        continue; /* skip it */
    }
    /* do something with val */
}</code></pre>
<p>We will see what happens when the hashtable must be resized, and how the <code>arData</code> C array may be reorganized to make "holes" dissapear (compaction).
Even with a very huge hashtable, iterating over it and skipping all possible deleted values (holes) is very fast because of the continuous piece of memory that represents the <code>arData</code> field scanning.</p>
<h3 id="hashing-string-based-keys">Hashing string-based keys<a href="#hashing-string-based-keys" class="anchor">#</a></h3>
<p>When we have a string-based key, we must hash it and reduce it, then make a translation from the hashed-reduced value, and the index into <code>arData</code>.
Even if the key is integer based, it will get reduced as well to fit the <code>arData</code> bounds.</p>
<p>Remember that we cant use the reduced value as-is to index directly the <code>arData</code> C array, because if we do so, that means that the keys used to index the <code>arData</code> are directly bound to the keys obtained from the hash, and that will break one feature of PHP hashtables : keep the order of things into the hashtable.</p>
<p>Example : if I insert something at key "foo", then at key "bar" , imagine key foo get hashed/reduced to the key 5, and for "bar", to the key 3.
If we store the "foo" data in <code>arData[5]</code> and the "bar" data into <code>arData[3]</code>, that means that the "bar" data comes <strong>before</strong> the "foo" data; and when we'll iterate over <code>arData</code> the elements won't show back in the same order they've been inserted...</p>
<p><img src="../../../img/php7-hashtables/direct_hash_wrong.png" alt="direct_hash_wrong"></p>
<p>So, when we hash and reduce the key, to obtain a key bound in the <code>arData</code> keyspace , we can't use it as-is (what we did in PHP 5). We must use another table that will do the translation for us. We'll call that table the <strong>translation table</strong> , it simply maps the hashed/reduced integer from the key, to an other integer usable to address the <code>arData</code> array.</p>
<p>There is a trick however : the translation table memory is cleverly stored <em>behind</em> the <code>arData</code> vector. That prevents us from using another memory area for such a translation table : it is allocated together along with the <code>arData</code>, and thus stays in the same address range, here again improving data locality.</p>
<p>The layout looks like this, for an 8-element hashtable (the minimum hashtable size actually) :</p>
<p><img src="../../../img/php7-hashtables/hash_layout.png" alt="hash_layout"></p>
<p>Now, when you come with the key "foo", this one is hashed through the DJB33X hash, and reduced using a modulo to the <code>arData</code> array size (<code>nTableMask</code>), so that the key now gives an index that can be used to probe the <code>arData</code> <strong>translation slots</strong> (not the direct slots like we said !).</p>
<p>Like you can see, those slots are accessed using a negative offset from <code>arData</code> starting point, just some C pointer maths are involved, and we keep our full workload into a contiguous space in memory.
The <code>nTableMask</code> is equal to minus the table size, thus when we modulo with it, we get a number from 0 to -7, and can probe our memory zone.
When we allocate the full <code>arData</code> buffer, we compute its size so that it is set of <em>tablesize * sizeof(bucket)</em> <strong>+</strong> <em>tablesize * sizeof(uint32)</em> translations slots.</p>
<p>This buffer division in two distinct areas is clearly visible in source :</p>
<pre><code>#define HT_HASH_SIZE(nTableMask) (((size_t)(uint32_t)-(int32_t)(nTableMask)) * sizeof(uint32_t))
#define HT_DATA_SIZE(nTableSize) ((size_t)(nTableSize) * sizeof(Bucket))
#define HT_SIZE_EX(nTableSize, nTableMask) (HT_DATA_SIZE((nTableSize)) + HT_HASH_SIZE((nTableMask)))
#define HT_SIZE(ht) HT_SIZE_EX((ht)->nTableSize, (ht)->nTableMask)

Bucket *arData;
arData = emalloc(HT_SIZE(ht)); /* now alloc this */</code></pre>
<p>Which gives when macros are resolved :</p>
<pre><code>(((size_t)(((ht)->nTableSize)) * sizeof(Bucket)) + (((size_t)(uint32_t)-(int32_t)(((ht)->nTableMask))) * sizeof(uint32_t)))</code></pre>
<p>Pretty nice.</p>
<h3 id="collisions-resolution">Collisions resolution<a href="#collisions-resolution" class="anchor">#</a></h3>
<p>Let's see how collisions are resolved. Remember that in a hashtable, several keys - when hashed and reduced - may lead to the same translation index (infinite place from, finite place to).
So what we do when we got a translation index, is that we use it to fetch back the data from <code>arData</code> (using translation slots) and we check this data is effectively the one we want by comparing the hashes and the keys. If the data is not the right one, we get through a linked list by using the <code>zval.u2.next</code> field , which indicates the next data slot to probe, etc...</p>
<p>Notice how the linked list is not sparsed in memory, like traditionnal linked lists are.
Instead of browsing several allocated pointers obtained from the heap - and thus very likely to be sparsed in memory address range - we keep reading the full <code>arData</code> vector from memory.</p>
<blockquote>
<p>This is a crucial point behind performance improvement in PHP 7 hashtable implementation, and in overall PHP 7 performances. Data locality has been hardly worked to reach that goal : do not make the CPU access main memory (slow operation) so often (compared to PHP 5, f.e). PHP 7 hashtable have a very strong data locality, many accesses are fetched from L1 CPU cache (about 1 nanosecond access time), as they very likely fit entirely into the L1 cache of your CPU.</p>
</blockquote>
<p>So now, let's see how we add an element to the hash, including managing the hash collisions :</p>
<pre><code>#define HT_HASH_EX(data, idx) ((uint32_t*)(data))[(int32_t)(idx)]
#define HT_HASH(ht, idx) HT_HASH_EX((ht)->arData, idx)
#define HT_IDX_TO_HASH(idx) (idx)

idx = ht->nNumUsed++; /* take the next avalaible slot number */
ht->nNumOfElements++; /* increment number of elements */
/* ... */
p = ht->arData + idx; /* Get the bucket in that slot from arData */
p->key = key; /* Affect it the key we want to insert at */
/* ... */
p->h = h = ZSTR_H(key); /* save the hash of the current key into the bucket */
ZVAL_COPY_VALUE(&p->val, pData); /* Copy the value into the bucket's value : add */

nIndex = h | ht->nTableMask; /* Get the translation table index */
Z_NEXT(p->val) = HT_HASH(ht, nIndex); /* Put the actual element as next of us */
HT_HASH(ht, nIndex) = HT_IDX_TO_HASH(idx); /* Put us into the actual translation slot */</code></pre>
<p>The same rules applies to deletion :</p>
<pre><code>#define HT_HASH_TO_BUCKET_EX(data, idx) ((data) + (idx))
#define HT_HASH_TO_BUCKET(ht, idx) HT_HASH_TO_BUCKET_EX((ht)->arData, idx)

h = zend_string_hash_val(key); /* get the hash from the key (assuming string key here) */
nIndex = h | ht->nTableMask; /* get the translation table index */

idx = HT_HASH(ht, nIndex); /* Get the slot corresponding to that translation index */
while (idx != HT_INVALID_IDX) { /* If there is a corresponding slot */
    p = HT_HASH_TO_BUCKET(ht, idx); /* Get the bucket from that slot */
    if ((p->key == key) || /* Is it the right bucket ? same key pointer ? */
        (p->h == h && /* ... or same hash */
         p->key && /* and a key (string key based) */
         ZSTR_LEN(p->key) == ZSTR_LEN(key) && /* and same key length */
         memcmp(ZSTR_VAL(p->key), ZSTR_VAL(key), ZSTR_LEN(key)) == 0)) { /* and same key content ? */
        _zend_hash_del_el_ex(ht, idx, p, prev); /* that's us ! delete us */
        return SUCCESS;
    }
    prev = p;
    idx = Z_NEXT(p->val); /* get the next corresponding slot from current one */
}
return FAILURE;</code></pre>
<h3 id="translation-slots-and-hash-initialization">Translation slots and hash initialization<a href="#translation-slots-and-hash-initialization" class="anchor">#</a></h3>
<p><code>HT_INVALID_IDX</code> is a special flag we put in translation table to say "that translation leads to no data, no need to continue".</p>
<p>The hashtable benefit from a two-step initialization, to reduce at maximum the impact of an empty-just-newly-born hashtable (pretty common use case in PHP).
When the table is first created, we create the <code>arData</code> bucket slots together with just two translation slots, and into them we place this
<code>HT_INVALID_IDX</code> flag. We then put the mask so that it will resolve into the first translation slot (leading to <code>HT_INVALID_IDX</code>, and then no data found here).</p>
<pre><code>#define HT_MIN_MASK ((uint32_t) -2)
#define HT_HASH_SIZE(nTableMask) (((size_t)(uint32_t)-(int32_t)(nTableMask)) * sizeof(uint32_t))
#define HT_SET_DATA_ADDR(ht, ptr) do { (ht)->arData = (Bucket*)(((char*)(ptr)) + HT_HASH_SIZE((ht)->nTableMask)); } while (0)

static const uint32_t uninitialized_bucket[-HT_MIN_MASK] = {HT_INVALID_IDX, HT_INVALID_IDX};

/* hash lazy init */
ZEND_API void ZEND_FASTCALL _zend_hash_init(HashTable *ht, uint32_t nSize, dtor_func_t pDestructor, zend_bool persistent ZEND_FILE_LINE_DC)
{
    /* ... */
    ht->nTableSize = zend_hash_check_size(nSize);
    ht->nTableMask = HT_MIN_MASK;
    HT_SET_DATA_ADDR(ht, &uninitialized_bucket);
    ht->nNumUsed = 0;
    ht->nNumOfElements = 0;
}</code></pre>
<p>Note that there is no need to use the heap. A static const memory zone is just enough and pretty much light here (<code>uninitialized_bucket</code>).</p>
<p>Then, when the first item is inserted, we fully initialize the hashtable, aka we create the last needed translation slots depending on the size asked (it starts at 8 slots if no clue given). This allocation is done from the heap as some dynamism is showing up.</p>
<pre><code>#define HT_HASH_EX(data, idx) ((uint32_t*)(data))[(int32_t)(idx)]
#define HT_HASH(ht, idx) HT_HASH_EX((ht)->arData, idx)

(ht)->nTableMask = -(ht)->nTableSize;
HT_SET_DATA_ADDR(ht, pemalloc(HT_SIZE(ht), (ht)->u.flags & HASH_FLAG_PERSISTENT));
memset(&HT_HASH(ht, (ht)->nTableMask), HT_INVALID_IDX, HT_HASH_SIZE((ht)->nTableMask))</code></pre>
<p>The <code>HT_HASH</code> macro allows to access the translation slots in the negative offset part of the allocated buffer.
The table mask is always negative, because the translation table slots are indexed negatively from the start of the <code>arData</code> buffer.
This is true C programming is all its beauty : you are given billions of memory slots : swim in that infinite pool but don't sink and take care of performances in each memory access !</p>
<p>Here is a hashtable lazy-initialized : It has been created, but nothing has never been inserted into it yet :</p>
<p><img src="../../../img/php7-hashtables/hash_lazy_init.png" alt="hash_lazy_init"></p>
<p>Pretty light isn't it ?</p>
<h3 id="hash-fragmentation-resizing-and-compacting">Hash fragmentation, resizing and compacting<a href="#hash-fragmentation-resizing-and-compacting" class="anchor">#</a></h3>
<p>When the hashtable becomes full, and one will keep-on inserting items, then the hash must resize itself (on more advantage of hashtables against classical C bound-arrays).
The hashtable size is then doubled everytime it is asked to grow. Here again, when we double the size of the hashtable, we pre-allocate the <code>arBucket</code> C array and store into the empty slots special UNDEF <code>zval</code> values. We then effectively waste space here : <em>(new_size - old_size) * sizeof(Bucket)</em> bytes are actually lost, waiting for data to be inserted and take the UNDEF slots.</p>
<p>Hence if you have a 1024 slots hashtable, and add one more item, the table is going to grow to 2048 slots, having 1023 of them empty, consuming 1023 * 32 bytes = roughly 32Kb here. This is one drawback of PHP's hashtable implementation, which anyway can't be perfect.</p>
<blockquote>
<p>Programming is always solving compromises, in case of low level programming, this is a CPU versus memory compromise.</p>
</blockquote>
<p>Remember however that the hashtable could be full of UNDEF slots. If one adds many items, then removes many of them, the hashtable will get fragmented. As we never insert something new in such a hole, but at the end of the <code>arData</code> (to keep order of things while iterating), we could run in a scenario where we are at the edge of the end, but still could see may empty UNDEF slots in the <code>arData</code>.</p>
<p>Here is a picture of a very fragmented 8-slots hashtable :</p>
<p><img src="../../../img/php7-hashtables/hash_fragmented.png" alt="hash_fragmented"></p>
<p>Remember we can't store new values in UNDEF holes, as when we iterate over the hashtable, we start from <code>arData[0]</code> to <code>arData[7]</code> in such an above example (assuming 8-slots hashtable).</p>
<p>Resizing is one occasion to shrink the <code>arData</code> vector and finally fill-in those empty slots by simply reorganizing the data.
When the hashtable is asked to get resized, it first tries to compact itself. It then computes if after compaction it effectively needs to grow, and grows if needed, doubling its size (the <code>arData</code> vector is then <code>realloc()</code>ed as twice its old size). If not needed, data have simply been reorganized into already-allocated slots, an algorithm we can't run at every deletion of items as it would burn CPU cycles too often for not a huge gain (you remember, that famous CPU/Memory compromise in programming ?)</p>
<p>This is a picture of the preceding fragmented hashtable, once it got compacted :</p>
<p><img src="../../../img/php7-hashtables/hash_compacted.png" alt="hash_compacted"></p>
<p>The algorithm must browse the <code>arData</code> and replace every UNDEF slot by the next defined value.
Here it is , simplified : </p>
<pre><code>Bucket *p;
uint32_t nIndex, i;
HT_HASH_RESET(ht);
i = 0;
p = ht->arData;

do {
    if (UNEXPECTED(Z_TYPE(p->val) == IS_UNDEF)) {
        uint32_t j = i;
        Bucket *q = p;
        while (++i < ht->nNumUsed) {
            p++;
            if (EXPECTED(Z_TYPE_INFO(p->val) != IS_UNDEF)) {
                ZVAL_COPY_VALUE(&q->val, &p->val);
                q->h = p->h;
                nIndex = q->h | ht->nTableMask;
                q->key = p->key;
                Z_NEXT(q->val) = HT_HASH(ht, nIndex);
                HT_HASH(ht, nIndex) = HT_IDX_TO_HASH(j);
                if (UNEXPECTED(ht->nInternalPointer == i)) {
                    ht->nInternalPointer = j;
                }
                q++;
                j++;
            }
        }
        ht->nNumUsed = j;
        break;
    }
    nIndex = p->h | ht->nTableMask;
    Z_NEXT(p->val) = HT_HASH(ht, nIndex);
    HT_HASH(ht, nIndex) = HT_IDX_TO_HASH(i);
    p++;
} while (++i < ht->nNumUsed);</code></pre>
<h2 id="hashtable-api">HashTable API<a href="#hashtable-api" class="anchor">#</a></h2>
<p>So far so good, we know the basics of PHP 7 hashtable implementation.
Let's have a look at its public API.</p>
<p>There is nothing special to say except that it is <strong>way better designed</strong> as PHP 5's; Just keep in mind there are three factors to take into account about what API function to use :</p>
<ul><li>Your operation (add, remove, clean, destroy etc...)</li>
<li>The type of your key (integer, or string)</li>
<li>The type of data you want to store</li>
</ul><p>Remember that wether your key is a string, or an integer ; is a very important factor hashtable API must know as string based keys will need to take the hash from the <code>zend_string</code> and integer based key will directly be used as hash.
Thus, we can meet <code>zend_hash_add(ht, zend_string, data)</code> or <code>zend_hash_index_add(ht, zend_ulong, data)</code>.</p>
<p>Sometimes, your key will be a simple classical <em>(char* / size_t)</em> pair. Here, you'll use a different API, f.e <code>zend_hash_str_add(ht, char *, size_t, data)</code>.
But keep in mind that whatever happens, the hashtable will deal with a <code>zend_string</code>, and will then turn your C string into a <code>zend_string</code>, duplicating it in memory and computing its hash. That could waste CPU cycles if the string were to be already known. If you can use a <code>zend_string</code>, use it; as they are very likely to have already computed their own hash, hence the hashtable API will simply use it. For example, the PHP compiler computes every hash of every piece of string it uses, as <code>zend_string</code> of course. OPCache also stores such a hash in shared memory. As extension writer : initialize all your <code>zend_string</code> litterals in MINIT.</p>
<p>Finally comes the data you want to store into hashtables. Here again, whatever you use : the hashtable will put it into a <code>zval</code>, stored into each <code>Bucket</code>. But zvals are really flexible in PHP 7, and can store any type of data.
The hashtable API mainly expect you to pack your data into a zval, that is it expects a <code>zval</code> as value. It may however ease things if you got a pointer to store, or a memory area.
It will then take your pointer or memory area, and build a <code>zval</code> with it, then use that <code>zval</code> as data.</p>
<p>Examples are now easy to understand :</p>
<pre><code>zend_hash_str_add_mem(hashtable *, char *, size_t, void *, size_t)
zend_hash_index_del(hashtable *, zend_ulong)
zend_hash_update_ptr(hashtable *, zend_string *, void *)
zend_hash_index_add_empty_element(hashtable *, zend_ulong)</code></pre>
<p>Retrieving data, you'll be given a <code>zval *</code>, or NULL. There is a special case for a pointer based value where the API can return it as-is :</p>
<pre><code>zend_hash_find(hashtable *, zend_string *) : zval *
zend_hash_find_ptr(hashtable *, zend_string *) : void *
zend_hash_index_find(hashtable *, zend_ulong) : zval *
zend_hash_index_find_ptr(hashtable *, zend_ulong) : void *</code></pre>
<p>About the "_new" API, like <code>zend_hash_add_new()</code> : you should not use it. This is used internally by the engine. This API forces the hashtable to store the data, even if that latter is already available into the hash (same key). You'll end up having doubles, and strange things could then show up. It may be used if you are very sure the data you're going to add is not already present : that will prevent a search for it. Analyze the source for more informations.</p>
<p>Last word : like in PHP 5, the <code>zend_symtable_xxx()</code> API takes care of numeric-like strings to turn them to integers :</p>
<pre><code>static zend_always_inline zval *zend_symtable_update(HashTable *ht, zend_string *key, zval *pData)
{
    zend_ulong idx;

    if (ZEND_HANDLE_NUMERIC(key, idx)) { /* handle numeric key */
        return zend_hash_index_update(ht, idx, pData);
    } else {
        return zend_hash_update(ht, key, pData);
    }
}</code></pre>
<p>For iteration, you may use lots of macros, depending on what data you want to be given in the loop : the key, the zval data ...
They're all based upon <code>ZEND_HASH_FOREACH</code> :</p>
<pre><code>#define ZEND_HASH_FOREACH(_ht, indirect) do { \
    Bucket *_p = (_ht)->arData; \
    Bucket *_end = _p + (_ht)->nNumUsed; \
    for (; _p != _end; _p++) { \
        zval *_z = &_p->val; \
        if (indirect && Z_TYPE_P(_z) == IS_INDIRECT) { \
            _z = Z_INDIRECT_P(_z); \
        } \
        if (UNEXPECTED(Z_TYPE_P(_z) == IS_UNDEF)) continue;

#define ZEND_HASH_FOREACH_END() \
        } \
    } while (0)</code></pre>
<p>You are provided many flavors of them, depending if you want to see the key in the iteration loop, if that key is a string or an integer; If you want to browse the table backwards, if you want it to probe for the pointer data into the zval... etc. <code>ZEND_HASH_FOREACH_KEY()</code>, <code>ZEND_HASH_FOREACH_STR_KEY_PTR()</code>, <code>ZEND_HASH_REVERSE_FOREACH_KEY_VAL()</code> ...</p>
<h2 id="packed-hashtable-optimization">Packed hashtable optimization<a href="#packed-hashtable-optimization" class="anchor">#</a></h2>
<p>So, remember the crucial design rule : we insert data elements in ascending order into <code>arData</code>, from 0 to end , then we grow the <code>arData</code> vector. This allows us to easily and cheaply iterate over the hashtable : simply iterate over <code>arData</code> C-array.
Because one would use a string or an unordered integer as the hashtable key, we must store a translation table to be able to probe the hash.</p>
<p>But there is one case where such a translation table is useless : if the user only uses integer based keys, and only in ascending order.
In such a special case, browsing the <code>arData</code> from begining to end will retrieve the data in the same order they've been inserted. Thus, for this case only, the translation table is useless, and we may not allocate it at all.</p>
<p>This optimization is called <em>"packed hashtable"</em>. Here is a packed hashtable :</p>
<p><img src="../../../img/php7-hashtables/packed_hash.png" alt="packed_hash"></p>
<p>Like you can see, the keys are all integer based (no string key) and all in ascending order, even not contiguous.
Iterating from <code>arData[0]</code> to end will then give elements in their right order. Hence, the translation table have been reduced to only two slots, weighting only 2 <code>uint32</code> (8 bytes). All other translation slots are useless. That may seem strange, but those two slots are here for performances (rather than not having any slot at all).</p>
<p>Be warned however : if you break the rule, for example by now inserting an element with a string-based key (which will need to get hashed/reduced), then we have no other choice of turning this packed hashtable into a classical hashtable : we create the full translation slots and reorganize buckets. Like this :</p>
<pre><code>ZEND_API void ZEND_FASTCALL zend_hash_packed_to_hash(HashTable *ht)
{
    void *new_data, *old_data = HT_GET_DATA_ADDR(ht);
    Bucket *old_buckets = ht->arData;

    ht->u.flags &= ~HASH_FLAG_PACKED;
    new_data = pemalloc(HT_SIZE_EX(ht->nTableSize, -ht->nTableSize), (ht)->u.flags & HASH_FLAG_PERSISTENT);
    ht->nTableMask = -ht->nTableSize;
    HT_SET_DATA_ADDR(ht, new_data);
    memcpy(ht->arData, old_buckets, sizeof(Bucket) * ht->nNumUsed);
    pefree(old_data, (ht)->u.flags & HASH_FLAG_PERSISTENT);
    zend_hash_rehash(ht); /* Prepare the translation table and the translation slots */
}</code></pre>
<p>You can spot here that the hashtable <code>u.flags</code> is used to recognize if the hashtable is packed or not.
A packed hashtable will behave differently from a traditionnal hashtable : there is no need to take care of translation slots. Thus, in the source code, you can find many places where packed hashes take a different code path from classical hashes. For example :</p>
<pre><code>static zend_always_inline zval *_zend_hash_index_add_or_update_i(HashTable *ht, zend_ulong h, zval *pData, uint32_t flag ZEND_FILE_LINE_DC)
{
    uint32_t nIndex;
    uint32_t idx;
    Bucket *p;

    /* ... */
    if (UNEXPECTED(!(ht->u.flags & HASH_FLAG_INITIALIZED))) {
        CHECK_INIT(ht, h < ht->nTableSize);
        if (h < ht->nTableSize) {
            p = ht->arData + h;
            goto add_to_packed;
        }
        goto add_to_hash;
    } else if (ht->u.flags & HASH_FLAG_PACKED) {
        /* ... */
        } else if (EXPECTED(h < ht->nTableSize)) {
            p = ht->arData + h;
        } else if ((h >> 1) < ht->nTableSize &&
                   (ht->nTableSize >> 1) < ht->nNumOfElements) {
            zend_hash_packed_grow(ht);
            p = ht->arData + h;
        } else {
            goto convert_to_hash;
        }
/* ... */</code></pre>
<p>So, to sum up things : packed hashtable are an optimization both in term of memory and CPU usage.</p>
<p>For memory first, you consume <em>(table_size - 2) * sizeof(uint32)</em> less bytes compared to a classical hashtable. For thousands of slots, that represents kilo bytes.</p>
<p>For CPU then, because every operation will not have to probe the translation slots, and make the translation. That's barely few less instructions per operation, which can once again show differences in term of millisecond in case of a heavily used/manipulated array.</p>
<p>However, if you start using a string-based key, or if you use an integer key breaking the order of things (inserting key 42 after key 60), then you'll force the hashtable to get converted to a "classical" hash : this process eats a little quantity of CPU cycles (more on very huge arrays), and more memory as well.</p>
<p>To create a packed hashtable, simply tell it to the API :</p>
<pre><code>void ZEND_FASTCALL zend_hash_real_init(HashTable *ht, zend_bool packed)</code></pre>
<p>Be warned that <code>zend_hash_real_init()</code> is the full initialization step, not the lazy one (<code>zend_hash_init()</code>).
Usually, when you initialize (lazy) a hashtable and start inserting things into it, it will start itself as packed , and as soon as one condition breaks packed optimization, it will turn to classical hash.</p>
<p>Last word : an API exists if you want to construct a full packed hashtable. Instead of using some <code>zend_hash_index_add()</code> or <code>zend_hash_add_next_index_insert()</code>, this API is fully macro based and as you can spot from its source code : it is very performant.</p>
<pre><code>#define ZEND_HASH_FILL_PACKED(ht) do { \
        HashTable *__fill_ht = (ht); \
        Bucket *__fill_bkt = __fill_ht->arData + __fill_ht->nNumUsed; \
        uint32_t __fill_idx = __fill_ht->nNumUsed; \
        ZEND_ASSERT(__fill_ht->u.flags & HASH_FLAG_PACKED);

#define ZEND_HASH_FILL_ADD(_val) do { \
        ZVAL_COPY_VALUE(&__fill_bkt->val, _val); \
        __fill_bkt->h = (__fill_idx); \
        __fill_bkt->key = NULL; \
        __fill_bkt++; \
        __fill_idx++; \
    } while (0)

#define ZEND_HASH_FILL_END() \
        __fill_ht->nNumUsed = __fill_idx; \
        __fill_ht->nNumOfElements = __fill_idx; \
        __fill_ht->nNextFreeElement = __fill_idx; \
        __fill_ht->nInternalPointer = __fill_idx ? 0 : HT_INVALID_IDX; \
    } while (0)</code></pre>
<h2 id="arrays-in-php-land">Arrays in PHP land<a href="#arrays-in-php-land" class="anchor">#</a></h2>
<p>You know PHP's arrays. Here, we'll see together how hashtable implementation details can be checked through userland code.</p>
<h3 id="playing-with-hashtables-memory-and-packed-optimization">Playing with hashtables memory and packed optimization<a href="#playing-with-hashtables-memory-and-packed-optimization" class="anchor">#</a></h3>
<p>So, here we go for a demo of packed arrays optimisation :</p>
<pre><code>function m()
{
    printf("%d\n", memory_get_usage());
}

$a = range(1,20000); /* range() creates a packed array */

m();

for($i=0; $i<5000; $i++) {
     /* We keep on inserting keys in ascending order,
      * thus the packed array contract is still valid : 
      * we stay in packed mode */
    $a[] = $i;
}

m();

/* We suddenly break packed array contract, and force
 * the hashtable to turn to "classical", eating more
 * memory for translation slots */
$a['foo'] = 'bar';

m();</code></pre>
<p>Like we can expect, the results of memory usage are :</p>
<pre><code>1406744
1406776
1533752</code></pre>
<p>For such a 25000 item array, memory usage grows of roughly 130Kb from packed optimized to classical hash.</p>
<p>Now, let's demonstrate the compact-or-grow algorithm in action :</p>
<pre><code>function m()
{
    printf("%d\n", memory_get_usage());
}

/* Hashtables are allocated power-of-two. Let's create a
 * 32768-slot array (2^15). We use here packed array */
for ($i=0; $i<32768; $i++) {
    $a[$i] = $i;
}

m();

/* Let's now empty it */
for ($i=0; $i<32768; $i++) {
    unset($a[$i]);
}
m();

/* Add one more element. The hash size should overflow, and
 * trigger the compact-or-resize algorithm */
$a[] = 42;

m();</code></pre>
<p>That displays :</p>
<pre><code>1406864
1406896
1533872</code></pre>
<p>So, when the table is full and when we empty it, the memory usage doesn't move at all (modulo noise). When we finished <code>unset()</code>ing every value, we end having a hashtable which <code>arData</code> is 32768 slots all full of UNDEF zvals.</p>
<p>Then, we add <strong>at the next element</strong> something. Remember the <code>nNumUsed</code>, used to address <code>arData</code> and which keeps growing at each insertion ? It will now overflow the table size : it is time to compact it or resize it if we can't compact.</p>
<p>Can we compact ?</p>
<p>The obvious answer is yes : we are full of UNDEF slots here, but the true answer is no : we must keep the order of things <strong>because we are using a packed array</strong> and would want to prevent it from turning to classical array until we are very forced to do so.
If we would have added an element to an already existing slot, we would have broken the order of things, and thus the algorithm would have triggered a compaction, and not a resize, eating no more memory. Like this :</p>
<pre><code>/* All code is the same as above, but : */

/* Add one more element at a known index (idx). The hash
 * size should overflow, and trigger the compact-or-resize
 * algorithm */
$a[3] = 42;

m();</code></pre>
<p>Here, memory usage is :</p>
<pre><code>1406864
1406896
1406896</code></pre>
<p>See the difference ? Now the algorithm has not resized our table from 32768 to 65538 slots, but have run the compaction.
Our hashtable is still 32767 slots allocated, and as a slot is a <code>Bucket</code>, into which a <code>zval</code>, into which size of a <code>long</code> (42 here) : the memory doesn't move a bit, as the zval already embeds the sizeof a long ;-) Hence, we may now <strong>reuse</strong> those 32768 slots with integer values, or booleans, or floats , for free. If we would use strings, objects, other arrays etc... as values, then extra memory allocation would be done, which pointer would be stored into the already preallocated UNDEF <code>zval</code>s of our "hot" array.</p>
<p>We can try the same with <strong>non-packed</strong> hashtable, but classical one, simply using a string based key. Here, when we overflow by one element, the table will compact and not resize, because there is no such thing as order to be kept : we are anyway in non-packed mode, just stick the additionnal value at the leftmost position (<code>idx</code> 0), all follows as UNDEF zvals.</p>
<pre><code>function m()
{
    printf("%d\n", memory_get_usage());
}

/* Hashtables are allocated power-of-two. Let's create a
 * 32768-slot array (2^15). We DONT use here packed array */
for ($i=0; $i<32768; $i++) {
    /* let's have a string-based key, to use classical hash */
    $a[' ' . $i] = $i;
}

m();

/* Let's now empty it */
for ($i=0; $i<32768; $i++) {
    unset($a[' ' . $i]);
}
m();

/* Add one more element. The hash size should overflow, and
 * trigger the compact-or-resize algorithm */
$a[] = 42;

m();</code></pre>
<p>That displays :</p>
<pre><code>2582480
1533936
1533936</code></pre>
<p>Like expected. The array consumes roughly 2.5Mb here, then when we <code>unset()</code> all its values, memory usage drops : we are freeing the keys. The keys are 32768 <code>zend_string</code>, freeing them drops us to 1.5Mb of memory usage now.</p>
<p>By now adding one more element, we overflow the table internal size, and trigger the compact-or-resize algorithm.
As we don't use a packed array, there is no need to keep any order, the table is then compacted, our new 42 value is stored at idx 0, the memory doesn't move a bit. End of story.</p>
<p>Like we can see, packed hashtables can play against us, in some very special cases, preventing the hashtable from compacting and growing it instead. But, will you use such a silly source code in real life example ?
This should not impact your day-to-day programming, but if you are looking for true performances (frameworks hear me here ?), and/or want to optimize some batch scripts - with heavy load data pool - this could be a cool trick instead of thinking about turning to true C for such tasks.</p>
<p>If you don't reach many thousands of elements, memory footprint will be ridiculous. But here we played with "only" 20.000 to 32.000 elements, and started seeing megabytes or kilobytes differences.</p>
<h3 id="immutable-arrays">Immutable arrays<a href="#immutable-arrays" class="anchor">#</a></h3>
<p>Immutable arrays are an OPCache specific feature. If you dont enable OPCache, you won't benefit from this concept.
Immutable arrays are arrays that are read-only. When OPCache is enabled, it browses every script content, and tries to copy to shared memory many things. Among those things, you will find constant AST nodes. A constant array is a constant AST node. Example :</p>
<pre><code>$a = ['foo', 1, 'bar'];</code></pre>
<p>Here, <code>$a</code> is a constant AST node, the compiler detected that it is an array full of constant things , and it turned this array into a constant node.
Then, OPCache browses every scripts' constant AST nodes, and copy their process bound address (heap address) into the shared memory segment and then frees back the process bound address. You may find some more infos about OPCache at <a href="http://jpauli.github.io/2015/03/05/opcache.html">PHP's OPCache extension review</a>.</p>
<p>But for arrays, OPCache also turns them into immutable arrays, setting them the <em>IS_ARRAY_IMMUTABLE</em> as well as the <em>IS_TYPE_IMMUTABLE</em> flags.
The engine has been designed so that every time it meets an <em>IS_IMMUTABLE</em> data, it takes specific paths about them.
For arrays, if you affect an immutable array to a variable, it will not duplicate it, otherwise, a full copy of the array is done.</p>
<p>Such an optimization can be seen in some code like :</p>
<pre><code>$ar = [];
for ($i = 0; $i < 1000000; ++$i) {
    $ar[] = [1, 2, 3, 4, 5, 6, 7, 8];
}</code></pre>
<p>This script consumes about 400Mb of memory when OPCache is not enabled, and roughly 35Mb when it is activated. This is 10 times less...
In such a script, when OPCache is not enabled, the engine will create a full copy of the 8-element array in each <code>$ar</code> slot, hence having effectively 1 million of 8-slot arrays residing in memory.
If OPCache is turned on, it will flag the 8-slot array as <em>IS_IMMUTABLE</em>, and thus when the executor will run such a script, it will simply copy the 8-slot array pointer to the <code>$ar</code> slots, preventing a full duplication at each loop step.
Obviously, if later on you come to modify one of those arrays, with a statement such as <code>$ar[42][3] = 'foo';</code> then the 8-slot array residing in <code>$ar[42]</code> will get fully duplicated as Copy on Write mecanism.</p>
<p>Another optimization is blindly done on internal HashTables. Remember that PHP arrays are just one use case of Zend Hashtables. One usage you can feel, because you can manipulate them through the PHP language. But HashTables are used everywhere in the engine.</p>
<p>For example, any PHP scripts may contain functions, and/or classes. Well, those two later big concepts are stored into 2 HashTables.
The compiler turns a PHP script into what's called an "OPArray", and it attaches this OPArray the function table (which could be empty), and the class table (which could also be empty).
When PHP finished its current request, it must clean this OPArray : it destroys the function table, and the class table. But if OPCache is enabled, it would have turned those two arrays as <em>IMMUTABLE</em> as well, preventing the engine from destroying them. They will be loaded back from shared memory as soon as another request shows in, and asks for such a same script.</p>
<p>OPCache not only stores those tables into memory once and only once, it also prevents them from being destroyed at the end of every request. Such a destruction process can take time, as it is recursive and involves destroying many pointers from memory (the more you have classes and functions, the more the destroy process will be long). Thus, immutable hashtables also allow OPCache to speed up the shutdown sequence of the engine, and the current PHP process will be recycled faster to treat another pending request : this accelerates the overall performances of PHP.</p>
<p>Don't get confused by immutable arrays. For example, there is no optimization at this time for such a scenario :</p>
<pre><code>$a = [1];
$b = [1];</code></pre>
<p>Here, two arrays will be created in memory. There is no process like for <a href="http://jpauli.github.io/2015/09/18/php-string-management.html#interned-strings">interned strings</a>, where the engine tracks every piece of string used to reuse it if it meets it later on.
Immutable arrays are arrays full of immutable types (no variables, no function calls, everything is resolvable at compile time), which are not duplicated in memory when carried from one place to the other as PHP runtime goes, and which are never destroyed from memory (from one request to the other). Also, immutable arrays are only used if the OPCache extension is enabled.</p>]]></content>
    </entry>
        <entry>
        <title>PHP 7 objects</title>
                <id>http://jpauli.github.io//2016/01/14/php-7-objects.html</id>
                <updated>2016-01-14T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2016/01/14/php-7-objects.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>Here is my first 2016 post, and as well my first PHP 7 targeted post.
I guess 2016 will be full of PHP 7 posts, and empty of PHP 5 posts. Clearly, today, PHP 7 is stable, production ready, released, a lot of extensions have been ported to it, and 2016 is PHP 7 year.</p>
<p>I myself work more under PHP 7 than PHP 5 today, but you know I'm not a PHP developer (any more) but now system developer mastering the internal C-level API of PHP.
So once more, in this post, we'll mainly talk about internal development, but as soon as interesting things show up for userland, we won't hesitate to get back to userland world for a moment to explain interesting concepts.</p>
<p>Let's go ?</p>
<h2 id="what-has-changed-in-objects-against-php-5">What has changed in objects against PHP 5<a href="#what-has-changed-in-objects-against-php-5" class="anchor">#</a></h2>
<p>You first should read <a href="http://jpauli.github.io/2015/03/24/zoom-on-php-objects.html">Zoom on PHP objects and classes</a> to have a full focus on PHP objects.</p>
<p>What have changed in PHP 7 about objects ? </p>
<ul><li>In userland : in a word : nearly nothing. In other words : objects is not the subject that has the most been changed in PHP 7. In conclusion : objects in PHP 7 are the same as PHP 5 objects. Nothing has changed. Nothing deep, nothing you can feel in your day to day development. PHP 7 objects behave the exact same way PHP 5 objects behave in userland. Why ? Because our object model is mature, heavilly used, and there is no need to break it deeply in new PHP versions. Of course it got improved with new additions.</li>
<li>In low level land : there are some changes, they are not <strong>that</strong> big, but they <strong>will</strong> require you to patch your extension code.
Basically, like everywhere else work has been done, PHP 7 new internal objects are much more meaningfull, clean and logical that they were back in PHP 5.
The first big change is related to the master change of PHP 7 : new zval and garbage collection management. We won't last on this point though, but focus on objects. However, new zval and garbage collection mechanisms bring by their own nature some changes into how objects are managed internally.</li>
</ul><h2 id="object-layout-and-memory-management">Object layout and memory management<a href="#object-layout-and-memory-management" class="anchor">#</a></h2>
<p>First of all, say byebye to <em>zend_object_value</em>, this structure does not exist any more in PHP 7.</p>
<p>Now, let's define an object, <em>zend_object</em> :</p>
<pre><code>/* in PHP 5 */
typedef struct _zend_object {
    zend_class_entry *ce;
    HashTable *properties;
    zval **properties_table;
    HashTable *guards;
} zend_object;

/* in PHP 7 */
struct _zend_object {
    zend_refcounted_h gc;
    uint32_t          handle;
    zend_class_entry *ce;
    const zend_object_handlers *handlers;
    HashTable        *properties;
    zval              properties_table[1]; /* C struct hack */
};</code></pre>
<p>As we can see, it is a little bit different from PHP 5. It embeds a <em>zend_refcounted_h</em> header, which is part of the new zval and garbage collection mechanisms of PHP 7.
Also, what's different from PHP 5 is that now the object embeds its <em>handle</em>, whereas on PHP 5, this responsibility was delegated to the <em>zend_object_store</em>. We'll see that now in PHP 7, the object store has much less responsibilities.
Also, you may have caught the C struct hack used to inline the zval vector <em>properties_table</em>, we'll have to take care of it when we'll create custom object.</p>
<h2 id="custom-objects-management">Custom objects management<a href="#custom-objects-management" class="anchor">#</a></h2>
<p>What is an important change is how we now manage <strong>custom objects</strong>, those are objects of our taste, embedding a <em>zend_object</em>.
This is the true power behind Zend Engine object model : the fact that extensions can declare and manage their own objects, that extend Zend default objects implementation without the need of changing the engine source.</p>
<p>Back in PHP 5, we simply create a C struct inheritence embedding the basis definition of a <em>zend_object</em>, like this :</p>
<pre><code>/* PHP 5 */
typedef struct _my_own_object {
    zend_object        zobj;
    my_custom_type    *my_buffer;
} my_own_object;</code></pre>
<p>Using C struct inheritence, a simple cast is enough to make it :</p>
<pre><code>/* PHP 5 */
my_own_object *my_obj;
zend_object   *zobj;

my_obj = (my_own_object *)zend_objects_store_get_object(this_zval);
zobj   = (zend_object *)my_obj;</code></pre>
<p>You may notice that in PHP 5, when you receive a zval, like <code>$this</code> in OO methods, you can't from this zval access the object it points to directly.
You need to ask the object store. You extract the handle from the zval (in PHP 5), and with this handle you ask the store to give you back the object it found. This object - as it may be a custom one - is returned as a <em>void*</em> you must cast it as <em>zend_object*</em>, if you didnt customize anything, or as <em>my_own_object*</em> if you did.</p>
<p>So in PHP 5, to retrieve an object from a method, you need a lookup. This is not nice in term of performances.</p>
<p>In PHP 7, this is different.
In PHP 7, the object - should it be custom or classic <em>zend_object</em> - is nested into the zval directly. <strong>The object store doesn't have any fetch operation available anymore</strong> , that means you can't read from the object store anymore, but only put into it, or delete from it.</p>
<p><strong>The whole allocated object is embeded into the zval</strong>, thus you don't need an extra lookup when receiving a zval as param and wanting to fetch back the object memory area it points to.</p>
<p>This is how you get an object in PHP 7 :</p>
<pre><code>/* PHP 7 */
zend_object *zobj;
zobj = Z_OBJ_P(this_zval);</code></pre>
<p>Simpler and cleaner than in PHP 5 right ?</p>
<p>Now things change if you have some custom allocation. From the lines above, the only way to fetch a custom object, is to play with memory, aka slice your pointer in any direction of the quantity needed, to make it point where you want. Pure C programming and pure performance : you are very likely to stay in the same physical memory page, and thus prevent your kernel from firing to page-in.</p>
<p>In PHP 7, when you want to declare a custom object, you do it like this :</p>
<pre><code>/* PHP 7 */
typedef struct _my_own_object {
    my_custom_type *my_buffer;
    zend_object     zobj;
} my_own_object;</code></pre>
<p>Notice the <strong>inversion</strong> in the members of the structure (compared to PHP 5). This is because now, when you read the <em>zend_object</em> from the zval, to be given back your <em>my_own_object</em>, you have to slice the memory backwards by substracting the offset of the <em>zend_object</em> into the structure.
This is done using <code>OffsetOf()</code> of <em>stddef.h</em> (which can be easilly emulated if needed).
This is C advanced structure usage, but if you master the language you use (and at our level you must), this should be something you have already done in your career , so nothing special in here.</p>
<p>So now to fetch your custom object in PHP 7, you'd do it like this :</p>
<pre><code>/* PHP 7 */
zend_object   *zobj;
my_own_object *my_obj;

zobj   = Z_OBJ_P(this_zval);
my_obj = (my_own_object *)((char *)zobj - XtoffsetOf(struct my_own_object, zobj));</code></pre>
<p>Using <code>offsetof()</code> here has one implication : <strong>the zend_object must be the last member of your_custom_struct object</strong>. Obviously if you declare types after it, you'll run into trouble accessing them, because of the way <em>zend_object</em> is allocated now in PHP 7.</p>
<p>Remember that now in PHP 7, <em>zend_object</em> has a struct hack. That means that the allocated memory quantity will differ from <code>sizeof(zend_object)</code>.
To allocate a <em>zend_object</em>, one would use :</p>
<pre><code>/* PHP 5 */
zend_object *zobj;
zobj = ecalloc(1, sizeof(zend_object));

/* PHP 7 */
zend_object *zobj;
zobj = ecalloc(1, sizeof(zend_object) + zend_object_properties_size(ce));</code></pre>
<p>You need to allocate enough space for the members which exact size is given by your class (<em>ce</em>), because your class knows everything about declared attributes.</p>
<h2 id="object-creation">Object creation<a href="#object-creation" class="anchor">#</a></h2>
<p>Now let's see a real example.
Let's have a custom object like this one :</p>
<pre><code>/* PHP 7 */
typedef struct _my_own_object {
    void        *my_custom_buffer;
    zend_object zobj; /* MUST be the last element */
} my_own_object;</code></pre>
<p>Here is what its <code>create_object()</code> handler could look like :</p>
<pre><code>/* PHP 7 */
static zend_object *my_create_object(zend_class_entry *ce)
{
    my_own_object *my_obj;

    my_obj                   = ecalloc(1, sizeof(*my_obj) + zend_object_properties_size(ce));
    my_obj->my_custom_buffer = emalloc(512); /* for example, our custom buffer will fit 512 bytes */

    zend_object_std_init(&my_obj->zobj, ce); /* take care of the zend_object also ! */
    object_properties_init(&my_obj->zobj, ce);

    my_obj->zobj.handlers = &my_class_handlers; /* I have custom handlers, we'll see them later */

    return &my_obj->zobj;
}</code></pre>
<p>So the difference with PHP 5 here, is that you must not miss the quantity of memory you allocate : you must not forget about the struct hack inlining the <em>zend_object</em> properties.
Also, there is no object store involvement anymore here. Back in PHP 5, the create handler had to register the object into the store, and when registering it, pass as well some function pointers for object future destruction and free. This is not needed anymore in PHP 7, resulting in a much more clear <code>create_object()</code> function compared to PHP 5.</p>
<p>Simple enough, to use this custom <code>create_object()</code> handler, you would declare it into your extension, and this is here as well that you'll declare every handler :</p>
<pre><code>/* PHP 7 */

zend_class_entry     *my_ce;
zend_object_handlers my_ce_handlers;

PHP_MINIT_FUNCTION(my_extension)
{
    zend_class_entry ce;

    INIT_CLASS_ENTRY(ce, "MyCustomClass", NULL);
    my_ce = zend_register_internal_class(&ce);

    my_ce->create_object = my_create_object; /* our create handler */

    memcpy(&my_ce_handlers, zend_get_std_object_handlers(), sizeof(my_ce_handlers));

    my_ce_handlers.free_obj = my_free_object; /* This is the free handler */
    my_ce_handlers.dtor_obj = my_destroy_object; /* This is the dtor handler */
    /* my_ce_handlers.clone_obj is also available though we won't use it here */
    my_ce_handlers.offset   = XtOffsetOf(my_own_object, zobj); /* Here, we declare the offset to the engine */

    return SUCCESS;
}</code></pre>
<p>You see here, that we declare the <code>free_obj()</code> and the <code>dtor_obj()</code> handlers in MINIT. Before, in PHP 5, we had to declare both of them to <code>zend_objects_store_put()</code>, when registering the object into the store, <strong>operation which is not needed anymore in PHP 7</strong>. In PHP 7, <code>zend_object_std_init()</code> will write the object into the store, you don't do that by hand anymore, so don't miss that call.</p>
<p>So we register our <code>dtor_obj()</code> and <code>free_obj()</code> handlers here, as well as an offset member, which represents the offset we used to compute our custom object placement in memory.
<strong>This information is needed by the engine</strong>. Why ? Well, simply because in PHP 7, <strong>this is the engine that frees the object, not you any more</strong>.
We'll see that later, but when it comes to free the object, back in PHP 5 you had to do it yourself (often with a simple <em>free()</em>), now in PHP 7, the engine does it ; but as the engine will only receive <em>zend_object</em> types (obviously), it will have to know the offset in your custom struct, to free the whole pointer. This is <a href="https://github.com/php/php-src/blob/PHP-7.0/Zend/zend_objects_API.c#L187">done here</a>.</p>
<h2 id="object-destruction">Object destruction<a href="#object-destruction" class="anchor">#</a></h2>
<p>Let's now focus on the destructor.</p>
<p>I remind you that the destructor is called when the object is destroyed from PHP userland, exactly the same way user land's <code>__destruct()</code> is called.
So, your destructor may not be called at all in case of fatal errors, and this has not changed in PHP 7.
Also, if you read carefully the articles I point you to or <a href="http://fr.slideshare.net/jpauli/understanding-php-objects">some talks I gave in the past</a>, you should remember that the destructor should not leave the object in an unstable state, because once destroyed, the object can still be accessed in some special cases. This is why we have a destructor handler <strong>and</strong> a free handler, separated. The free handler is called when the engine is extra sure the object is not used elsewhere. The destructor is called when the object's refcount has reached zero, but as now some userland code can be run (<code>__destruct()</code>), the current object could be reused as a reference elsewhere, thus it should stay in a stable state. That means that if you free memory in destructor, be extra careful about it. Usually, a destructor should release resources, but not free them (this is the free handler job).</p>
<p>So to sum up things about destructors :</p>
<ul><li>The destructor is called exactly zero <strong>or</strong> one time (most likely), but never more than once. In case of fatal errors, it <strong>won't</strong> be called at all.</li>
<li>The destructor shouldn't free resources, as the object <strong>could</strong> be reused by the engine in some special rare cases.</li>
<li>If you don't call <code>zend_objects_destroy_object()</code> from your custom destructor, userland's <code>__destruct()</code> won't be triggered.</li>
</ul><p>.</p>
<pre><code>/* PHP 7 */
static void my_destroy_object(zend_object *object)
{
    my_own_object *my_obj;

    my_obj = (my_own_object *)((char *)object - XtoffsetOf(my_own_object, zobj));

    /* Now we could do something with my_obj->my_custom_buffer, like sending it
       on a socket, or flush it to a file, or whatever, but not free it here */

    zend_objects_destroy_object(object); /* call __destruct() from userland */
}</code></pre>
<h2 id="object-storage-free">Object storage free<a href="#object-storage-free" class="anchor">#</a></h2>
<p>Finally, the free storage function is triggered when the engine is extra sure the object is not used elsewhere. The engine <strong>is</strong> about to destroy it, but just before doing so, it calls your <code>free_obj()</code> handler. You allocated some resources in your custom <code>create_object()</code> handler ? It is now time to free them :</p>
<pre><code>/* PHP 7 */
static void my_free_object(zend_object *object)
{
    my_own_object *my_obj;

    my_obj = (my_own_object *)((char *)object - XtoffsetOf(my_own_object, zobj));

    efree(my_obj->my_custom_buffer); /* Free your custom resources */

    zend_object_std_dtor(object); /* call Zend's free handler, which will free object properties */
}</code></pre>
<p>And that's all. What changes here, is that you don't free the object yourself anymore, like it was the case in PHP 5. In PHP 5, the handler would end with something like <em>free(object)</em>. You never do that in PHP 7.
In your <code>create_object()</code> handler, you allocated some space for your custom object structure, but as you passed the offset of your custom data to the engine in your MINIT, it is now able itself to free it.
It does that exactly <a href="https://github.com/php/php-src/blob/PHP-7.0/Zend/zend_objects_API.c#L187">here</a>.</p>
<p>Of course, in many cases, the <code>free_obj()</code> handler is called immediately after the <code>dtor_obj()</code> handler. Only if the userland destructor passes $this to someone else, then it won't be the case (or in the case of a custom extension object which is badly designed or hackish).
Read <a href="https://github.com/php/php-src/blob/PHP-7.0/Zend/zend_objects_API.c#L143">zend_object_store_del()</a> for the full sequence of code run when the engine wants to release an object.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h2>
<p>We've seen how objects have changed in PHP 7 compared to PHP 5, from an internal point of view. In userland, nothing has changed : all works similar to PHP 5, simply the PHP 7 object model is more optimized, so faster, and has some little more features compared to PHP 5, but nothing big here.</p>
<p>Internally, there are some changes. They are not huge, they won't require you hours of work, but they will generate some work. Both object models are incompatible internally, that means that you must rewrite your extension source code about objects, a little bit.
I tried here to explain the differences keeping the focus on the objects. If you turn to PHP 7 internally, you will notice that it is generally cleaner and more well written than PHP 5, because PHP 5 has suffered from a 10 year old history. PHP 7 is a major and broke many things internally to redesign more correctly some code that kept getting patched over years.</p>
<p>Hope I helped, but remember : all is written in the source code, which is just plain old C ;-)</p>]]></content>
    </entry>
        <entry>
        <title>Huge Page usage in PHP 7</title>
                <id>http://jpauli.github.io//2015/10/28/huge-page.html</id>
                <updated>2015-10-28T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/10/28/huge-page.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="recall-on-memory-paging">Recall on memory paging<a href="#recall-on-memory-paging" class="anchor">#</a></h2>
<p>Memory paging is a way Operating Systems manage userland process memory.
Each process memory access is virtual, and the OS together with the hardware MMU must translate that address into a physical address used to access the data in main memory (RAM).</p>
<p>Paging memory is dividing memory in chunks of fixed size, called pages. Under Linux, page size is usually 4Kb for many platforms, including X86/64.
Each memory page address translation is stored into a table attached to each process, this is what's called the Page Table Entry. To prevent the OS from accessing that table (stored into memory) at each memory access - leading to having two memory accesses to manage for each memory access demand - the hardware helps the OS in the use of a little cache for translations : the Translation-lookaside Buffer (TLB). This is stored into the MMU and is extremely fast and efficient, as soon as the translation is found into the TLB : a TLB hit. If not, then we happen having a TLB miss, and must access slow memory to find the translation an update the TLB (the OS Kernel does this job) to finally load our data from known memory address.</p>
<p>All those concepts are explained deeper in my <a href="http://jpauli.github.io/2015/04/16/segmentation-fault.html">segmentation fault article</a> , and I highly recommand you to read it if not familiar to virtual memory management in modern Operating Systems.</p>
<h2 id="why-use-huge-pages">Why use huge pages ?<a href="#why-use-huge-pages" class="anchor">#</a></h2>
<p>The concept is easy. If we make the OS Kernel use bigger page sizes, that means that more data can be accessed into one single page. That also means that we'll suffer from less TLB miss, once the page translation is stored into the TLB, because one translation will now be valid for more data.
The Linux Kernel used to use default 4Kb page size on X86/64 architectures, but back in ~2.6.20, the Kernel evolved and has been added the <em>huge page</em> concept. A huge page is typically 512 times larger than a traditionnal page : it fits 2Mb. You can read <a href="http://linuxgazette.net/155/krishnakumar.html">many articles (1)</a> <a href="https://www.kernel.org/doc/Documentation/vm/transhuge.txt">about (2)</a> <a href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt">huge pages (3)</a> management in the linux Kernel, you'll then learn that usually the Kernel performs what's called transparent huge page mappings (Kernel 2.6.38) : it will map virtual memory onto traditionnal 4Kb pages, but will try sometimes (you can have hand on this) to merge contiguous pages into huge pages. This is especially done for the heap segment of processes, that can represent a very huge address space, but care should be taken as this memory may be given back to the OS (freed) by small chunks, hence wasting huge page space and probably forcing the Kernel to undo its job and shrink back a huge page into 512 smaller 4Kb pages.</p>
<p>However, the user process may itself ask for huge page based mappings specifically. If you are sure you're gonna fill-in the huge page space, then it is better to ask the Kernel to give you a huge page for such virtual memory page. Huge page means less pages to manage, that means smaller lists to browse by the Kernel in the process page table entry, and that means as well less entries in the crucial TLB cache. The system then becomes more efficient, more responsive and faster.</p>
<h2 id="opcache-coming-in-help-in-php-7">OPCache coming in help in PHP 7<a href="#opcache-coming-in-help-in-php-7" class="anchor">#</a></h2>
<p>In PHP7, we worked very hard in improving memory efficiency. That means that we reworked crucial PHP internal structures, to make them fit into CPU caches more efficiently. We worked hard on data spacial locality, that means that more contiguous data fit into CPU caches, and then less memory accesses in main engine parts.
This is the basic concept behind PHP 7 overall performances, and those are pretty easier to get under C than C++ (because C++ is a larger language, more complex and harder to master, together with its compiler).</p>
<p>In addition to that, we pushed the concepts of better memory efficiency even further by also experiencing Kernel huge pages.
In PHP 7, the OPCache extension I <a href="http://jpauli.github.io/2015/03/05/opcache.html">already wrote about for PHP 5</a> has been added features to play with Kernel huge pages. Let's see that together.</p>
<h3 id="asking-for-huge-pages">Asking for huge pages<a href="#asking-for-huge-pages" class="anchor">#</a></h3>
<p>Under many Unix flavors, you are povided with two APIs to play with virtual memory mappings. The so-well-called <code>mmap()</code> function (prefered, because it really plays with memory mappings and can really allocate huge pages if asked for), or <code>madvise()</code> (that just hints (adivses) the Kernel about a memory zone, f.e that the current page should be turned to huge page, with no guaranty it will be done).
First, you need to make sure your OS has huge page support and some free huge pages; If not, allocation will fail. Tune <em>vm.nr_hugepages</em> using sysctl.
Then, cat /proc/meminfo to confirm some huge pages are available.</p>
<pre><code>> cat /proc/meminfo
HugePages_Total:      20
HugePages_Free:       20
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB</code></pre>
<p>Here, 20 huge pages are available, each huge page is 2Mb size (Linux can use huge pages of up to 1Gb on X86/64 platforms, thus I dont recommand such a size for PHP, but RDBMS will benefit from such page sizes).</p>
<p>Then we may use the API. Of course, you can't map a memory segment on a huge page if this latter is not aligned on huge page boundary, so first, you must align your address (what must anyway be done for overall CPU efficiency), then ask for the Kernel to map it using a huge page. We will align it using the C language as in the example, the to-be-aligned buffer comes from the heap, though some alignment functions exist (like <code>posix_memalign()</code>), but for crossplatform compatibility, we won't make use of this latter.</p>
<p>Here is the simple little example :</p>
<pre><code>#include <stdio.h>
#include <sys/mman.h>
#include <string.h>
#include <stdlib.h>

#define ALIGN 1024*1024*2 /* We assume huge pages are 2Mb */
#define SIZE 1024*1024*32 /* Let's allocate 32Mb */

int main(int argc, char *argv[])
{
    void *addr;
    void *buf = NULL;
    void *aligned_buf;

    /* As we're gonna align on 2Mb, we need to allocate 34Mb if
    we want to be sure we can use huge pages on 32Mb total */
    buf = malloc(SIZE + ALIGN);

    if (!buf) {
        perror("Could not allocate memory");
        exit(1);
    }

    printf("buf is at: %p\n", buf);

    */ Align on ALIGN boundary */
    aligned_buf = (void *) ( ((unsigned long)buf + ALIGN - 1) & ~(ALIGN -1) );

    printf("aligned buf: %p\n", aligned_buf);

    /* Turn the address to huge page backed address, using MAP_HUGETLB */
    addr = mmap(aligned_buf, SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE | MAP_HUGETLB | MAP_FIXED, -1, 0);

    if (addr == MAP_FAILED) {
        printf("failed mapping, check address or huge page support\n");
        exit(0);
    }

    printf("mmapped: %p with huge page usage\n", addr);

    return 0;
}</code></pre>
<p>There should be nothing special to explain here, if you are used to C programming. Memory is not freed explicitely because the program will anyway end and is dedicated to explain you the concepts.</p>
<p>If we look at memory information when this process has mapped memory and is about to exit, we can see that reserved huge page have been asked by the kernel :</p>
<pre><code>HugePages_Total:      20
HugePages_Free:       20
HugePages_Rsvd:       16
HugePages_Surp:        0
Hugepagesize:       2048 kB</code></pre>
<p>Reserved, because you remember how virtual memory works : the kernel will not pagein the pages until you write to them. Here, 16 pages are marked reserved, and 16 * 2MB effectively equals the 32Mb segment we mapped using <code>mmap()</code>.</p>
<p>So far so good, this API works like we just demonstrated.</p>
<h3 id="php-7-code-segment-mapped-on-huge-pages">PHP 7 code segment mapped on huge pages<a href="#php-7-code-segment-mapped-on-huge-pages" class="anchor">#</a></h3>
<p>If you look at your PHP 7 code segment, you'll see that this latter is pretty big. On my LP64 X86/64 traditionnal machine, it is about 9Mb large (for a debug build).
Let's see it :</p>
<pre><code>> cat /proc/8435/maps
00400000-00db8000 r-xp 00000000 08:01 4196579                            /home/julien.pauli/php70/nzts/bin/php /* text segment */
00fb8000-01056000 rw-p 009b8000 08:01 4196579                            /home/julien.pauli/php70/nzts/bin/php
01056000-01073000 rw-p 00000000 00:00 0 
02bd0000-02ce8000 rw-p 00000000 00:00 0                                  [heap]
... ... ...</code></pre>
<p>The memory text segment is starting at virtual memory <em>00400000</em> and ending at <em>00db8000</em> (in the above example), it is then about 9Mb large.
That means that the PHP binary machine instructions total 9Mb. Yes, PHP is growing more and more as time goes. It evolves and is added more and more features, meaning more and more C code, translated into more and more CPU low level instructions.</p>
<blockquote>
<p>PHP text segment is 9Mb large so far on LP64. That means that classical compiled (debug) PHP machine instructions actually weigh 9Mb.</p>
</blockquote>
<p>If we look further at this memory segment, we will see that it is mapped by the Kernel using traditional 4Kb large pages :</p>
<pre><code>> cat /proc/8435/smaps
00400000-00db8000 r-xp 00000000 08:01 4196579  /home/julien.pauli/php70/nzts/bin/php
Size:               9952 kB /* VM size */
Rss:                1276 kB /* PM busy load */
Pss:                1276 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:      1276 kB
Private_Dirty:         0 kB
Referenced:         1276 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB /* page size is 4Kb */
MMUPageSize:           4 kB
Locked:                0 kB</code></pre>
<p>Like you can see, the Kernel did not perform transparent huge page usage for this segment. Perhaps it will do it in the future when I further use my PHP process (which pid id 8435 here) ? We don't know, as we are not Kernel programmers and don't want to dive into Kernel code managing huge pages (for this article purpose).</p>
<p>However what we can do, is remap this segment onto a huge page managed segment.
This is what OPCache does.</p>
<p>We may do it, because the code segment does not grow nor shrink while the process leaves. If it could, then a huge page could not be that good. But here, we know the segment will not move, and those 9952Kb of code could be mapped using 4 huge pages (huge page are 2Mb size) and the rest could use traditionnal 4Kb page size.</p>
<h3 id="mapping-the-code-segment-on-huge-pages">Mapping the code segment on huge pages<a href="#mapping-the-code-segment-on-huge-pages" class="anchor">#</a></h3>
<p>If you use PHP 7, your system supports huge pages, if you give <em>opcache.huge_code_pages</em> INI setting the value 1 (default 0), and if PHP is not a webserver module (and thus has its own memory image), then OPCache will try to map your code segment onto huge pages as soon as it starts. This is done in the <code>accel_move_code_to_huge_pages()</code> function.</p>
<p>Let's see that :</p>
<pre><code>static void accel_move_code_to_huge_pages(void)
{
    FILE *f;
    long unsigned int huge_page_size = 2 * 1024 * 1024;

    f = fopen("/proc/self/maps", "r");
    if (f) {
        long unsigned int  start, end, offset, inode;
        char perm[5], dev[6], name[MAXPATHLEN];
        int ret;

        ret = fscanf(f, "%lx-%lx %4s %lx %5s %ld %s\n", &start, &end, perm, &offset, dev, &inode, name);
        if (ret == 7 && perm[0] == 'r' && perm[1] == '-' && perm[2] == 'x' && name[0] == '/') {
            long unsigned int  seg_start = ZEND_MM_ALIGNED_SIZE_EX(start, huge_page_size);
            long unsigned int  seg_end = (end & ~(huge_page_size-1L));

            if (seg_end > seg_start) {
                zend_accel_error(ACCEL_LOG_DEBUG, "remap to huge page %lx-%lx %s \n", seg_start, seg_end, name);
                accel_remap_huge_pages((void*)seg_start, seg_end - seg_start, name, offset + seg_start - start);
            }
        }
        fclose(f);
    }
}</code></pre>
<p>What we see here, is that OPCache opens itself <em>/proc/self/maps</em> to find the code memory segment. It has no other way to do it because accessing such information can't be done without the explicit usage of kernel dependencies, and we don't want to rely on such.
The procfs is nowadays present on every Unix based system, I don't know any serious system not publishing the procfs : so many user tools rely on it today (ps, free, uptime, dmesg, sysctl etc...)</p>
<p>We scan the file to find the code segment, then we align its bounds : start and end, on a huge page boundary address.
Then <code>accel_remap_huge_pages()</code> is called with the aligned bounds.</p>
<pre><code># if defined(MAP_HUGETLB) || defined(MADV_HUGEPAGE)
static int accel_remap_huge_pages(void *start, size_t size, const char *name, size_t offset)
{
    void *ret = MAP_FAILED;
    void *mem;

    mem = mmap(NULL, size,
        PROT_READ | PROT_WRITE,
        MAP_PRIVATE | MAP_ANONYMOUS,
        -1, 0);
    if (mem == MAP_FAILED) {
        return -1;
    }
    memcpy(mem, start, size);

#  ifdef MAP_HUGETLB
    ret = mmap(start, size,
        PROT_READ | PROT_WRITE | PROT_EXEC,
        MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED | MAP_HUGETLB,
        -1, 0);
#  endif
#  ifdef MADV_HUGEPAGE
    if (ret == MAP_FAILED) {
        ret = mmap(start, size,
            PROT_READ | PROT_WRITE | PROT_EXEC,
            MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED,
            -1, 0);
        if (-1 == madvise(start, size, MADV_HUGEPAGE)) {
            munmap(mem, size);
            return -1;
        }
    }
#  endif
    if (ret == start) {
        memcpy(start, mem, size);
        mprotect(start, size, PROT_READ | PROT_EXEC);
    }
    munmap(mem, size);

    return (ret == start) ? 0 : -1;
}
#endif</code></pre>
<p>Easy enough, we create a new temporary buffer (<em>mem</em>) to copy the data into it, then we try to <code>mmap()</code> the aligned buffer onto huge pages.
If that fails, as a second chance, we try to hint the kernel using <code>madvise()</code> version.
Once the segment is mapped, we simply copy back the original data into it, then we return.</p>
<p>Here are the detailed segments :</p>
<pre><code>00400000-00c00000 r-xp 00000000 00:0b 1008956  /anon_hugepage
Size:               8192 kB
Rss:                   0 kB
Pss:                   0 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:         0 kB
Referenced:            0 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:     2048 kB
MMUPageSize:        2048 kB
Locked:                0 kB
00c00000-00db8000 r-xp 00800000 08:01 4196579 /home/julien.pauli/php70/nzts/bin/php
Size:               1760 kB
Rss:                 224 kB
Pss:                 224 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:       224 kB
Private_Dirty:         0 kB
Referenced:          224 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB</code></pre>
<p>8Mb mapped on huge pages, and the rest of the text segment (1760Kb) is mapped with traditionnal 4Kb pages.
Done !</p>
<p>We have just turned our code segment to huge pages. Zend provided me the 3% overall performance improvement under high load.
I myself did not perform tests, but the results are what we expect.</p>
<p>Using huge pages, we require 512 times pages less than with default 4Kb pages.
The TLB cache is then more often used, much more, leading to less memory accesses. And we are talking about the code segment, that means every PHP process machine instruction load the CPU has to perfom, is optimized. Millions of them per seconds, that may lead to interesting overall results, right ?</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h2>
<p>We've seen that PHP 7 OPCache extension has evolved and now allows the Linux user to get more performance by using a now-widely-deployed Kernel memory management technic known as "huge pages". Should you know that big heap applications like RDBMS already performed such an improvement few years ago, like <a href="https://oracle-base.com/articles/linux/configuring-huge-pages-for-oracle-on-linux-64">Oracle</a> or <a href="http://www.postgresql.org/docs/9.4/static/kernel-resources.html">PostgreSQL</a>.</p>
<p>Now PHP does so, with PHP 7 and through the usage of OPCache extension.</p>]]></content>
    </entry>
        <entry>
        <title>PHP strings management</title>
                <id>http://jpauli.github.io//2015/09/18/php-string-management.html</id>
                <updated>2015-09-18T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/09/18/php-string-management.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>Strings management has always been a "problem" to consider when designing a C program. If you think about a tiny self-contained C program, just don't bother with strings, use libc functions, or if you need to support Unicode, use libraries such as ICU.
You may also use libraries such as the <a href="http://bstring.sourceforge.net/">well known bstring</a>, <a href="https://apr.apache.org/docs/apr/2.0/group__apr__strings.html">the APR strings</a> or even <a href="https://developer.gnome.org/glib/2.32/glib-String-Utility-Functions.html">glib strings</a>. Many libraries exist, and once you are a senior C developper, you can easilly build your own library fitting your exact needs.</p>
<p>In C, strings are simple NULL-terminated char arrays, like you know. However, when designing a scripting language such as PHP, the need to manage those strings arises. In management, we think about classical operations, such as concatenation, extension or truncation ; and eventually more advanced concepts, such as special allocation mechanisms, string interning or string compression. Libc answers the easy operations (concat, search, truncate), but complex operations are to be developped by yourself.</p>
<p>Let's see together how strings are implemented into the PHP 5 language core, and the main differences with PHP 7.</p>
<h2 id="the-php-5-way">The PHP 5 way<a href="#the-php-5-way" class="anchor">#</a></h2>
<p>In PHP 5, strings don't have their own C structure. Yes I know, that may seem extremely surprising, but that's the case.
We keep playing the traditional way with C NULL-terminated char arrays, also often written as <em>char *</em>.
However, we support what is called <em>"binary strings"</em> , those are strings that can embed the NULL character.
Strings embeding the NULL char can't be directly passed to libc classical functions anymore, but need to be addressed by special functions (that exist in libc as well) taking care of the length of the string.</p>
<p>Hence PHP 5 memorizes the size of the string, together with the string itself (the <em>char *</em>).
Obviously, as PHP doesn't support Unicode natively, the string stores each C ASCII character, and the length stores the number of characters, as we always assume one printable char = one byte : the plain 50-year-old C concept of a "string", ASCII based. If one graphical character (what Unicode calls "Grapheme") were to be stored in more than one byte, then every concept presented here falls down to just being wrong. We always assume that one graphical character equals one byte (no Unicode support). Also, remember that <em>char *</em> buffers can contain any byte, not just only printable characters.</p>
<blockquote>
<p>One C char equals one byte. This statement is always true, worldwide, whatever the machine / the platform. When not talking about Unicode but plain ASCII, one char = one printable character.</p>
</blockquote>
<p>So, we end-up having something like :</p>
<pre><code>typedef union _zvalue_value {
    long lval;
    double dval;
    struct {
        char *val;     /* C string buffer, NULL terminated */
        int len;      /* String length : num of ASCII chars */
    } str;            /* string structure */
    HashTable *ht;
    zend_object_value obj;
    zend_ast *ast;
} zvalue_value;</code></pre>
<p>I lied a little bit when I said PHP doesn't manage strings using its own structure. In fact in PHP 5, a string is used in the <em>str</em> field of the zval (the PHP variable container).
Graphically, this could give :</p>
<p><img src="../../../img/php-strings/strings_php5.png" alt="strings_php5"></p>
<h3 id="problems-in-the-php-5-way">Problems in the PHP 5 way<a href="#problems-in-the-php-5-way" class="anchor">#</a></h3>
<p>This model has several problems, some are addressed in later PHP 5 versions, and others in the new PHP 7 implementation we'll talk about later.</p>
<h4 id="integer-size">Integer size<a href="#integer-size" class="anchor">#</a></h4>
<p>First thing is that we store the length of the string into an integer, which is platform dependant.
On LP64 (~Linux/Unix), an integer weights 4 bytes, but on ILP64 (SPARC64), it weights 8 bytes. Things are barely the same for the 32 bits variants. So, depending on your platform, PHP will behave differently and have a different memory image, what you wouldn't really expect. That shows a lack of consistency in supporting several platforms (a crucial concept PHP has always tried to carry) and harden debugging.
Also - this is pretty uncommon I assume - but you can't store in PHP's string a string which is larger than the size of the integer, aka in Linux LP64, you can't have strings which length would be over 2^31, even though your CPU line is 64 bits large.</p>
<h4 id="no-uniform-structure">No uniform structure<a href="#no-uniform-structure" class="anchor">#</a></h4>
<p>Second problem : as soon as we don't use the zval container (and its <em>str</em> field), we end-up beeing forced to duplicate the concept.
As we support binary strings nearly everywhere into the engine, it is not rare in PHP 5, to see again the same kind of structure, but taken out of the zval container.
Examples :</p>
<pre><code>struct _zend_class_entry {
    char type;
    const char *name;       /* C string buffer, NULL terminated */
    zend_uint name_length;  /* String length : num of ASCII chars */
...</code></pre>
<p>The above code show a snippet of a PHP class internally : a <em>zend_class_entry</em> structure.
As you can see, this latter also got its own definition of a string : a <em>char *name</em>, and a <em>zend_uint name_length</em> that stores the length.</p>
<p>What about hashtables ?</p>
<pre><code>typedef struct _zend_hash_key {
    const char *arKey;  /* C string buffer, NULL terminated */
    uint nKeyLength;    /* String length : num of ASCII chars */
    ulong h;
} zend_hash_key;</code></pre>
<p>Here again, this <em>zend_hash_key</em> structure is used often when it comes to play with hash tables (very very common use-case) ; and here again, we notice that the concept of "PHP string" is once more duplicated : a <em>const char* arKey</em> and its <em>uint nKeyLength</em>.</p>
<p>Note that in every case, the length is always a typedef that will more-or-less lead to platform integer (<em>zend_uint</em>, <em>uint</em>, <em>int</em>).
Some even being signed, thus dividing by two the size capacity.</p>
<p>So to sum-up this second problem, there is no unified way of representing a string in PHP 5. The concept is always the same : a <em>char*</em> buffer together with its length ; but this concept is not "globally shared and assumed" across all PHP source code, thus many code duplication happens, as well as one last problem.</p>
<h4 id="memory-usage">Memory usage<a href="#memory-usage" class="anchor">#</a></h4>
<p>The last problem is memory consumption.
If PHP meets twice the same string into its life, it will likely store that string twice in memory, or even more than twice.
Add-up every piece of string you can think about, and you'll notice that this is not so little : memory consumption will suffer from the numbers of different copy of the same piece of string in memory.</p>
<p>For example, if two internal layers communicate each other, the top layer passes a string to the bottom layer. If that bottom layer wants to keep the string for itself, to reuse it later for example (with no intention to modify it), well in PHP 5, it has no other way than copying the whole string.
It can't keep the pointer, because the above layer is free to free the pointer whenever it wants to, and also, the bottom layer would like to free that string whenever it wants to, without having the top layer crash in a use-after-free situation.</p>
<p>Just one quick and easy example to illustrate :</p>
<pre><code>static PHP_FUNCTION(session_id)
{
    char *name = NULL;
    int name_len, argc = ZEND_NUM_ARGS();

    if (zend_parse_parameters(argc TSRMLS_CC, "|s", &name, &name_len) == FAILURE) {
        return;
    }

    /* ... ... */

    if (name) {
        if (PS(id)) {
            efree(PS(id));
        }
        PS(id) = estrndup(name, name_len);
    }
}</code></pre>
<p>This is the <code>session_id()</code> PHP function. It is given a string as input (<em>name</em>), and must store it internally in the session module (into <em>PS(id)</em>), to remember and use it later.
This is done by fully duplicating the passed string (the function is <code>estrndup()</code> , this function duplicates a string into memory).
Why duplicate it ? Because if we change the session id again, well, we'll free the last id, but if this last id string were used elsewhere (in your PHP variables), then you will crash reading free'ed memory.
Opposite problem : if we just store the pointer into the session module without duplicating the string it points to, what happens if you - PHP user - destroy the variable this $id was stored in ? We'll end up in the exact same (upside down) situation : Session module is going to use a free()'ed pointer, and then is going to crash.</p>
<p>Those situations, where strings are duplicated just to be kept hot in memory for further usage, happen often in PHP source code. If you dump the heap memory of a PHP process in the middle of its lifetime, you will notice lots of memory bytes that contain the exact same string. This is a pure waste of machine main memory.</p>
<p>To solve this last problem, PHP 5.4 added a well-known-yet-clever concept to the receipe : interned strings.
PHP 7 on its side, reworked in deep the global "string" concept to finally have a very consistent and memory fair solution.</p>
<blockquote>
<p>Before PHP 5.4, there were no solution nor consistency regarding the management of strings into memory. This resulted in poor performances, both in term of CPU and memory usage, especially when the web application is big.</p>
</blockquote>
<h3 id="solutions-implemented-in-php-5-for-strings-management">Solutions implemented in PHP 5 for strings management<a href="#solutions-implemented-in-php-5-for-strings-management" class="anchor">#</a></h3>
<p>PHP 5 tried to address the memory consumption problem, and managed to find a clever solution to it.
For every other problem related in the last chapter just above, only PHP 7 solves them, because their solution require massive breaks in the PHP source code, and massive code rewrite.</p>
<h4 id="interned-strings">Interned strings<a href="#interned-strings" class="anchor">#</a></h4>
<p>Before PHP 5.4 , every problem related to string management is present.
Starting from PHP 5.4 , the concept of "interned strings" was implemented, and resulted in less memory consumption, thus solving one of the exposed problem (the biggest one in my opinion).</p>
<p>But, as you will see, interned strings require sharing a global buffer, something which is by definition not thread safe.
Thus, at the moment, interned strings are not supported by ZTS PHP.</p>
<blockquote>
<p>Interned strings are fully disabled if you run PHP in ZTS mode. You'll then suffer from memory waste in string management compared to non-ZTS.</p>
</blockquote>
<p>What are interned strings ?</p>
<p>If you use your prefered search engine with those terms ("strings interning"), you'll land on many pages defining interned strings. That means that we are facing here a general solution, that is implemented in other programming languages, such as Python or Java, and even in BIG stand-alone softwares, such as your favorite IDE, or your favorite video games ( yes, those latter are "just" some BIG C++ softwares ).</p>
<p>Interned strings basically tells that a same string (f.e "bar"); should never be stored more than once in memory, for one process. Easy enough, isn't it ?
But, how did PHP implement this concept, back in PHP 5.4 ?
Let's see that together.</p>
<blockquote>
<p>Interning a string is ensuring this string will never be stored in memory more than once per process. For softwares managing big strings, or many strings (like PHP does), this can represent a nice memory saving as well as better performances regarding any string manipulation.</p>
</blockquote>
<p>The concept is easy. Whenever we meet a string, instead of creating it with a classical <code>malloc()</code> (we are assuming dynamic strings that can't really be stack allocated), we store the string into a bound buffer and add it to a dictionnary (which is a hashtable). If the string is already present in the dictionnary, the API returns its pointer, effectively preventing us from creating yet another copy of such a string in memory.</p>
<p>However, only persistent strings can be stored in this interned strings buffer, because you know PHP will free the request-bound memory between each request, when we are actually in the process of treating a request, no interned strings must be created as their pointers need to be freed at the end of the request. To accomplish that, we use a snapshot buffer that is reseted to its position at the end of the current request. So interned strings do work for request-scope allocations, but they are less efficient than "persistent" strings that get allocated at PHP startup and reused until PHP dies, because request-allocated interned strings are freed at the end of the current request and thus have a smaller lifecycle.</p>
<p>Here is how we prepare the buffer, at the very early startup stage of PHP (truncated) :</p>
<pre><code>void zend_interned_strings_init(TSRMLS_D)
{
    size_t size = 1024 * 1024;

    CG(interned_strings_start) = malloc(size);

    CG(interned_strings_top) = CG(interned_strings_start);
    CG(interned_strings_snapshot_top) = CG(interned_strings_start);
    CG(interned_strings_end) = CG(interned_strings_start) + size;

    zend_hash_init(&CG(interned_strings), 0, NULL, NULL, 1);

    CG(interned_strings).nTableMask = CG(interned_strings).nTableSize - 1;
    CG(interned_strings).arBuckets = (Bucket **) pecalloc(CG(interned_strings).nTableSize, sizeof(Bucket *), CG(interned_strings).persistent);
}</code></pre>
<p>What you first must spot, is that the interned string buffer is 1Mb large (1024*1024) and cannot be changed by the PHP user (INI setting). Effectively, when this buffer will be full, it will NOT be resized, and from that point the interned strings API will behave like if there is no interned strings : it will lead us to having malloc()ed our strings.</p>
<p>Now, to create an interned string, we internally use <code>zend_new_interned_string()</code> , and not <code>malloc()</code> or <code>strdup()</code> or anything else :</p>
<pre><code>#define IS_INTERNED(s) \
    (((s) >= CG(interned_strings_start)) && ((s) < CG(interned_strings_end)))

static const char *zend_new_interned_string_int(const char *arKey, int nKeyLength, int free_src TSRMLS_DC)
{
    ulong h;
    uint nIndex;
    Bucket *p;

    if (IS_INTERNED(arKey)) {
        return arKey;
    }

    h = zend_inline_hash_func(arKey, nKeyLength);
    nIndex = h & CG(interned_strings).nTableMask;
    p = CG(interned_strings).arBuckets[nIndex];
    while (p != NULL) {
        if ((p->h == h) && (p->nKeyLength == nKeyLength)) {
            if (!memcmp(p->arKey, arKey, nKeyLength)) {
                if (free_src) {
                    efree((void *)arKey);
                }
                return p->arKey;
            }
        }
        p = p->pNext;
    }
    /* ... ... */</code></pre>
<p>As you can see, this API immediately returns the string you want to intern, if this latter is already in the interned string buffer.
If not, it will lookup the interned string hashtable to find if the same string is stored into it. This is a heavy operation, as the hashtable needs to be browsed, and the string needs to be per-byte compared. Both operations will likely invalidate your L1 CPU cache, and possibly your L2 cache as well ; but we only create interned strings when this is necessary and will save performances later (heavilly used string). This is a tradeoff between the work needed to create the string (heavy) and the later work done to fetch back this string and use it (light, and memory fair).
If the same string is found in the hashtable, this latter pointer is returned and the original string buffer can also be freed by the API if we asked it to, passing '1' as last parameter.</p>
<p>Let's continue :</p>
<pre><code>if (CG(interned_strings_top) + ZEND_MM_ALIGNED_SIZE(sizeof(Bucket) + nKeyLength) >=
    CG(interned_strings_end)) {
    /* no memory */
    return arKey;
}</code></pre>
<p>Like I said, if the memory buffer for storing the strings is full, the API returns the pointer you passed to it, effectively doing nothing.
Let's end :</p>
<pre><code>p = (Bucket *) CG(interned_strings_top); /* reserve room from our allocated buffer */
CG(interned_strings_top) += ZEND_MM_ALIGNED_SIZE(sizeof(Bucket) + nKeyLength); /* move up the border */
h = zend_inline_hash_func(arKey, nKeyLength);

p->arKey = (char*)(p+1);
memcpy((char*)p->arKey, arKey, nKeyLength); /* copy the string into the interned string buffer */
if (free_src) {
    efree((void *)arKey); /* free the original string */
}
p->nKeyLength = nKeyLength;
p->h = h;
p->pData = &p->pDataPtr;
p->pDataPtr = p;

/* ... ... */

return p->arKey; /* return the interned string */</code></pre>
<p>And finally, the string is duplicated (<code>memcpy()</code>) from the pointer you provided (<em>arKey</em>), into the HashTable, which Bucket will be allocated from the interned string buffer itself.</p>
<p>As you can see, there is nothing really complicated, just some clever tricks to make any future manipulation of the related string more efficient.
For example, the string hash (<em>h</em> variable) is computed every time we intern a string. This hash will be needed any time the string is used as a key into a hashtable, and this is very likely to happen, so we prefer eating some more CPU cycles now (by computing the hash), than later at runtime when performances will be critical to the user.</p>
<blockquote>
<p>Interning a string is an operation which is done weither when PHP starts, or when it compiles a script, never at execution stage.</p>
</blockquote>
<p>Now we must think about string destruction. As you probably understood, interned strings are shared pointers, and thus should never be freed randomly by someone, because any place elsewhere the pointer is used, will lead to a use-after-free bug.</p>
<p>Thus, when we are given a string and want to free it, we must first ask if this latter is interned.
For this, we don't use <code>efree()</code> (the free() equivalent in PHP's source), but <code>str_efree()</code>, which takes care of interned strings.</p>
<pre><code>#define str_efree(s) do { \
        if (!IS_INTERNED(s)) { \
            efree((char*)s); \
        } \
    } while (0)</code></pre>
<p>We can see that interned strings are effectively NOT destroyed when asked for (because they are shared and used elsewhere).</p>
<p>Also, if you want to duplicate a string pointer for read-only use purpose, use <code>str_estrdup()</code> , instead of <code>estrdup()</code> (which will duplicate the string in memory in anycase). Look :</p>
<pre><code>#define str_estrndup(str, len) \
    (IS_INTERNED(str) ? (str) : estrndup((str), (len)))</code></pre>
<p>Obviously, interned strings refer to shared strings and thus read-only purpose string. Any time you want to modify one of theses strings, for your own usage, you will be required to fully duplicate it in memory and work on your copy. But often, the string is used in a read-only maner, so there should be no need at all to duplicate it in memory if the string is interned (this is the concept).</p>
<blockquote>
<p>Interned strings are both shared + read-only concepts, don't attempt to free() an interned string, nor to modify it directly. The main API call <code>zend_new_interned_string_int()</code> returns a <em>const char*</em> to hint you. If you need to write to the interned string : create a private full copy before, and work on that copy (and <code>efree()</code> it when finished if heap-allocated).</p>
</blockquote>
<p>Have you seen how cleverly interned strings are stored into memory ?
Here is a picture of what the memory layout could look :</p>
<p><img src="../../../img/php-strings/interned_string_buffer_layout.png" alt="interned_string_buffer_layout_php5"></p>
<p>Interned strings are stored into a well known bound buffer, so to check if a pointer holds an interned string, we just have to check if its address is inside the interned string buffer bounds :</p>
<pre><code>#define IS_INTERNED(s) \
    (((s) >= CG(interned_strings_start)) && ((s) < CG(interned_strings_end)))</code></pre>
<p>This is highly performant, as looking up a HashTable any time we want to know if a string is interned or not, is just a no-go for performance, and would slow down the language a lot, as strings are used everywhere into PHP's heart.</p>
<p>So, how to really free an interned string ? You don't do that as a PHP extension writer. The engine will free the whole interned string buffer at once, once it shuts down (end of PHP life, after having treated several requests) :</p>
<pre><code>void zend_interned_strings_dtor(TSRMLS_D)
{
    free(CG(interned_strings).arBuckets);
    free(CG(interned_strings_start));
}</code></pre>
<p>This is once more highly optimized, because the buffer is contiguous address, and the free operation will destroy every piece of interned string at once, instead of one free operation per string ( like in PHP < 5.4).</p>
<p>For request-bound interned strings, the border of the string buffer is simply snapshoted when a request is about to come, and restored when the request has gone, thus, every string created between both operations (during a request) will be taken out of the buffer by simply moving the border of this latter (<em>CG(interned_strings_top)</em>).
At the beginning of the request, we snapshot the upper border of the interned strings buffer :</p>
<pre><code>static void zend_interned_strings_snapshot_int(TSRMLS_D)
{
    CG(interned_strings_snapshot_top) = CG(interned_strings_top);
}</code></pre>
<p>At the end of the request, we restore it, and delete any reference of the strings from our hashtable:</p>
<pre><code>static void zend_interned_strings_restore_int(TSRMLS_D)
{
    Bucket *p;
    int i;

    CG(interned_strings_top) = CG(interned_strings_snapshot_top);

    for (i = 0; i < CG(interned_strings).nTableSize; i++) {
        p = CG(interned_strings).arBuckets[i];
        while (p && p->arKey > CG(interned_strings_top)) {
            CG(interned_strings).nNumOfElements--;
            if (p->pListLast != NULL) {
                p->pListLast->pListNext = p->pListNext;
            } else {
                CG(interned_strings).pListHead = p->pListNext;
            }
            /* ... */
    }
}</code></pre>
<p>Now, to have a concrete example of interned strings usage, let's have a look together at the PHP compiler (which allocates request-bound interned strings) :</p>
<pre><code>void zend_do_begin_class_declaration(const znode *class_token, znode *class_name, const znode *parent_class_name TSRMLS_DC)
{
    /* ... ... */

    new_class_entry = emalloc(sizeof(zend_class_entry));
    new_class_entry->type = ZEND_USER_CLASS;
    new_class_entry->name = zend_new_interned_string(Z_STRVAL(class_name->u.constant), Z_STRLEN(class_name->u.constant) + 1, 1 TSRMLS_CC);
    new_class_entry->name_length = Z_STRLEN(class_name->u.constant);

    /* ... ... */</code></pre>
<p>The code above is triggered when PHP compiles a user class, like <code>class Bar { }</code>
Like you can read, the name of the class will be interned, <code>zend_new_interned_string()</code> is used. It is passed a pointer storing the name of the class as it comes from the parser (class_name->u.constant) , and it will return a new pointer to the same string, but interned. Also, the old pointer will be freed and will become invalid (1 is passed as last parameter to <code>zend_new_interned_string()</code>, which means "free the original pointer so that I don't have to do it myself").</p>
<p>If we continue analyzing the compiler, we'll notice that it does the same thing for many concepts : function names, variable names, constant names, userland PHP strings and more advanced concepts, such as OPArray litterals.</p>
<p>Here is what the string-related memory layout of some PHP script could look like :</p>
<pre><code>class Bar {
    const FOO = "Bar";
    public function foo($var = "foo") {
        return "var";
    }
}</code></pre>
<p><img src="../../../img/php-strings/memory_layout_compiler.png" alt="memory_layout_compiler"></p>
<p>Each piece of string is effectively stored once and only once in memory, and they are all stored into the same contiguous buffer, and not sparsed everywhere in memory, improving CPU cache efficiency.</p>
<h4 id="summary-of-interned-strings">Summary of interned strings<a href="#summary-of-interned-strings" class="anchor">#</a></h4>
<p>Interned strings are a programmatic mechanism designed to store any piece of string (char *) only once in memory. This is a read-only, globally shared concept : one should not change an interned string (usually given as a <em>const char*</em> pointer to prevent that), nor free it.
Also, as the concept involves a global buffer, care should be taken when using a threaded environment. In PHP ZTS, interned strings are simply disabled.</p>
<p>Interned strings have many advantages :</p>
<ul><li>They save memory - this is their first goal - and the save can be huge on big applications, with tons of functions / classes / variables...</li>
<li>Interned string hash is computed only once for all and reused when needed (and it is often needed). This saves lots of CPU cycles at PHP runtime.</li>
<li>Comparing two interned strings ends in comparing two pointers, with no memory scanning at all, which is very performant.</li>
</ul><p>And also drawbacks :</p>
<ul><li>Creating an interned string often requires scanning a hashtable, and sometimes two string buffers (<code>memcmp()</code>); this effort must be worth the expected later gains.</li>
<li>Internal developpers must remember that any string could be interned, and thus should never try to free() it directly (will lead to a crash) nor modify it.</li>
<li>Because the compiler makes use of interned string, it is then slower, but is likely to accelerate your runtime. You must use an OPCode cache solution to fully benefit from interned string advantages.</li>
</ul><blockquote>
<p>The OPCache extension for PHP pushes the interned strings concept even further, by sharing the same interned strings buffer accross several PHP process, and by allowing the user to configure the space of the buffer (using an INI setting) whereas traditionnal PHP doesn't allow that.
You can read more about this <a href="http://jpauli.github.io/2015/03/05/opcache.html#sharing-interned-strings">on the dedicated blog post</a>.</p>
</blockquote>
<h2 id="the-php-7-way">The PHP 7 way<a href="#the-php-7-way" class="anchor">#</a></h2>
<p>PHP 7 changed many things in the way PHP manipulates strings internally.</p>
<h3 id="finally-a-real-shared-structure-and-its-api">Finally a real shared structure and its API<a href="#finally-a-real-shared-structure-and-its-api" class="anchor">#</a></h3>
<p>PHP 7 finally centralized the concept of "strings" into PHP, by designing a structure which is used everywhere PHP uses strings :</p>
<pre><code>struct _zend_string {
    zend_refcounted_h gc;
    zend_ulong        h;
    size_t            len;
    char              val[1];
};</code></pre>
<p>3 things are noticeable in the structure above :</p>
<ul><li>The length of the string is stored using a <em>size_t</em> type.</li>
<li>The real C string is not declared as a <em>char*</em> but as <em>char[1]</em>.</li>
<li>It embeds a refcount : <em>gc</em></li>
</ul><p>As length are typed on a <em>size_t</em> variable, they weight {platform size} bytes ! Whatever the platform. One of the PHP 5 problems is then solved : under a CPU64, string length will be 8 bytes (64 digits) for every platform (this is one of the definition of the C <em>size_t</em> type).</p>
<p>The string is not stored into a <em>char*</em> but a <em>char[1]</em>, this is a C trick called a "struct hack" (look for that term if needed). That allows us to allocate the string buffer together with the <em>zend_string</em> buffer, and save one pointer along having a contiguous area of memory. Performances++</p>
<p>Notice that now, strings embed by default their hash (<em>h</em>). So we compute the hash for a given string only once (usually at compile time), and never after that. In PHP, mainly before interned strings (< 5.4), the same string hash was recomputed every time it is needed, that led to tons of CPU cycles burnt for nothing... Pre-computed hashes have pushed overall PHP performances.</p>
<p>Strings are refcounted ! In PHP 7, strings are refcounted (as well as many other primitive types). That means that interned strings are still relevant, but less : PHP layers can now pass strings from one to the other, as strings are refcounted, we are plainly sure that noone will accidentaly free the string as this latter is still used elsewhere (until doing an error on purpose).</p>
<p>This is the concept behind "reference counting" (search the term if needed) : we now count every place where a string is used (stored), so that it will be freed when nobody uses it anymore.</p>
<p>Let's go back to our session module example. Here is its PHP 5 code recalled to you, followed by its PHP 7 code, just for the part managing strings (what we are looking after) :</p>
<pre><code>/* PHP 5 */
static PHP_FUNCTION(session_id)
{
    char *name = NULL;
    int name_len, argc = ZEND_NUM_ARGS();

    /* ... */

    if (name) {
        if (PS(id)) {
            efree(PS(id));
        }
        PS(id) = estrndup(name, name_len);
    }
}

/* PHP 7 */
static PHP_FUNCTION(session_id)
{
    zend_string *name = NULL;
    int argc = ZEND_NUM_ARGS();

    /* ... */

    if (name) {
        if (PS(id)) {
            zend_string_release(PS(id));
        }
        PS(id) = zend_string_copy(name);
    }
}</code></pre>
<p>Like you can see, we use a <em>zend_string</em> structure in PHP 7, and we use an API : <code>zend_string_release()</code> and <code>zend_string_copy()</code> with it.</p>
<pre><code>static zend_always_inline zend_string *zend_string_copy(zend_string *s)
{
    if (!ZSTR_IS_INTERNED(s)) {
        GC_REFCOUNT(s)++;
    }
    return s;
}
static zend_always_inline void zend_string_release(zend_string *s)
{
    if (!ZSTR_IS_INTERNED(s)) {
        if (--GC_REFCOUNT(s) == 0) {
            pefree(s, GC_FLAGS(s) & IS_STR_PERSISTENT);
        }
    }
}</code></pre>
<p>Just a matter of refcounting : the string is passed from external world to PHP session module, and this latter keeps a reference to the string, never needing to fully copy it in memory, like PHP 5 does.</p>
<p>That is a huge step forward in string management in PHP.</p>
<blockquote>
<p>PHP 7 added a real structure and API for string management internally. This is a huge step forward in consistency, memory savings and performances.</p>
</blockquote>
<p>If you want to grab the zend_string API, it is inlined (for compilation performance reasons) and stored in <a href="http://lxr.php.net/xref/PHP_TRUNK/Zend/zend_string.h">zend_string.h</a>.</p>
<h3 id="interned-strings-still-matter">Interned strings still matter<a href="#interned-strings-still-matter" class="anchor">#</a></h3>
<p>Like we saw, strings in PHP 7 are now reference counted, and that prevents us from needing to fully duplicate them when wanting to store a "copy" of a string from a layer to the other.</p>
<p>But, interned strings still matter. They are still used in PHP 7, and that works nearly the same way as in PHP 5; except that we don't use a special buffer anymore, because we can flag for gargage collector a <em>zend_string</em> as being interned (the structure now allows us to do so).</p>
<p>So, creating an interned string in PHP 7, is creating a <em>zend_string</em> and flag it with <strong>IS_STR_INTERNED</strong>
When releasing a <em>zend_string</em> using <code>zend_string_release()</code>, the API checks if the string is interned and just does nothing if it is the case.
The interned strings are destroyed barely the same way as in PHP 5, simply the process in PHP 7 is optimized thanks to new allocation and garbage collection mechanisms.</p>
<h3 id="a-heavy-migration">A heavy migration<a href="#a-heavy-migration" class="anchor">#</a></h3>
<p>You got it ? Replacing any place in PHP source code ( ~750K lines) where we used a <em>char*/int</em> by a <em>zend_string</em> structure and its API ... was not an easy job.
You can see some <a href="https://github.com/php/php-src/commit/f4cfaf36e23ca47da3e352e1c60909104c059647#diff-b27dcc67dedd7af10b0fb1ec4fd540dc">commit diff</a> that are huge about that.</p>
<p>This could definitely not happen in PHP 5 source codebase, because <em>zend_string</em> simply breaks the ABI, and we don't break the ABI until major versions of PHP.</p>
<p>Migrating PHP extensions is not an easy task neither, <em>zend_string</em> is not the only change in PHP 7, and many big centralized structure have changed significantely in PHP 7. As the ABI is broken between PHP 5 and PHP 7, obviously you'll have to rebuild / redownload your favorite extensions for PHP 7, PHP 5 ones won't load into PHP 7 at all.</p>
<h2 id="conclusions">Conclusions<a href="#conclusions" class="anchor">#</a></h2>
<p>You now have a glance on how PHP manages strings into its heart. Most of the strings come from the PHP compiler: the user PHP scripts. PHP 5, starting with 5.4, introduced interned strings, which is a concept meaning to save memory by not duplicating strings into memory. Before PHP 5.4, string management was plainly missing in PHP.</p>
<p>Starting with PHP 7, PHP added a new structure and a nice reference-counting-based API for string management, resulting in even more memory savings, and nice consistency accross the language.</p>]]></content>
    </entry>
        <entry>
        <title>PHP closures</title>
                <id>http://jpauli.github.io//2015/07/08/php-closures.html</id>
                <updated>2015-07-08T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/07/08/php-closures.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="history">History<a href="#history" class="anchor">#</a></h2>
<p>Back in 2009, when PHP 5.3 got released, a new feature (among many others) were introduced : anonymous functions (also called lambdas or closures).</p>
<p>The feature was very expected, as closures have proved their utility through several other languages, particularly javascript that web developers master.</p>
<p>But there has been a problem when developing such a feature into the heart of PHP : how could we add support for anonymous functions, without rewriting a big part of the engine ?
Because, you probably don't notice it (yet), but adding support for closures was not that simple. You could naively think as the final result would tell you to think : "Well, this is just
a normal function, but with no name". Heh, that's more than that.</p>
<p>Just the fact that this function can be assigned to a variable, must make us think there is a lot of work. Add a new type ? What type would then be the variable, when assigned a closure ?
That's impossible to add a new type, that's way too complex, and that would break for sure tons of things. PHP 5.3 was thought as being a minor, not a major, things could not break like that.</p>
<p>Also, the other problem was how to reuse things ? How to start from classical PHP functions source code base, and extend it in a way that we could add anonymous functions support, without changing
the general meaning of a "function" into the Zend engine ?</p>
<p>Let's see together how Closures have been added to PHP, as usual by turning to the truth : the PHP source code.</p>
<h2 id="the-work-to-do-for-closures-to-get-born">The work to do for closures to get born<a href="#the-work-to-do-for-closures-to-get-born" class="anchor">#</a></h2>
<p>Some work need to be done in the parser (new syntax), in the compiler (new syntax to take care of,  new structures to use, and probably new OPCode to generate), in the executor and elsewhere in the engine.
Let's start.</p>
<h3 id="choose-a-type-use-objects">Choose a type, use objects<a href="#choose-a-type-use-objects" class="anchor">#</a></h3>
<p>If the user would be able to assign a function to a variable, that means we need a type for this variable.</p>
<pre><code>$a = function() { }; /* what type for $a ? */</code></pre>
<p>You know that PHP's anonymous functions are of type "Object", more accurately "object of class Closure".
What is amazing into the Zend engine, is that when the second version has been thought and built - Zend engine 2 (PHP 5.0, 2004) - its creators pushed one big topic very far : the object model.
The Zend engine 2 object model is so extensible, that critical features that have been added later to PHP have been built on top of this 2004-designed object model (2004 is the release date of PHP5, foundations date back from 2001-2002).
Anonymous functions, and PHP 5.5 Generators are two critical features of the PHP language that benefit from the Zend engine 2 object model extensibility, and that could be added thanks to it.</p>
<h3 id="objects-being-callable">Objects being callable<a href="#objects-being-callable" class="anchor">#</a></h3>
<p>Now that we chose the object type, we must patch the engine to tell it that when a function call is made, it should allow it to be made on an object (that wasnt the case before).</p>
<pre><code>$a();
/* Before PHP5.3, $a could only be of type array or string here */</code></pre>
<p>So we need to patch the executor OPCode that is responsible of launching functions, and tell it that now we not only support strings or arrays, but also objects.</p>
<p>But, the problem will then be : what the hell could the engine do with an object given, as it is about to launch a PHP function ?
The answer can only be by using a nicely thought extensibility point of ZE2 : object handlers.</p>
<p>A new object handler has been added in PHP5.3, that every object of every class can take advantage of : the <code>get_closure()</code> handler :</p>
<pre><code>typedef int (*zend_object_get_closure_t)(zval *obj, zend_class_entry **ce_ptr, union _zend_function **fptr_ptr, zval **zobj_ptr TSRMLS_DC);</code></pre>
<p>And with every new handler, usually comes a default implementation of it, that is used when nobody tells to use anything else. It is called <code>zend_std_get_closure()</code></p>
<pre><code>#define ZEND_INVOKE_FUNC_NAME "__invoke"

int zend_std_get_closure(zval *obj, zend_class_entry **ce_ptr, zend_function **fptr_ptr, zval **zobj_ptr TSRMLS_DC)
{
    zend_class_entry *ce;
    if (Z_TYPE_P(obj) != IS_OBJECT) {
        return FAILURE;
    }

    ce = Z_OBJCE_P(obj);

    if (zend_hash_find(&ce->function_table, ZEND_INVOKE_FUNC_NAME, sizeof(ZEND_INVOKE_FUNC_NAME), (void**)fptr_ptr) == FAILURE) {
        return FAILURE;
    }

    *ce_ptr = ce;
    if ((*fptr_ptr)->common.fn_flags & ZEND_ACC_STATIC) {
        if (zobj_ptr) {
            *zobj_ptr = NULL;
        }
    } else {
        if (zobj_ptr) {
            *zobj_ptr = obj;
        }
    }
    return SUCCESS;
}</code></pre>
<p>As you may have spotted it, what this handler does is that it looks up the class function table, to try to find a function named <code>__invoke()</code>. If found, it fills in the <strong>fptr_ptr</strong> pointer the engine is expecting to be given back : that's the pointer to the function to run. What we can notice as well, is that the engine will fill-in <code>ce_ptr</code> and <code>zobj_ptr</code> , which both represent the calling scope and the current object to feed <code>$this</code> in. We'll talk about those later on.</p>
<p>The engine executor makes use of this handler and the function pointer it retrieves, in the OPCode that is dispatched when a dynamic function call is made : <strong>ZEND_INIT_FCALL_BY_NAME</strong>
The engine checks the argument type, against a string representing a function, against an array representing a class and a method to launch, and finally against an object defining a <code>get_closure()</code> handler :</p>
<pre><code>ZEND_VM_HANDLER(59, ZEND_INIT_FCALL_BY_NAME, ANY, CONST|TMP|VAR|CV)
{

/* ... here, code to take care of string and array arguments ... */

} else if (OP2_TYPE != IS_CONST && OP2_TYPE != IS_TMP_VAR &&
    EXPECTED(Z_TYPE_P(function_name) == IS_OBJECT) && /* we are an object ? */
    Z_OBJ_HANDLER_P(function_name, get_closure) && /* we have a get_closure() handler ? */
    Z_OBJ_HANDLER_P(function_name, get_closure)(function_name, &call->called_scope, &call->fbc, &call->object TSRMLS_CC) == SUCCESS) { 
        /* the handler can take care of the call ? */

    /* ... */
}</code></pre>
<h3 id="the-closure-class-and-the-zend-closure-object">The Closure class and the zend_closure object<a href="#the-closure-class-and-the-zend-closure-object" class="anchor">#</a></h3>
<p>So far so good, we know that the engine is able to call a function onto an object, and for that it looks if this object has a <code>get_closure()</code> handler, which default implementation tells it to look for (and make use of) an <code>__invoke()</code> function.</p>
<p>But with just those points, we haven't got closures yet.
What we have however, are the mechanisms needed for objects to be invokable. That is, now, any user may design a class, declare a special magic method "__invoke()", and then run the object from it as a function. Just like this :</p>
<pre><code>class Foo {
    public function __invoke() { }
}

$f = new Foo;
$f();</code></pre>
<p>This will work, because the default <code>zend_std_get_closure()</code> handler is added to every class not telling something else, so it is added to every userland class (class designed using the PHP language).
It can be different when designing PHP extensions, where in we can change this default handler to provide another one of ours.</p>
<p>For real PHP anonymous functions to work, there needs to be a base class every closure will use, and some more magic.
Let's have a tour and meet the <code>zend_closure</code> object.</p>
<pre><code>typedef struct _zend_closure {
    zend_object    std;
    zend_function  func;
    zval          *this_ptr;
    HashTable     *debug_info;
} zend_closure;</code></pre>
<p>This is a Closure into the Zend Engine. A standard object, then a function : <code>zend_function</code>, a pointer to <code>$this</code> into the anonymous function body and some debug info.</p>
<p>That's all needed for the engine to work, but there is once again more work to do. We forgot two things here : what about PHP's reflection ? And what about PHP's anonymous function type ?</p>
<p>To fully support closures and merge their concept into the engine, we need a base <code>Closure</code> class.
That class is just here, because anonymous functions must be of type "something", and the type "object" has been chosen, then a class is needed.
If we don't talk about PHP's reflection, and other PHP features (like the rebinding of <code>$this</code> into closures), what we simply need is a nearly empty class, to support PHP's anonymous functions.
A class which could'nt be user manipulable, that's why we declared it as final, and we changed nearly all its handlers to forbid everything on it. Have a look :</p>
<pre><code>void zend_register_closure_ce(TSRMLS_D)
{
    zend_class_entry ce;

    INIT_CLASS_ENTRY(ce, "Closure", closure_functions); /* the class is named "Closure" */
    zend_ce_closure = zend_register_internal_class(&ce TSRMLS_CC);
    zend_ce_closure->ce_flags |= ZEND_ACC_FINAL_CLASS; /* The class is final */
    zend_ce_closure->create_object = zend_closure_new; /* function to run when an object is created */
    zend_ce_closure->serialize = zend_class_serialize_deny; /* function to run on serialize() call */
    zend_ce_closure->unserialize = zend_class_unserialize_deny; /* function to run on unserialize() call */

    memcpy(&closure_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));
    closure_handlers.get_constructor = zend_closure_get_constructor; /* function to run when fetching the constructor */
    closure_handlers.get_method = zend_closure_get_method; /* function to run when fetching a method */
    closure_handlers.write_property = zend_closure_write_property; /* function to run when willing to write to an attribute */
    closure_handlers.read_property = zend_closure_read_property; /* function to run when willing to read from an attribute */
    closure_handlers.get_property_ptr_ptr = zend_closure_get_property_ptr_ptr; /* function to run when fetching an attribute */
    closure_handlers.has_property = zend_closure_has_property; /* function to run when willing to test for an attribute existence */
    closure_handlers.unset_property = zend_closure_unset_property; /* function to run when willing to unset an attribute */
    closure_handlers.compare_objects = zend_closure_compare_objects; /* function to run when comparing two objects of this class */
    closure_handlers.clone_obj = zend_closure_clone; /* function to run when willing to clone an object of this class */
    closure_handlers.get_debug_info = zend_closure_get_debug_info; /* function to run when var_dump()ing an object of this class*/
    closure_handlers.get_closure = zend_closure_get_closure; /* function to run when willing to launch a method call from an object of this class */
    closure_handlers.get_gc = zend_closure_get_gc; /* function to run when the garbage collector fires in */
}</code></pre>
<p>You can see that when registering this class into the engine (automaticaly done when the engine starts), it provides <code>zend_class_serialize_deny()</code> and <code>zend_class_unserialize_deny()</code>. So it will be impossible to both <code>serialize()</code> and <code>unserialize()</code> any objects of Closure.
Also, the class is declared final (it is added the <strong>ZEND_ACC_FINAL_CLASS</strong> flag), so the PHP user won't be able to extend from it.</p>
<p>And finally, many other handlers are redefined, for example, the <code>get_constructor()</code> handler -which is called by the engine when it needs to create an object from the class- is designed like this :</p>
<pre><code>static zend_function *zend_closure_get_constructor(zval *object TSRMLS_DC)
{
    zend_error(E_RECOVERABLE_ERROR, "Instantiation of 'Closure' is not allowed");
    return NULL;
}</code></pre>
<p>Again, if you try to fetch, read, write or unset an attribute into an object of the Closure class ( that is : a PHP anonymous function), you will be warned :</p>
<pre><code>#define ZEND_CLOSURE_PROPERTY_ERROR() \
zend_error(E_RECOVERABLE_ERROR, "Closure object cannot have properties")

static zval *zend_closure_read_property(zval *object, zval *member, int type, const zend_literal *key TSRMLS_DC)
{
    ZEND_CLOSURE_PROPERTY_ERROR();
    Z_ADDREF(EG(uninitialized_zval));
    return &EG(uninitialized_zval);
}

static void zend_closure_write_property(zval *object, zval *member, zval *value, const zend_literal *key TSRMLS_DC)
{
    ZEND_CLOSURE_PROPERTY_ERROR();
}

static zval **zend_closure_get_property_ptr_ptr(zval *object, zval *member, int type, const zend_literal *key TSRMLS_DC)
{
    ZEND_CLOSURE_PROPERTY_ERROR();
    return NULL;
}

static int zend_closure_has_property(zval *object, zval *member, int has_set_exists, const zend_literal *key TSRMLS_DC)
{
    if (has_set_exists != 2) {
        ZEND_CLOSURE_PROPERTY_ERROR();
    }
    return 0;
}

static void zend_closure_unset_property(zval *object, zval *member, const zend_literal *key TSRMLS_DC)
{
    ZEND_CLOSURE_PROPERTY_ERROR();
}</code></pre>
<p>Try it :</p>
<pre><code>$a = function() { };
$a->foo = 'bar';  /* Fatal error : Closure object cannot have properties */</code></pre>
<p>Ok, here we can see that once more, thanks to Zend engine 2 object handlers, we managed to lock every operations the user could try to perform on such a class (and objects of it).</p>
<h3 id="and-the-magic-happens">And the magic happens<a href="#and-the-magic-happens" class="anchor">#</a></h3>
<p>Now, we're gonna see how the compiler compiles a PHP function into an object of class Closure when it sees it is an anonymous function, and how it is then launched.</p>
<p>When the compiler compiles a function, its main role is to create a <code>zend_function</code> based variable, and fill-in its OPArray. The OPArray represent all the instructions that are part of the function body.
So the compiler starts by firing a <code>zend_do_begin_function_declaration()</code> call , then it parses the body of the function, and finally it calls for <code>zend_do_end_function_declaration()</code> and <code>zend_do_early_binding()</code>. That's true for classical PHP functions.</p>
<p>For anonymous functions though, the steps that change from regular functions is that the compiler will name the function "{closure}" (as it couldn't fetch a name from the syntax, because you know : "anonymous" function) , and it will NOT register that function name into the global function table (this step is done while early binding the function).</p>
<p>So the compiler will compile many anonymous functions, without adding their name to the global function table (obviously : they all got the same name). That seems like leaking and doing useless things. Not really, as the compiler for such functions, will generate a special OPCode for the executor to do some job later : <strong>ZEND_DECLARE_LAMBDA_FUNCTION</strong></p>
<p>Here is the important part of the PHP parser code :</p>
<pre><code>function is_reference { zend_do_begin_lambda_function_declaration(&$$, &$1, $2.op_type, 0 TSRMLS_CC); }
    '(' parameter_list ')' lexical_vars
    '{' inner_statement_list '}' { zend_do_end_function_declaration(&$1 TSRMLS_CC); $$ = $3; }
|   T_STATIC function is_reference { zend_do_begin_lambda_function_declaration(&$$, &$2, $3.op_type, 1 TSRMLS_CC); }
    '(' parameter_list ')' lexical_vars
    '{' inner_statement_list '}' { zend_do_end_function_declaration(&$2 TSRMLS_CC); $$ = $4; }</code></pre>
<p>When meeting an anonymous function, the parser will call for <code>zend_do_begin_lambda_function_declaration()</code> from the compiler. Here it is :</p>
<pre><code>void zend_do_begin_lambda_function_declaration(znode *result, znode *function_token, int return_reference, int is_static TSRMLS_DC)
{
    znode          function_name;
    zend_op_array *current_op_array = CG(active_op_array);
    int            current_op_number = get_next_op_number(CG(active_op_array));
    zend_op       *current_op;

    function_name.op_type = IS_CONST;
    ZVAL_STRINGL(&function_name.u.constant, "{closure}", sizeof("{closure}")-1, 1); /* the function will be named '{closure}' */

    /* classical compilation steps, shared with classical named PHP functions */
    zend_do_begin_function_declaration(function_token, &function_name, 0, return_reference, NULL TSRMLS_CC);

    result->op_type = IS_TMP_VAR;
    result->u.op.var = get_temporary_variable(current_op_array);

    current_op = &current_op_array->opcodes[current_op_number];
    current_op->opcode = ZEND_DECLARE_LAMBDA_FUNCTION; /* OPCode generation */
    zend_del_literal(current_op_array, current_op->op2.constant);
    SET_UNUSED(current_op->op2);
    SET_NODE(current_op->result, result);
    if (is_static) { /* static closures case */
        CG(active_op_array)->fn_flags |= ZEND_ACC_STATIC;
    }
    CG(active_op_array)->fn_flags |= ZEND_ACC_CLOSURE;
}</code></pre>
<p>We can see that the compiler effectively calls for generic function declaration function, <code>zend_do_begin_function_declaration()</code>, but generates an OPCode <strong>ZEND_DECLARE_LAMBDA_FUNCTION</strong>.
This is very different from classical named functions, where no OPCode at all is generated (if the function is not declared conditionnaly), and where the function name is registered into the global function table for it to be looked for later, when called into the executor.</p>
<blockquote>
<p>So, anonymous functions require some runtime job, whereas non-anonymous classical PHP functions don't.</p>
</blockquote>
<p>That means that anonymous functions will be less performant that named ones, because named onces are fully resolved at compile time, and OPCode cache solutions such as OPCache entirely take care of them (preventing the compiler from kicking-in). For anonymous functions, a big job is also done by OPCache, but there still need to go for some runtime job. Don't be scared however, we are talking about very little performance penalty.</p>
<p>What's then in this executor handler ?</p>
<pre><code>ZEND_VM_HANDLER(153, ZEND_DECLARE_LAMBDA_FUNCTION, CONST, UNUSED)
{
    /* ... */

    if (UNEXPECTED((op_array->common.fn_flags & ZEND_ACC_STATIC) || 
            (EX(prev_execute_data) &&
             EX(prev_execute_data)->function_state.function->common.fn_flags & ZEND_ACC_STATIC))) {
        zend_create_closure(&EX_T(opline->result.var).tmp_var, (zend_function *) op_array,  EG(called_scope), NULL TSRMLS_CC);
    } else {
        zend_create_closure(&EX_T(opline->result.var).tmp_var, (zend_function *) op_array,  EG(scope), EG(This) TSRMLS_CC);
    }

    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>If you feel lost into OPCodes and VM executor, please read <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">the dedicated article about those</a></p>
<p>As we can notice, the executor's OPCode handler for <strong>ZEND_DECLARE_LAMBDA_FUNCTION</strong> basically calls for <code>zend_create_closure()</code>, and here the magic happens :</p>
<pre><code>ZEND_API void zend_create_closure(zval *res, zend_function *func, zend_class_entry *scope, zval *this_ptr TSRMLS_DC)
{
    zend_closure *closure;

    object_init_ex(res, zend_ce_closure); /* create a closure object */
    closure = (zend_closure *)zend_object_store_get_object(res TSRMLS_CC);

    closure->func = *func; /* pass its function ; here the belt is buckled */
    closure->func.common.prototype = NULL;
    closure->func.common.fn_flags |= ZEND_ACC_CLOSURE; /* flag the zend_function as beeing of type closure */

    if ((scope == NULL) && (this_ptr != NULL)) {
        scope = zend_ce_closure;
    }

    /* ... */

    closure->this_ptr = NULL;
    closure->func.common.scope = scope;
    if (scope) {
        closure->func.common.fn_flags |= ZEND_ACC_PUBLIC;
        if (this_ptr && (closure->func.common.fn_flags & ZEND_ACC_STATIC) == 0) {
            closure->this_ptr = this_ptr;
            Z_ADDREF_P(this_ptr);
        } else {
            closure->func.common.fn_flags |= ZEND_ACC_STATIC;
        }
    }
}</code></pre>
<p><code>zend_create_closure()</code> is the trick : it creates an object of class Closure, and fill-in the zend_closure's function pointer, the function that itself received as a parameter : this is the function that the compiler compiled : the PHP user function OPArray.</p>
<p>And the belt is buckled !</p>
<p>Have a look at the Closure class's <code>get_closure()</code> handler. Unlike the <code>zend_std_get_closure()</code> handler, this one will not look for an "__invoke()" method in the class, but will fill the function pointer back with the one into the zend_closure, created by <code>zend_create_closure()</code></p>
<pre><code>int zend_closure_get_closure(zval *obj, zend_class_entry **ce_ptr, zend_function **fptr_ptr, zval **zobj_ptr TSRMLS_DC)/
{
    zend_closure *closure;

    if (Z_TYPE_P(obj) != IS_OBJECT) {
        return FAILURE;
    }

    closure = (zend_closure *)zend_object_store_get_object(obj TSRMLS_CC);
    *fptr_ptr = &closure->func; /* here we are, the function to execute is the one that got compiled before */

    if (closure->this_ptr) {
        if (zobj_ptr) {
            *zobj_ptr = closure->this_ptr;
        }
        *ce_ptr = Z_OBJCE_P(closure->this_ptr);
    } else {
        if (zobj_ptr) {
            *zobj_ptr = NULL;
        }
        *ce_ptr = closure->func.common.scope;
    }
    return SUCCESS;
}</code></pre>
<p>And we can see that it binds the scopes as well.</p>
<h3 id="scopes-static-closures-and-rebinding-of-this">Scopes, static closures and rebinding of $this<a href="#scopes-static-closures-and-rebinding-of-this" class="anchor">#</a></h3>
<p>You may remember that in PHP5.3 , it was not possible to access <code>$this</code> into a closure. In fact, you were accessing the <code>$this</code> of the Closure class itself, instead of the <code>$this</code> of the class the anonymous function is defined in.</p>
<p>If you compare the source code of Zend/zend_closures.c for PHP5.3 , and nowadays' PHP 5.6 , you will notice that every reference to <code>$this</code> (internally called "<code>this_ptr</code>") is missing in PHP5.3.
Closures have evolved through PHP versions. Accessing the "real" <code>$this</code> was added in 5.4, as well as the possibility to change the scope of the anonymous function. Let's see that together in detail.</p>
<p>When the compiler creates a standard, named, PHP function ; it looks if this function is declared into a class body. If it's the case, then the function is a method, and must be given the current class as its scope. This is done into the compiler. Here :</p>
<pre><code>void zend_do_begin_function_declaration(znode *function_token, znode *function_name, int is_method, int return_reference, znode *fn_flags_znode TSRMLS_DC)
{
    /* ... */
    op_array.scope = is_method?CG(active_class_entry):NULL;
    /* ... */</code></pre>
<p><code>$this</code> willl then be bound later at runtime (because $this obviously doesn't exist yet at compile time) by the engine which automaticaly creates this variable when a method call is done.</p>
<blockquote>
<p>Remember that in PHP's heart, a method is a function which scope is not NULL, that's all, no other difference (the same zend_function C structure is used, anyway).</p>
</blockquote>
<p>What happens for closures however, is that the current scope (the class) and <code>$this</code> are both bound at runtime, by the <strong>ZEND_DECLARE_LAMBDA_FUNCTION</strong> OPCode. Look :</p>
<pre><code>/* void zend_create_closure(zval *res, zend_function *func, zend_class_entry *scope, zval *this_ptr TSRMLS_DC); */

ZEND_VM_HANDLER(153, ZEND_DECLARE_LAMBDA_FUNCTION, CONST, UNUSED)
{
    /* ... */

    if (UNEXPECTED((op_array->common.fn_flags & ZEND_ACC_STATIC) || 
            (EX(prev_execute_data) &&
             EX(prev_execute_data)->function_state.function->common.fn_flags & ZEND_ACC_STATIC))) {
        /* if we are creating a closure into a static call -or we declared the closure explicitely static- pass the called_scope to the closure body */
        zend_create_closure(&EX_T(opline->result.var).tmp_var, (zend_function *) op_array,  EG(called_scope), NULL TSRMLS_CC);
    } else {
        /* else, pass the object scope to the closure body */
        zend_create_closure(&EX_T(opline->result.var).tmp_var, (zend_function *) op_array,  EG(scope), EG(This) TSRMLS_CC);
    }

    /* ... */
}</code></pre>
<p>This is tricky. When in runtime, when it comes time to create the closure, we browse the previous executor stack frame to see if the last call was static or not. If the last call was a non-static method call, then we extract the <code>$this</code> pointer from this method call, and pass it to the anonymous function.</p>
<pre><code>class Foo {
    public function hello() {
        return function () { };
    }
    public static function world() {
        return function () { };
    }
}

class Bar extends Foo { }

$foo = new Foo;

$closure = $foo->hello(); /* into hello() $this exists, the closure will then be created and bound to this $this and to the class scope */
$closure = Foo::world(); /* world() is a STATIC function, so there will be NO $this passed to the Closure, but only its scope : Foo */
$closure = Bar::world(); /* world() is a STATIC function, so there will be NO $this passed to the Closure, but only its scope : Bar */</code></pre>
<p>That's how its done.</p>
<p>Also, if you spot the parser and the compiler code carefully, you'll notice that an anonymous function can be declared static itself :</p>
<pre><code>$a = static function () { };
/* $a holds a static closure, that will never ever receive any $this into its body */</code></pre>
<p>If the closure is declared static itself, it will never receive any <code>$this</code> pointer, even if we would have declared it into a non static method. This is what we call a "static closure".</p>
<pre><code>class Foo {
    public function hello() {
        return static function () { }; /* let's return a static closure */
    }
}

$foo = new Foo;

$closure = $foo->hello(); /* the $closure has no $this access, because it was declared static itself */</code></pre>
<p>Now let's talk about the scope, that is the current class where in the Closure resides (which is used to check for PPP access).
The scope is the class's which was used for the call to create the closure, like in the example above, with Foo and Bar classes.</p>
<blockquote>
<p>The scope is the current calling class, it is used to check for public/private/protected access rights (PPP).</p>
</blockquote>
<p>Remember that both scope and <code>$this</code> pointer are important, as they will serve when the Closure will get called. They even can be changed at runtime, starting from PHP 5.4, using <code>bind()</code> or <code>bindTo()</code></p>
<pre><code>class Foo { private $a = 42; }
$foo = new Foo;

$closure = function() { var_dump($this->a); };

$foo_closure = $closure->bindTo($foo);

$foo_closure(); /* 42 */</code></pre>
<p>The above code displays 42.</p>
<p>The <code>$closure</code> closure was created out of any context, so its <code>$this</code> and its scope are both NULL. This closure is actually unbound : it has no object scope and can't access any <code>$this</code> variable at the moment.</p>
<p>Using <code>bindTo()</code>, we create another closure from this one, but we explicitely bind its <code>$this</code> variable to the <code>$foo</code> object; thus, calling this new created closure works : it can access a <code>$this</code> now.
But is it allowed to read the private property ? Yes it is, because the scope is also good. <code>bindTo()</code> accepts a second parameter : the scope, which will default to the class of the object passed as first parameter : to us : Foo class. Into Foo, I can access Foo's privates : no problem. Let's change that behavior :</p>
<pre><code>class Foo { private $a = 42; }
$foo = new Foo;

class Bar { }

$closure = function() { var_dump($this->a); };

$foo_closure = $closure->bindTo($foo, 'Bar'); /* Pass the scope of Bar */

$foo_closure(); /* fatal error, accessing a private member */</code></pre>
<p>Now the new closure still has a <code>$this</code> representing <code>$foo</code>, but the scope it will act into is the scope of Bar. Hence, in Bar, you can't access Foo's $a, as both Foo's $a is private, and Bar doesn't even extend Foo.</p>
<p>This scoping functionnality is presented to the PHP user for the first time here. All those mechanisms used to be hidden and automatic before, when you use classical objects and methods , but with closures, things change as closures are by definition functions or methods that can be carried from class to class at runtime : you are then dealing manually with the scopes.</p>
<blockquote>
<p>PHP7 added Closure::call(object $to[, mixed ...$parameters])</p>
</blockquote>
<h3 id="what-about-reflection-and-direct-invoke-calls">What about Reflection and direct __invoke() calls ?<a href="#what-about-reflection-and-direct-invoke-calls" class="anchor">#</a></h3>
<p>All could have been finished if Reflection wouldn't exist...</p>
<p>But Reflection exists, and can do many things. Thus, we need to finalize the Closure class. Because even if the user can't manipulate this class, Reflection can.
Reflection will ask the class for some methods, particularly <code>__invoke()</code> , and we saw together that this <code>Closure::__invoke()</code> simply does not exist, it is not used by PHP's closures, it is short circuited by redefining a <code>get_closure()</code> handler that does the job.</p>
<p>So we need to implement some more handlers for Reflection to be happy. <code>ReflectionFunction::getClosureScopeClass()</code>, <code>ReflectionFunction::getClosure()</code>, <code>ReflectionFunction::isClosure()</code>.</p>
<p>Try this :</p>
<pre><code>var_dump ((new ReflectionClass('Closure'))->getMethods());</code></pre>
<p>You will see <code>__construct()</code> and <code>bind()</code>/<code>bindTo()</code> , but not <code>__invoke()</code>, because the Closure class simply has no <code>__invoke()</code> method.</p>
<p>Now try this :</p>
<pre><code>var_dump ((new ReflectionObject(function(){}))->getMethods());</code></pre>
<p>Here, an <code>__invoke()</code> method  will magically appear. It is faked, faked by the Closure class and a Reflection trick. It is built and specially crafted just to be shown in Reflection's output :</p>
<pre><code>#define ZEND_INVOKE_FUNC_NAME       "__invoke"
ZEND_API zend_function *zend_get_closure_invoke_method(zval *obj TSRMLS_DC)
{
    zend_closure *closure = (zend_closure *)zend_object_store_get_object(obj TSRMLS_CC);
    zend_function *invoke = (zend_function*)emalloc(sizeof(zend_function));
    const zend_uint keep_flags = ZEND_ACC_RETURN_REFERENCE | ZEND_ACC_VARIADIC;

    invoke->common = closure->func.common;
    invoke->type = ZEND_INTERNAL_FUNCTION;
    invoke->internal_function.fn_flags =
        ZEND_ACC_PUBLIC | ZEND_ACC_CALL_VIA_HANDLER | (closure->func.common.fn_flags & keep_flags);
    invoke->internal_function.handler = ZEND_MN(Closure___invoke);
    invoke->internal_function.module = 0;
    invoke->internal_function.scope = zend_ce_closure;
    invoke->internal_function.function_name = estrndup(ZEND_INVOKE_FUNC_NAME, sizeof(ZEND_INVOKE_FUNC_NAME)-1);
    return invoke;
}</code></pre>
<p>This <code>zend_get_closure_invoke_method()</code> that creates a fake <code>__invoke()</code> for the engine, is also used when one directly calls <code>__invoke()</code> on a closure.</p>
<pre><code>$a = function() { };
$a->__invoke();</code></pre>
<p>But you shouldn't do that. Doing this, you instruct the engine to fetch a method, whereas if you were using the <code>$a()</code> syntax, we saw that the engine directly fetches the function to run using the <code>get_closure()</code> handler.
The problem with the explicit <code>__invoke()</code> call is that you turn around, and ask the engine much more work to do. It has to fetch the method, it will then run the <code>get_method()</code> handler on the object, which is of class Closure. Here is its code :</p>
<pre><code>#define ZEND_INVOKE_FUNC_NAME       "__invoke"
static zend_function *zend_closure_get_method(zval **object_ptr, char *method_name, int method_len, const zend_literal *key TSRMLS_DC)
{
    char *lc_name;
    ALLOCA_FLAG(use_heap)

    lc_name = do_alloca(method_len + 1, use_heap);
    zend_str_tolower_copy(lc_name, method_name, method_len);
    if ((method_len == sizeof(ZEND_INVOKE_FUNC_NAME)-1) &&
        memcmp(lc_name, ZEND_INVOKE_FUNC_NAME, sizeof(ZEND_INVOKE_FUNC_NAME)-1) == 0
    ) {
        free_alloca(lc_name, use_heap);
        return zend_get_closure_invoke_method(*object_ptr TSRMLS_CC);
    }
    free_alloca(lc_name, use_heap);
    return std_object_handlers.get_method(object_ptr, method_name, method_len, key TSRMLS_CC);
}</code></pre>
<p>It checks if you call a method named "__invoke", you can't call anything else, as if you do, you jump into the default <code>get_method()</code> handler, which will tell you that the Closure class has no "foobar" method.
So here, we called <code>__invoke()</code>, so we return <code>zend_get_closure_invoke_method()</code> which code we already analyzed. It creates a "fake" <code>__invoke()</code>, but with a real handler :</p>
<pre><code>invoke->internal_function.handler = ZEND_MN(Closure___invoke);</code></pre>
<p>And here is its awful code :</p>
<pre><code>ZEND_METHOD(Closure, __invoke)
{
    zend_function *func = EG(current_execute_data)->function_state.function;
    zval ***arguments;
    zval *closure_result_ptr = NULL;

    arguments = emalloc(sizeof(zval**) * ZEND_NUM_ARGS());
    if (zend_get_parameters_array_ex(ZEND_NUM_ARGS(), arguments) == FAILURE) {
        efree(arguments);
        zend_error(E_RECOVERABLE_ERROR, "Cannot get arguments for calling closure");
        RETVAL_FALSE;
    } else if (call_user_function_ex(CG(function_table), NULL, this_ptr, &closure_result_ptr, ZEND_NUM_ARGS(), arguments, 1, NULL TSRMLS_CC) == FAILURE) {
        RETVAL_FALSE;
    } else if (closure_result_ptr) {
        zval_ptr_dtor(&return_value);
        *return_value_ptr = closure_result_ptr;
    }
    efree(arguments);

    /* destruct the function also, then - we have allocated it in get_method */
    efree((char*)func->internal_function.function_name);
    efree(func);
}</code></pre>
<p>It does a <code>call_user_function()</code>. That is, you launch <code>__invoke()</code>, you pass through 2 handlers ending in running a <code>call_user_function()</code>. Remember that a <code>call_user_function()</code> is really bad for performances, because it basicly pushes another stack frame and another function onto the engine stack, whereas we are already calling a function. It's like using <code>call_user_func()</code> in PHP where using a direct call is possible : just a pure waste of resources, for the exact same result.</p>
<blockquote>
<p>Don't call __invoke() directly on your Closure object, it is better for performance to call the $closure() directly.</p>
</blockquote>
<h2 id="conclusions">Conclusions<a href="#conclusions" class="anchor">#</a></h2>
<p>So, this is how Closures got added to PHP : A new class internal handler has been designed : <code>get_closure()</code>. This latter is called when a function call is done in PHP, onto a variable of type object.
<code>get_closure()</code> is then expected to fill in a <code>zend_function</code> pointer that will be run by the engine (otherwise this latter doesn't know what to do).
But to support anonymous functions, a class was needed : the Closure class was added back in 2009 (PHP5.3), and many of its internal handlers have been redefined so that the PHP user can't do anything with just the Closure class as-is.
Then, the compiler was patched to generate runtime opcode when it meets an anonymous function, that will turn this latter into an object of the Closure class, which when invoked will run the parsed OPArray of such a function.</p>
<p>Clever tricks to add more code onto a 10 year old codebase (Zend Engine 2), without breaking everything everywhere.
The same has been done when generators have been added to PHP5.5, but this time, it is way more complicated that just a Generator class and a new class handler. Perhaps the subject of a next article ?</p>]]></content>
    </entry>
        <entry>
        <title>Segmentation Fault (Computer memory layout)</title>
                <id>http://jpauli.github.io//2015/04/16/segmentation-fault.html</id>
                <updated>2015-04-16T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/04/16/segmentation-fault.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="that-word-segmentation-fault">That word : segmentation fault<a href="#that-word-segmentation-fault" class="anchor">#</a></h2>
<p>A quick word on what's this blog post is about.</p>
<p>When I make mistakes in my code, it very often generates a "segmentation fault" message, often shorten as "segfault". And then, my collegues and managers come to me exclaming "ha!, we got a segfault for you (to fix)".
"All right, that's mine" is often my answer. But, do you really know what a "segmentation fault" is ?.</p>
<p>In addition to that, I could plan in the future to write technical in-depth PHP-memory-related articles, I need my readers to have such knowledge to understand some concepts further explained.</p>
<p>To answer such a question, we'll have to rewind time back in 1960's. I'm going to explain you how a computer works, more accurately how memory is accessed into a modern computer and you'll then understand where this strange message comes from.</p>
<p>What you'll read here is a summary of the basics of computer architecture design, I won't go too far if it's not necessary, and will use well known wordings so that anyone working with a computer everyday can understand such crucial concepts about how the machine works.</p>
<p>Many books exist about computer architecture, if you want to go further into such a subject, I suggest you get some of them and start reading. Also, don't forget to grab one OS Kernel source code and study it, such as the Linux Kernel, or any else.</p>
<blockquote>
<p>We won't rewrite the history here. This post is detailed somehow, but not a full computer architecture class ; some info are missing or (sometimes extremely) simplified.</p>
</blockquote>
<h2 id="some-computer-science-history">Some computer science history<a href="#some-computer-science-history" class="anchor">#</a></h2>
<p>Back in the time, computer were enormous machines, weighting tons, inside what you could find one CPU with something like 16Kb of memory (RAM). We won't go back in time further, that is before the CPU chips era.</p>
<p>So in this period, a computer cost something like $150,000 and could execute exactly one task at a time : it could run one process at a given time.
If we would draw a schema of the memory architecure then, we would draw it like this :</p>
<p><img src="../../../img/segfault/early_systems.png" alt="early_systems"></p>
<p>As you can see, the memory is 16Kb wide, and into it you can find two things :</p>
<ul><li>The Operating System memory area, which is 4Kb wide (f.e)</li>
<li>The actually running process memory area, which is then 12Kb wide (f.e)</li>
</ul><p>The operating system role was, at this time, to simply manage the hardware using CPU interruptions. So the OS needs memory for itself, to copy the data from a device f.e and treat them (PIO mode). Just to display something on the screen needs some main memory, back in this time where video chipsets bundled zero to few kilobytes of memory.</p>
<p>And then, our solo program was running just next to the OS memory, achieving its tasks.</p>
<p>We are fine with that, right ?</p>
<h2 id="sharing-the-machine">Sharing the machine<a href="#sharing-the-machine" class="anchor">#</a></h2>
<p>But one big problem of such a model is that the machine (costing $150,000) could only perform one task at a time, and this task was terribly long to run : entire days, to treat few Kb of data.</p>
<p>At this huge price, it was clearly not possible to buy several machines to perform several treatments at the same time, so people was trying to share the machine resources.
The time of <em>multitasking</em> was born. Keep in mind that it is way too early to talk about multi-CPU machines. How can we make one machine, with one CPU, actually achieve several different tasks ?</p>
<p>The answer was <em>scheduling</em> : when one process was busy waiting for an I/O to come through an interrupt, the CPU would then run another process during this time. We won't talk about scheduling at all (a too wide subject), but about memory.</p>
<p>If a machine can run several process tasks one after the other, then that means that memory would then look something like this (f.e) :</p>
<p><img src="../../../img/segfault/multitasking_memory.png" alt="multitasking_memory"></p>
<p>Both task A and task B memory are stored into the RAM, because copying it back and forth to a disk is a way too heavy process : the data have to stay into RAM, permanently, as their respective tasks still run.</p>
<p>Cool : the scheduler gives some CPU time to A, then B, etc... each accessing its memory area. But wait, there is a problem here.</p>
<p>When one programmer would write the task B's code, it then had to know the memory address bounds. Task B for example, would start from memory 10Kb to memory 12Kb, so every address in the program needs to be hardcoded exactly into those bounds, and if the machine could then run 3 tasks, then the address space would be divided in even more areas, and the memory bounds of task B would then move : B's programmer had to rewrite his program, to use less memory this time, and to rewrite every memory pointer address.</p>
<p>Another problem is clear here : what if task B accessed memory in the task A area ? It is really easy to do so, because when you manipulate pointers, a little mistake in computation lead to a totally different address : task B can access task A's memory and corrupt it (overwrite it). Security as well : what if task A is a very sensitive program playing with very sensitive data ? There is no way to prevent task B from reading task A's memory area.
And last : what if task B does a mistake, and overwrite the OS memory ? From 0Kb to 4Kb, here, it is OS memory, if task B overwrites it, then the OS will crash for sure.</p>
<h2 id="address-space">Address Space<a href="#address-space" class="anchor">#</a></h2>
<p>So, to be able to run several tasks residing in memory, the OS and the hardware must help. One way of helping, is by creating what's called an address space.
An address space is an abstraction of the memory that the OS will give to a process, and this concept is absolutely fundamental, as nowadays, every piece of computer you meet in your life, is designed like that. There exists no other model (in the civilian society, army may retain secrets). You use your personnal computer, you keep typing on your mobile phone's screen, you start your TV, you play with your video game console, and you put your credit card in a cash machine and you ridiculously talk to your glasses or your watch.</p>
<blockquote>
<p>Every system nowadays is organized with a code-stack-heap memory layout like this, in its deepnesses.</p>
</blockquote>
<p>The address space contains everything a task (a process) will need to run :</p>
<ul><li>Its code : its machine instructions the CPU will have to run</li>
<li>Its data : the data the machine instructions will play with</li>
</ul><p>The address space is divided like this :</p>
<p><img src="../../../img/segfault/process_address_space.png" alt="process_address_space"></p>
<ul><li>The <em>stack</em> is the memory area where the program keeps informations about called functions, their arguments and every local variable into the functions.</li>
<li>The <em>heap</em> is the memory area where the program does whatever it wants to, the programmer is absolutely free to do anything he wants in such area.</li>
<li>
<p>The <em>code</em> is the memory area where the CPU instructions of the compiled program will be stored. Those instructions are generated by a compiler, but can be hand written. Note that the code segment is usually divided itself in three parts (Text, Data and BSS), but we don't need to go that far in our analyze.</p>
</li>
<li>The <em>code</em> is fixed size : it is born from a compiler, will weight (in our example picture) 1Kb, and that's it.</li>
<li>The <em>stack</em> however is a resizable zone, as the program runs. When functions get called, the stack expands, when function calls are terminated : the stack expands backwards.</li>
<li>The <em>heap</em> as well is a resizable zone, as the programmer asks memory from the heap (<code>malloc()</code>), this latter will expand forwards, and when the programmer frees back memory (<code>free()</code>), the heap narrows.</li>
</ul><p>As the stack and the heap are expandable zones, they've been located at opposite locations into the whole address space : the stack will grow backwards, and the heap forwards. They are both fully free to grow, each one in the direction of the other. What the OS will have to check is simply that the zones don't overlap at some time, using limits mainly.</p>
<h2 id="memory-virtualization">Memory virtualization<a href="#memory-virtualization" class="anchor">#</a></h2>
<p>If task A has got an address space like the one we saw, and so task B... How can we fit both of them into memory ? That seems weird. Task A address space starts from 0kb to 16Kb and so for task B. Huh...</p>
<p>The trick relies in <strong>virtualization</strong>.</p>
<p>In fact, here is back the picture of both A and B in memory :</p>
<p><img src="../../../img/segfault/multitasking_memory.png" alt="multitasking_memory"></p>
<p>When task A will try to access memory into its own address space at index, let's say 11K, probably somewhere into its own stack, the OS will have to find a trick to actually not load memory index 1500, because in memory, index 11K leads to task B.</p>
<p>In fact, the whole address space every program thinks is memory, is just <strong>virtual memory</strong>. <em>Everything is fake</em>.
In task A memory, memory index for example 11K, is just a fake address. This is a virtual memory address.</p>
<p><strong>Every program running on the machine plays with fake, virtual address</strong>. With the help of some hardware chips, the OS will trick the process when this latter will try to access any zone of memory.</p>
<p>The OS will virtualize memory, and will guarantee every task that it can't access memory is doesn't own : the virtualization of memory has allowed process isolations : task A can't access task B's memory anymore, nether can it access the OS own memory. And everything is totally transparent to the user-level tasks, thanks to tons of complex OS Kernel code.</p>
<p>Thus, the OS will have to come on scene for every process memory demand. It will then have to be very efficient - not to slow down too much the different programs running - and to achieve this it will get helped by the hardware : mainly by the CPU and some electronical device around it, like the MMU (Memory Management Unit).
MMU appeared then in early 70's, with IBM, as separated chips. They are now embed directly into our CPU chips, and are mandatory for any modern OS to run.
In fact, the OS won't have tons of things to do, it will heavilly rely on some hardware specific behaviors that will ease a lot every memory access.</p>
<p>Here is a little C program showing some memory addresses :</p>
<pre><code>#include <stdio.h>
#include <stdlib.h>

int main(int argc, char **argv)
{
    int v = 3;
    printf("Code is at %p \n", (void *)main);
    printf("Stack is at %p \n", (void *)&v);
    printf("Heap is at %p \n", malloc(8));

    return 0;
}</code></pre>
<p>On my LP64 X86_64 machine, it shows :</p>
<pre><code>Code is at 0x40054c 
Stack is at 0x7ffe60a1465c 
Heap is at 0x1ecf010</code></pre>
<p>We can see that the stack is at a very higher address than the heap, and the code is located before the stack, just like we described.</p>
<p>But, every of those 3 addresses are fakes : in the physical memory, at address 0x7ffe60a1465c, there is absolutely not an integer, which value is 3.
Remember, every user-land program manipulates virtual memory addresses, whereas kernel-land programs such as the OS kernel itself (or its hardware drivers code) may manipulate the physical RAM addresses.</p>
<h2 id="translating-addresses">Translating addresses<a href="#translating-addresses" class="anchor">#</a></h2>
<p><strong>Address translation</strong> is the wording behind such a magical technic. The hardware (MMU) will translate every virtual address from a user-land program into the right physical address. That's all.</p>
<p>Thus, the OS will have to remember, for every task running, the correspondence between every of its virtual address, to the physical address. And this is challenging. The OS will have to manage every user-level task memory for every memory-access demand, thus providing a full illusion to the process. Hence, the OS transforms all the physical memory awful reality into a useful, powerful and easy abstraction.</p>
<p>Let's detail that in a simple scenario :</p>
<p>When a process is launched, the OS will book a fixed area of physical memory, let's say 16Kb. It will then save the starting address of such a space, in a special variable called the <em>base</em>. It will set another special variable, called the <em>bounds</em> (or limit) to the width of the space : 16Kb.
The OS will then save those two values into each process table, called the PCB (Process Control Block).</p>
<p>Now, here is a process virtual address space :</p>
<p><img src="../../../img/segfault/process_address_space.png" alt="process_address_space"></p>
<p>And here is its physical image :</p>
<p><img src="../../../img/segfault/memory_virt.png" alt="memory_virt"></p>
<p>The OS chose to store it into physical memory at address range 4K to 20K, thus the base address is set to 4K and the bound/limit is set to 4+16 = 20K.
When this process is scheduled (given some CPU time), the OS reads back both the <em>bound</em> and <em>limit</em> values from the PCB, and copies them into specific CPU registers.
Then the process will run and will try to load for example its virtual address 2K (something into its heap). The CPU will then add to this address the base it has received from the OS. Thus, this process memory access will lead to the physical location 2K + 4K = 6K.</p>
<p><strong>physical address = virtual address + base</strong></p>
<p>If the resulting physical address (6K) is out of the bounds ( -4K|20K- ), that means that the process tried to access invalid memory that it doesnt own : the CPU will then generate an exception, and as the OS did set up an exception handler for that, the OS will be triggered back by the CPU and knows a memory exception has just happened onto the CPU. Its default behavior is then to issue a signal to the faulty processk : a SIGSEGV : a Segmentation Fault, which by default (this can be changed) will terminate the task : the process has crashed about invalid memory access.</p>
<h3 id="memory-relocation">Memory Relocation<a href="#memory-relocation" class="anchor">#</a></h3>
<p>Even better, if task A is unscheduled, that means it is taken out from the CPU because the scheduler asked to run another task now (say task B), when running task B, the OS is free to relocate the entire physical address space of task A.
The OS is given the CPU often when a user task runs. When this latter issues a system call, the control of the CPU is given back to the OS, and before honnoring the system call, the OS is free to do whatever it wants about memory management, like relocating an entire process space into a different physical memory slot.</p>
<p>For this, it is relatively simple : the OS moves the 16K wide area into another 16K wide free space, and simply updates the base and bound variables of the task A. When this latter will be resumed and given back the CPU, the address translation process still works, but it doesn't lead to the same physical address as before.</p>
<p>Task A has noticed nothing, from its point of view, its own address space still starts from 0K up to 16K. The OS and the hardware MMU take full control over every memory access for task A, and they have thrown a complete illusion to it. The programmer behind task A manipulates its allowed virtual addresses, from 0 to 16, and the MMU behind will take care of positionning everything into physical memory.</p>
<p>The memory image, after the move, would then look like this :</p>
<p><img src="../../../img/segfault/process_relocation.png" alt="process_relocation"></p>
<p>It has become very easy to program memory now : a programmer no longer has to wonder where its program will be located in RAM, if another task will run next to his own, and what memory addresses to manipulate : it is taken by hand by the OS, helped with very performant and clever hardware : the Memory Management Unit (MMU).</p>
<h2 id="memory-segmentation">Memory segmentation<a href="#memory-segmentation" class="anchor">#</a></h2>
<p>Notice the appearance of the "segmentation" word : we are close to the explaination of "why 'segmentation fault'".</p>
<p>In the last chapter, we explained about memory translation and rellocation, but the model we used has drawbacks :</p>
<ul><li>We assumed every virtual address space is fixed 16Kb wide. This is obviously not the case in reality.</li>
<li>The OS has to maintain a list of physical memory free slots (16Kb wide), to be able to find a place for any new process asking to start, or to relocating a started process. How to do this efficiently to not slow down all the system ?</li>
<li>As you can see, every process memory image is 16Kb wide, even if the process doesn't use its whole address space, which is very likely. This model clearly wastes a lot of memory, as if a process really consumes say 1KB of memory, its memory image in physical RAM holds 16Kb. Such a waste is called <em>internal fragmentation</em> : the memory is reserved, but never used.</li>
</ul><p>To address some of those problems, we're gonna dive into more complex memory organization from the OS : segmentation.</p>
<p>Segmentation is easy to understand : we widen the concept of "base and bounds" to the three logicial segments of memory : the heap, the code and the stack, of each process - instead of just cosiderating the memory image as one unique entity.</p>
<p>With such a concept, the wasted memory between the stack and the heap, is no longer wasted. Like this :</p>
<p><img src="../../../img/segfault/basic_segments.png" alt="basic_segments"></p>
<p>Now it is easy to notice that the free space in virtual memory for task A is no longer allocated into physical memory, the memory usage has become much more efficient.</p>
<p>The only difference now is that for any task, the OS doesn't have to remember one couple base/bounds, but three of them : one couple for each segment type. The MMU takes care of the translations, just like before, and now supports as well 3 <em>base</em> values and 3 <em>bounds</em>.</p>
<p>For example, here, the task A's heap has a base of 126K and a bound of 2K. When the task A asks to access its virtual address 3Kb, into its heap; the physical address is 3Kb - 2Kb (start of the heap) = 1Kb + 126K (offset) = 127K. 127K is before 128K : this is a valid memory address that can be honored.</p>
<h3 id="segment-sharing">Segment sharing<a href="#segment-sharing" class="anchor">#</a></h3>
<p>Segmenting the physical memory not only solves the problem of free virtual memory not eating any more physical memory, but it also allows to share physical segments through different processe virtual address spaces.</p>
<p>If you run twice the same task, task A for example, the code segment is exactly the same : both tasks run the same CPU instructions. While both tasks will use their own stack and heap, as they treat their own set of data, it is silly to duplicate the code segment of both in memory. The OS can now share it, and save even more memory. Something like this :</p>
<p><img src="../../../img/segfault/shared_seg.png" alt="shared_seg"></p>
<p>On the picture above, both A and B have their own code area into their respective virtual memory space, but under the hood, the OS shared this area into the same physical memory segments.
Both A and B are once more fooled : they absolutely don't see this, for both of them, they own their memory.</p>
<p>To achieve this, the OS has to implement one more feature : segment protection bits.</p>
<p>The OS will, for each physical segment it creates, register the bound/limit for the MMU translation unit to work correctly, but it will also register a permission flag.</p>
<p>As the code is not modifiable, the code segments are all created with the RX permission flag. The process can load those memory areas for eXecution, but any process trying to Write into such memory area, will be shout at by the OS.
The other two segments : heap and stack are RW, the processes can read and write from their own stack/heap , but they can't execute code from it (this prevents program security flaws, where a bad user may want to corrupt the heap or the stack to inject code to run, mainly to be given root access : this is not possible as the heap and stack segments often are not eXecutable. Note that this has not always been the case in history and requires some more hardware support to work efficiently, this is called the "NX bit" under Intel CPU).</p>
<p>Memory segments permissions are changeable at runtime : the task may call for <a href="http://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect()</a> from the OS.</p>
<p>Those memory segments are clearly visible under Linux, use <em>/proc/{pid}/maps</em> or the <em>/usr/bin/pmap</em> utility</p>
<p>Here is an example for PHP :</p>
<pre><code>$ pmap -x 31329
0000000000400000   10300    2004       0 r-x--  php
000000000100e000     832     460      76 rw---  php
00000000010de000     148      72      72 rw---    [ anon ]
000000000197a000    2784    2696    2696 rw---    [ anon ]
00007ff772bc4000      12      12       0 r-x--  libuuid.so.0.0.0
00007ff772bc7000    1020       0       0 -----  libuuid.so.0.0.0
00007ff772cc6000       4       4       4 rw---  libuuid.so.0.0.0
... ...</code></pre>
<p>Here, we have a detail of all the memory mappings. Addresses are virtual, and every memory area permissions are displayed.
Like we can see, every shared object (.so) is mapped into the address space as several mappings (likely code and data), and the code areas are eXecutable, and behind the hood, they are shared into physical memory between every process having mapped such a shared object into its own address space.</p>
<p>This is one enormous advantage of Shared Objects under Linux (and Unixes) : memory savings.</p>
<p>It is possible also to create a shared area leading to a shared physical memory segment, by using the <a href="http://man7.org/linux/man-pages/man2/mmap.2.html">mmap()</a> system call. A 's' letter will then appear next to the area, standing for "shared".</p>
<h3 id="segmentation-limits">Segmentation limits<a href="#segmentation-limits" class="anchor">#</a></h3>
<p>We've seen that segmentation fixed the problem of unused virtual memory space. When a process doesn't use some memory space, this latter is not mapped into physical memory, thanks to segments, that correspond to used memory.</p>
<p>However, that is not entirely true.</p>
<p>What if a process asks for 16Kb of heap ? The OS will likely create a 16Kb wide segment in physical memory. But if the user then frees 2Kb of such memory ? Here, the OS has to shrink down the 16Kb segment, back to 14Kb. What if now the programmer asks for suddenly 30Kb of heap ? The old 14Kb segment now has to grow to 30Kb, but can it do so ? Other segments may now surround our 14Kb segment, preventing it from growing. Then the OS will have to look for a free space of 30Kb, and relocate the segment.</p>
<p><img src="../../../img/segfault/fragmented_memory.png" alt="fragmented_memory"></p>
<p>The big problem with segments, is that they lead to very fragmented physical memory, because they keep growing and shrinking as the user-land tasks ask for memory and release it. The OS then has to maintain a list of free memory holes, and manage them.</p>
<p>Sometimes, the OS by summing up all the free segments, has some space available, but as it is not contiguous, it can't use that space and must refuse memory demands from processes, even if there is space in physical memory. That is a really bad scenario.</p>
<p>The OS can try to compact the memory, by merging all the free areas into one big chunk that could be used in the future to satisfy a memory demand.</p>
<p><img src="../../../img/segfault/compacted_memory.png" alt="compacted_memory"></p>
<p>But such compaction algorithm is really heavy for CPU, and in the meantime, no user process may be given the CPU : the OS is fully working reorganizing its physical memory, thus the system becomes unusable.</p>
<p>Memory segmentation addresses lots of problems about memory management and multitasking, but they also show real weaknesses. Thus, there is a need to enhance the segmentation capabilities and fix those flaws : this is done by another concept : <em>memory paging</em>.</p>
<h2 id="memory-pagination">Memory pagination<a href="#memory-pagination" class="anchor">#</a></h2>
<p>Memory pagination shares some concepts with memory segmentation and tries to address segmentation problems. We saw that the main problem of memory segmentation is that segments will grow and shrink very often, as the user process asks and releases memory. Sometimes, the OS faces a problem in that it can't find a big enough free space to satisfy a user process memory ask, because the physical memory has been so much fragmented with time : it is full of many segments of different sizes, sparsed everywhere in physical memory leading to a highly fragmented physical memory.</p>
<p>Pagination solves this problem with a simple concept : what if every physical allocation the Kernel will perform is fixed-sized ?
Pages are physical memory fixed-size segments, nothing else.
If the OS uses fixed size allocations, it is way easier to manage the space, and the result is that there is no more physical fragmentation.</p>
<p>Let's show an example, once more assuming a tiny 16Kb wide virtual address space, to ease the representation : </p>
<p><img src="../../../img/segfault/paged_virtual_memory.png" alt="paged_virtual_memory"></p>
<p>With pagination, we don't talk about heap, stack or code segments, but we divide the whole process virtual memory into fixed size zones : we call them pages. On the example above, we divided the address space as 4 pages of 4Kb each.</p>
<p>Then, we do the same thing with physical memory.</p>
<p><img src="../../../img/segfault/paged_physical_memory.png" alt="paged_physical_memory"></p>
<p>And the OS simply keeps in what's called the "process page table", the association between one process virtual memory page and the underlying physical page (which we call a "page frame").</p>
<p><img src="../../../img/segfault/paged_memory_layout.png" alt="paged_memory_layout"></p>
<p>With this way of managing memory, there is no more problem in free space management : the page frame is weither mapped (used), or not ; and it is easy for the kernel to find enough pages to satisfy a user process memory request, it simply keeps a free list of page frames, and browse it at every memory demand.</p>
<p>The page is the smallest memory unit the OS can manage. A page (at our level) is indivisible.</p>
<p>With pages, every process is attached a page table that stores address translations. The translations no longer use the "bound" and "limit" values like it used to do with segmentation, but rather use a "virtual page number (VPN)" and an "offset" into this page.</p>
<p>Let's show an example of address translation with pagination. The virtual address space is 16Kb large, thus we need 14 bits to represent an address (2^14 = 16kb). The page size is 4Kb, so we need 4kb (16/4) to select our page :</p>
<p><img src="../../../img/segfault/paged_address_layout.png" alt="paged_address_layout"></p>
<p>Now, when the process wants to load for example address 9438 (out of 16384 possibilities), it gives 10.0100.1101.1110 in binary, leading to this :</p>
<p><img src="../../../img/segfault/paged_address_example.png" alt="paged_address_example"></p>
<p>That is the 1246th byte in virtual page 2 ("0100.1101.1110"th byte in "10"th page). Now, the OS simply has to lookup this process page table, to know what page 2 maps. According to what we suggested, page 2 is the 8k byte in physical memory.
Thus, virtual address 9438 leads to physical address 9442 (8k + 1246 offset). We found our data !</p>
<p>Like we said, there is one page table per process, because each process will have its own address translations, just like with segments. But wait, where are those page tables actually stored ? Guess... : in physical memory yes, where else could they be ?</p>
<p>If page tables are themselves stored into memory, that means that for every memory access, the memory will have to be accessed to fetch the VPN. So with pages, one memory access equals in fact two memory accesses : one to fetch the page table entry, and one to access the "real" data. Knowing that memory accesses are slow, that doesn't seem like a nice solution does it ?</p>
<h2 id="translation-lookaside-buffer-tlb">Translation-lookaside Buffer : TLB<a href="#translation-lookaside-buffer-tlb" class="anchor">#</a></h2>
<p>Using paging as the core mechanism to support virtual memory can lead to high performance overheads. By chopping the address space into small, fixed-sized units (pages), paging requires a large amount of mapping information. Because that mapping information is generally stored in physical memory, paging logically requires an extra memory lookup for each virtual address generated by the program.</p>
<p>And here comes once more the hardware, to accelerate things and help the OS. In pagination, like in segmentation, the hardware will fire and help the OS Kernel to translate addresses in an efficient acceptable way. TLB is part of the MMU, and is just a simple cache of some VPN translations. TLB will prevent the OS from firing a memory access to access the process page table to get the physical memory address from the virtual one.</p>
<p>The hardware MMU will fire at every virtual memory access, extract the VPN from this address, and lookup the TLB if it has a hit for this specific VPN. If it has a hit, well, it just accomplished its role. If it gets a miss, then it will lookup the process page table, and if the memory reference is valid, it will update the TLB so that any further memory access of this page will find a hit in the TLB.</p>
<p>Like any cache, you'd better have a hit than a miss, as the miss situation will trigger a page lookup and will result in a slow memory access.
You'd guess as well that the bigger the pages are, the better it is for a TLB hit situation, but the more wasted space you'll experience in each page. A tradeoff must be found here. Modern kernels use different page sizes, like the Linux Kernel may use what's called "huge pages", pages that are 2Mb large instead of the traditionnal 4Kb large.</p>
<p>Also, you'd better store informations in contiguous memory addresses. If you sparse your data in memory, you'll more likely suffer from TLB misses or TLB beeing full. This is what's called spacial locality efficiency of the TLB : the data immeditely next to yours may be retained in the same physical page, thus benefit from the current memory access from the TLB.</p>
<p>For context switches, the TLB stores also what's called the ASID in each of its entries. This stands for the Address Space Identifier, which is something like a PID. Each process scheduled has its own ASID, then the TLB can manage any process address without risk of invalid addresses coming from other processes.</p>
<p>Here again, if the user process tries to load an invalid address, the address will likely not be stored into the TLB, hence a miss and a lookup into the process page table entry. Here, the address is stored (as every possible translation is stored) but with an invalid bit set. Under X86, each translation uses 4bytes, thus many bits in there are available, and it is not rare to find a valid bit, together with other complex stuff such as a dirty bit, the protection bits, a reference bit etc... If the entry is marked invalid, the OS will trigger by default a SIGSEGV, which leads to a "segmentation fault", even if here, we don't talk about segments anymore.</p>
<p>What you need to know is that paging is pretty more complex in modern OS that what I explained. Modern OS typically use multi level page table entries, multi page sizes as well as a crucial concept we won't explain : page eviction, known as "swaping" (a process where the Kernel exchange pages from memory to disk, to efficiently use main memory and give the illusion to user processes that main memory is unlimited in space).</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h2>
<p>You now know what resides under the "segmentation fault" message. OSes used to use segments to map virtual memory space to physical memory space.
When a user land process wants to access some memory, it issues a demand that the MMU will translate to a physical memory address. But if this address is wrong : out of the bounds of the physical segment, or if the segment protection rights are not good (asking to write to a read-only segment), then the OS by default sends a signal to the faulting process : a SIGSEGV , which has a default handler that kills the process and outputs a message : "Segmentation fault". Under other OSes (guess), it is often reported as a "General protection fault". For Linux, we are lucky to be able to access the source code, here is the place of the source code, for X86/64 platforms, that manages memory access errors : <a href="http://lxr.free-electrons.com/source/arch/x86/mm/fault.c"></a><a href="http://lxr.free-electrons.com/source/arch/x86/mm/fault.c">http://lxr.free-electrons.com/source/arch/x86/mm/fault.c</a> , and for SIGSEGV, its precisely <a href="http://lxr.free-electrons.com/source/arch/x86/mm/fault.c#L731">here</a></p>
<p>If you are interested in the design of segments for X86/64 platforms, you can <a href="http://lxr.free-electrons.com/source/arch/x86/include/asm/segment.h#L8">look at their definition in the Linux Kernel</a>. You will also find interesting stuff about memory paging, which pushes the segmentation of memory way further than classical segments usage.</p>
<p>I liked writing this article, it drove me back in late nineties, when I was programming my first CPUs : <a href="http://www.freescale.com/files/microcontrollers/doc/data_sheet/M68HC11E.pdf">Motorola 68HC11</a> using C, VHDL and direct Assembly. I did not program a virtual memory management OS myself but used physical addresses directly (such a CPU did not need such complex mechanisms). Then I turned to Web ; but my first knowledge come from electronics, the systems we make use of everyday... Exciting.</p>]]></content>
    </entry>
        <entry>
        <title>Exceptional PHP (PHP 5)</title>
                <id>http://jpauli.github.io//2015/04/09/exceptional-php.html</id>
                <updated>2015-04-09T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/04/09/exceptional-php.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="php-exceptions-in-short">PHP Exceptions in short<a href="#php-exceptions-in-short" class="anchor">#</a></h2>
<p>Back in 2004, PHP 5 came out with a new model object. This latter allows PHP users to make use of a well known OO paradigm : Exceptions.
The Exceptions model has then not been really reworked. PHP 5.3 introduced stacked Exceptions, which is a very nice improvement in stack traces analysis, and PHP 5.5 added the "<em>finally</em>" feature.
As you know how Exceptions work with PHP, because you are a heavy user of the PHP language, let me show you how this big feature works in the PHP source code, into the Zend Engine : how it's been implemented.</p>
<h2 id="exception-this-so-particular-class">Exception : this so particular class<a href="#exception-this-so-particular-class" class="anchor">#</a></h2>
<p>You know that the Exception class (and all of its possible children) is very special into the engine, because it is the only one that may react with the <em>try-throw-catch-finally</em> PHP language constructs.
Also, you know the Exception class automagically builds a stacktrace when an object is built from it.
Let's recall its structure :</p>
<pre><code>> php --rc Exception
Class [ <internal:Core> class Exception ] {

  - Constants [0] { }

  - Static properties [0] { }

  - Static methods [0] { }

  - Properties [7] {
    Property [ <default> protected $message ]
    Property [ <default> private $string ]
    Property [ <default> protected $code ]
    Property [ <default> protected $file ]
    Property [ <default> protected $line ]
    Property [ <default> private $trace ]
    Property [ <default> private $previous ]
  }

  - Methods [10] {
    Method [ <internal:Core> final private method __clone ] {
    }

    Method [ <internal:Core, ctor> public method __construct ] {

      - Parameters [3] {
        Parameter #0 [ <optional> $message ]
        Parameter #1 [ <optional> $code ]
        Parameter #2 [ <optional> $previous ]
      }
    }

    Method [ <internal:Core> final public method getMessage ] {
    }

    Method [ <internal:Core> final public method getCode ] {
    }

    Method [ <internal:Core> final public method getFile ] {
    }

    Method [ <internal:Core> final public method getLine ] {
    }

    Method [ <internal:Core> final public method getTrace ] {
    }

    Method [ <internal:Core> final public method getPrevious ] {
    }

    Method [ <internal:Core> final public method getTraceAsString ] {
    }

    Method [ <internal:Core> public method __toString ] {
    }
  }
}</code></pre>
<p>As you can see, lots of methods are final : you may not change the default behavior, dictated by the engine source code.
You cannot clone Exceptions, and if you extend the class, some attributes are private : you can't change them.</p>
<p>This is because the engine expects some well defined behavior when it comes to play with an Exception object, or one of its children.</p>
<p>You also know that Exception is the base class of every other exceptions, SPL ones, foobar ones, or yours. This has changed in PHP 7 where every Exception must implement a new Throwable interface, and where the engine itself can now convert fatal errors into exceptions.
Exceptions are checked when one wants to throw something, for PHP extensions one must call <code>zend_throw_exception_object()</code>, and for PHP userland code the compiler will anyway lead to this same function (when meeting the <code>throw</code> keyword especially):</p>
<pre><code>ZEND_API void zend_throw_exception_object(zval *exception TSRMLS_DC)
{
    zend_class_entry *exception_ce;

    if (exception == NULL || Z_TYPE_P(exception) != IS_OBJECT) {
        zend_error(E_ERROR, "Need to supply an object when throwing an exception");
    }

    exception_ce = Z_OBJCE_P(exception);

    if (!exception_ce || !instanceof_function(exception_ce, default_exception_ce TSRMLS_CC)) {
        zend_error(E_ERROR, "Exceptions must be valid objects derived from the Exception base class");
    }
    zend_throw_exception_internal(exception TSRMLS_CC);
}</code></pre>
<p>So, you can't throw something which is not an object, and you can't throw an object which doesn't have the Exception class as an ancestor. Things are somewhat "locked" here.</p>
<h2 id="a-little-tour-of-exception-s-internals">A little tour of Exception's internals<a href="#a-little-tour-of-exception-s-internals" class="anchor">#</a></h2>
<p>Internally, Exceptions are nothing more than objects. They however define custom Zend Engine object handlers, which provide them this so particular behavior.
When the engine starts, among many other boots, it boots the exceptions by calling <code>zend_register_default_exception()</code> :</p>
<pre><code>void zend_register_default_exception(TSRMLS_D)
{
    zend_class_entry ce;

    INIT_CLASS_ENTRY(ce, "Exception", default_exception_functions);
    default_exception_ce = zend_register_internal_class(&ce TSRMLS_CC);
    default_exception_ce->create_object = zend_default_exception_new;
    memcpy(&default_exception_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));
    default_exception_handlers.clone_obj = NULL;

    /* ... */
}</code></pre>
<p>As we can see, this function registers the Exception class, and puts the clone handler to NULL. That means (somehow) that the Exception class is not clonable. Also, the <code>__clone()</code> method which is added to the class (not shown here) is passed final, so that you can't redefine it, Exceptions are not clonable, that's a fact.</p>
<p>We can notice as well that we overwrite the <em>create_object</em> handler. This handler is triggered when an object will be created from the class, and before the userland constructor : <code>__construct()</code>.
That means that even if you extend the class, redefine the constructor, and forget to call the parent one, the Exception object will be just right to the eyes of the engine.
Here is the <em>create_object</em> handler :</p>
<pre><code>static zend_object_value zend_default_exception_new_ex(zend_class_entry *class_type, int skip_top_traces TSRMLS_DC)
{
    zval obj;
    zend_object *object;
    zval *trace;

    Z_OBJVAL(obj) = zend_objects_new(&object, class_type TSRMLS_CC);
    Z_OBJ_HT(obj) = &default_exception_handlers;

    object_properties_init(object, class_type);

    ALLOC_ZVAL(trace);
    Z_UNSET_ISREF_P(trace);
    Z_SET_REFCOUNT_P(trace, 0);
    zend_fetch_debug_backtrace(trace, skip_top_traces, 0, 0 TSRMLS_CC);

    zend_update_property_string(default_exception_ce, &obj, "file", sizeof("file")-1, zend_get_executed_filename(TSRMLS_C) TSRMLS_CC);
    zend_update_property_long(default_exception_ce, &obj, "line", sizeof("line")-1, zend_get_executed_lineno(TSRMLS_C) TSRMLS_CC);
    zend_update_property(default_exception_ce, &obj, "trace", sizeof("trace")-1, trace TSRMLS_CC);

    return Z_OBJVAL(obj);
}</code></pre>
<p>What is interesting to note, is that we fetch the backtrace (<code>zend_fetch_debug_backtrace()</code>) immediately when the object is created, and <em>not</em> when the object is thrown.
Have a look :</p>
<pre><code>function bar(Exception $a)
{
    throw $a;
}
function baz($a)
{
    throw new Exception('foo');
}
function foo($a)
{
    return new Exception('foo');
}
$b = foo('a');

bar($b); /* first */
baz($b); /* second */</code></pre>
<p><code>bar()</code> and <code>baz()</code> cant be run following as <code>bar()</code> will throw an exception and stop the script. But if you run this code with only <code>bar()</code> call, you get this</p>
<pre><code>Fatal error: Uncaught exception 'Exception' with message 'foo' in /tmp/php.php:13
Stack trace:
#0 /tmp/php.php(15): foo('a')
#1 {main}
  thrown in /tmp/php.php on line 13</code></pre>
<p>But with a call to <code>baz()</code> instead of <code>bar()</code>, you'll get this :</p>
<pre><code>Fatal error: Uncaught exception 'Exception' with message 'foo' in /tmp/php.php:9
Stack trace:
#0 /tmp/php.php(17): baz(Object(Exception))
#1 {main}
  thrown in /tmp/php.php on line 9</code></pre>
<p>As you can see, the line numbers in the stack trace are not the same, they always match the Exception construction and not the Exception throw.</p>
<h2 id="exceptions-into-the-zend-virtual-machine-executor">Exceptions into the Zend Virtual Machine Executor<a href="#exceptions-into-the-zend-virtual-machine-executor" class="anchor">#</a></h2>
<p>If you don't know how the Zend Virtual Machine Executor works, you should read <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">the related article</a>.
Now that you have a glance on how the executor works, well, Exceptions are not hard to understand.</p>
<h3 id="throwing-an-exception">Throwing an Exception<a href="#throwing-an-exception" class="anchor">#</a></h3>
<p>To throw an Exception, one may use the <code>throw</code> PHP keyword, compiled as a <code>ZEND_THROW</code> OPCode.
<code>ZEND_THROW</code> simply gets the exception, and adds it into the <em>engine executor exception slot</em>. This slot is alone : either there is an exception into it, or not. There can't be several exceptions into the slot, the basic line is binary : whether or not there is an exception pending (not 2, 3 or 42).</p>
<p>The slot is accessible using the <code>EG(exception)</code> macro. If it is NULL : no exception have been thrown so far.
Here is <code>ZEND_THROW</code>, simplified :</p>
<pre><code>ZEND_VM_HANDLER(108, ZEND_THROW, CONST|TMP|VAR|CV, ANY)
{
    /* ... */
    zend_exception_save(TSRMLS_C);
    ALLOC_ZVAL(exception);
    INIT_PZVAL_COPY(exception, value);
    if (!IS_OP1_TMP_FREE()) {
        zval_copy_ctor(exception);
    }

    zend_throw_exception_object(exception TSRMLS_CC);
    zend_exception_restore(TSRMLS_C);
    /* ... */
}</code></pre>
<p>So basically things are easy, the executor code leads to <code>zend_throw_exception_object()</code> , which will quickly lead to <code>zend_throw_exception_internal()</code> :</p>
<pre><code>void zend_throw_exception_internal(zval *exception TSRMLS_DC)
{
    if (exception != NULL) {
        zval *previous = EG(exception);
        zend_exception_set_previous(exception, EG(exception) TSRMLS_CC);
        EG(exception) = exception; /* Fill in the executor slot */
        if (previous) {
            return;
        }
    }
    if (!EG(current_execute_data)) {
        if(EG(exception)) {
            zend_exception_error(EG(exception), E_ERROR TSRMLS_CC);
        }
        zend_error(E_ERROR, "Exception thrown without a stack frame");
    }

    /* ... */

    /* Change the VM path next to execute */
    EG(opline_before_exception) = EG(current_execute_data)->opline;
    EG(current_execute_data)->opline = EG(exception_op);
}</code></pre>
<p>That's it : <code>EG(exception)</code> is beeing filled with the thrown exception. And the very important things are the two last lines.</p>
<pre><code>/* Change the VM path next to execute */
EG(opline_before_exception) = EG(current_execute_data)->opline;
EG(current_execute_data)->opline = EG(exception_op);</code></pre>
<p>We just threw an Exception, so now, the engine is not expected to continue on the next instruction like if nothing had happened, but to treat the exception : run the catch block (if any), run the finally block (if any), or continue running if none of those blocks are present.</p>
<p>This is done by changing the opline of the executor, and making it point to <code>EG(exception_op)</code>, which value is always the same : <code>ZEND_HANDLE_EXCEPTION</code></p>
<h3 id="handling-an-exception">Handling an Exception<a href="#handling-an-exception" class="anchor">#</a></h3>
<p>So now, whatever was compiled next (whatever the PHP lines of code following the <code>throw</code> keyword), the engine will run <code>ZEND_HANDLE_EXCEPTION</code>.</p>
<p>This handler is a little bit big, because of some memory management routines. Simplified, it gives this :</p>
<pre><code>ZEND_VM_HANDLER(149, ZEND_HANDLE_EXCEPTION, ANY, ANY)
{
    zend_uint op_num = EG(opline_before_exception)-EG(active_op_array)->opcodes;
    int i;
    zend_uint catch_op_num = 0, finally_op_num = 0;
    void **stack_frame;

    /* ... */

    for (i=0; i<EG(active_op_array)->last_try_catch; i++) {
        if (EG(active_op_array)->try_catch_array[i].try_op > op_num) {
            /* further blocks will not be relevant... */
            break;
        }
        if (op_num < EG(active_op_array)->try_catch_array[i].catch_op) {
            catch_op_num = EX(op_array)->try_catch_array[i].catch_op;
        }
        if (op_num < EG(active_op_array)->try_catch_array[i].finally_op) {
            finally_op_num = EX(op_array)->try_catch_array[i].finally_op;
        }
    }

    /* ... */
}</code></pre>
<p>We can see that this Zend Virtual Machine Executor handler's job is to find into the OPArray the very next <code>catch</code> block and <code>finally</code> block. Don't forget that such blocks may be nested : you can nest <em>try-catch-finally</em> structures, and it would be better in such case to run the <em>catch</em> block corresponding to the right <em>try</em> wouldn't it ?</p>
<p>So we search for the next catch block as <em>catch_op_num</em> (if any), and the next finally block as <em>finally_op_num</em> (if any).
The procedure is fast, because the compiler already filled-in the index of the <em>last_try_catch</em>, and every try-catch block is compiled into the <em>try_catch_array</em> of the current OPArray : the executor has here a little job to do, all the hard work has been computed by the compiler earlier.</p>
<h3 id="catch">Catch<a href="#catch" class="anchor">#</a></h3>
<p>Continuing the source code of <code>ZEND_HANDLE_EXCEPTION</code> :</p>
<pre><code>/* ... */

/* Treat finally, as it is alone (no fetchable catch block) */
if (finally_op_num && (!catch_op_num || catch_op_num >= finally_op_num)) {
    zend_exception_save(TSRMLS_C);
    EX(fast_ret) = NULL;
    ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[finally_op_num]);
    ZEND_VM_CONTINUE();
} else if (catch_op_num) { /* Treat the catch block, as it is here and fetchable */
    ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[catch_op_num]);
    ZEND_VM_CONTINUE();
} else { /* leave, as there is no catch block nor finally block to fetch and treat */
    if (UNEXPECTED((EX(op_array)->fn_flags & ZEND_ACC_GENERATOR) != 0)) {
        ZEND_VM_DISPATCH_TO_HANDLER(ZEND_GENERATOR_RETURN);
    } else {
        ZEND_VM_DISPATCH_TO_HELPER(zend_leave_helper);
    }
}</code></pre>
<p>Well, this is now very clear.
If there is a finally block and no catch block, or if the catch block appears after the finally block, make the executor jump to the finally block, and run it</p>
<pre><code>ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[finally_op_num]);
ZEND_VM_CONTINUE();</code></pre>
<p>If there is no finally block but a catch block, make the executor jump to this catch block, and run it</p>
<pre><code>ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[catch_op_num]);
ZEND_VM_CONTINUE();</code></pre>
<p>Else, no catch nor finally ? Then make the executor runs the <code>zend_leave_helper</code>, which will basically acts like a <code>return</code> statement : it will stop the current execution and return from it, quickly leading to the "Uncaught Exception" error.</p>
<p>The catch block is compiled as a <code>ZEND_CATCH</code> opcode. This latter will barely fetch the Exception class you declared into your catch block, and browse its inheritence tree to see if it will run the block or not.</p>
<pre><code>ZEND_VM_HANDLER(107, ZEND_CATCH, CONST, CV)
{
    /* ... */
    catch_ce = zend_fetch_class_by_name(Z_STRVAL_P(opline->op1.zv), Z_STRLEN_P(opline->op1.zv), opline->op1.literal + 1, ZEND_FETCH_CLASS_NO_AUTOLOAD TSRMLS_CC);

    ce = Z_OBJCE_P(EG(exception));

    if (ce != catch_ce) { /* This is not our exception ? */
        if (!instanceof_function(ce, catch_ce TSRMLS_CC)) { /* This is not one of its ancestor ? */
            if (opline->result.num) {
                zend_throw_exception_internal(NULL TSRMLS_CC); /* rethrow the exception */
                HANDLE_EXCEPTION();
            }
            ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[opline->extended_value]);
            ZEND_VM_CONTINUE();
        }
    }
    exception = EG(exception);
    /* ... */
    if (UNEXPECTED(EG(exception) != exception)) {
        Z_ADDREF_P(EG(exception));
        HANDLE_EXCEPTION();
    } else { /* This is our exception, let's treat that catch block */
        EG(exception) = NULL;
        ZEND_VM_NEXT_OPCODE();
    }
}</code></pre>
<p>So here, we try to load the class which is declared into the catch block, without triggering the autoload (this was a change from PHP 5.0 which triggered the autoload).</p>
<p>If it is the right class, or one of its ancestor : this catch block is ours, we must run its code : we then use <code>ZEND_VM_NEXT_OPCODE()</code> to tell the executor to fetch the next instruction and run it.</p>
<p>If it is not our Exception, then we must not run this current catch block : it is not ours. We then "rethrow" the Exception internally : <code>zend_throw_exception_internal()</code>. That will make the VM Executor re-run the <code>ZEND_HANDLE_EXCEPTION</code> OPCode, but this time, starting from our catch block : it will then re-do its operation, considerating the (eventually) next catch block , etc.. etc... until it finds the right catch block (if any) to run code from.</p>
<p>Important thing : if it is our catch block and we run its code, we reset the exception slot : <code>EG(exception) = NULL;</code></p>
<h3 id="finally">finally<a href="#finally" class="anchor">#</a></h3>
<p><em>Finally</em> is harder to understand and has not been trivial to add to PHP 5.5, it is full of hacks.</p>
<p>The problem is that after having run the <em>finally</em> block, we must weither continue execution if a catch treated the exception, or stop the execution if the Exception was actually uncaught.</p>
<p>To achieve this, we introduced two new OPCodes in PHP 5.5, just for the <em>finally</em> feature : <code>ZEND_FAST_CALL</code> and <code>ZEND_FAST_RETURN</code>, and we also play with <code>ZEND_JMP</code>.</p>
<p>So here is the code the Zend Compiler generates for finally block :</p>
<pre><code>void zend_do_finally(znode *finally_token TSRMLS_DC)
{
    zend_op *opline = get_next_op(CG(active_op_array) TSRMLS_CC);

    finally_token->u.op.opline_num = get_next_op_number(CG(active_op_array));
    /* call the the "finally" block */
    opline->opcode = ZEND_FAST_CALL;
    SET_UNUSED(opline->op1);
    opline->op1.opline_num = finally_token->u.op.opline_num + 1;
    SET_UNUSED(opline->op2);
    /* jump to code after the "finally" block,
     * the actual jump address is going to be set in zend_do_end_finally()
     */
    opline = get_next_op(CG(active_op_array) TSRMLS_CC);
    opline->opcode = ZEND_JMP;
    SET_UNUSED(opline->op1);
    SET_UNUSED(opline->op2);

    CG(context).in_finally++;
}

void zend_do_end_finally(znode *try_token, znode* catch_token, znode *finally_token TSRMLS_DC)
{
    if (catch_token->op_type == IS_UNUSED && finally_token->op_type == IS_UNUSED) {
        zend_error(E_COMPILE_ERROR, "Cannot use try without catch or finally");
    }
    if (finally_token->op_type != IS_UNUSED) {
        zend_op *opline;

        CG(active_op_array)->try_catch_array[try_token->u.op.opline_num].finally_op = finally_token->u.op.opline_num + 1;
        CG(active_op_array)->try_catch_array[try_token->u.op.opline_num].finally_end = get_next_op_number(CG(active_op_array));
        CG(active_op_array)->has_finally_block = 1;

        opline = get_next_op(CG(active_op_array) TSRMLS_CC);
        opline->opcode = ZEND_FAST_RET;
        SET_UNUSED(opline->op1);
        SET_UNUSED(opline->op2);

        CG(active_op_array)->opcodes[finally_token->u.op.opline_num].op1.opline_num = get_next_op_number(CG(active_op_array));

        CG(context).in_finally--;
    }
}</code></pre>
<p>What the compiler does is simple :</p>
<ul><li>When we meet a finally block, we generate a <code>ZEND_FAST_CALL</code> plus a <code>ZEND_JMP</code></li>
<li>We keep compiling the instructions into the finally block, normally, nothing to say</li>
<li>At the end of the finally block, we generate a <code>ZEND_FAST_RET</code> OPCode</li>
</ul><p>We have just wrapped the finally block between two markers that will help the executor to find its path.</p>
<p>Here is a simplified compiler output :</p>
<pre><code>try {
    throw new Exception('foo');
} catch (Exception $e) {
    echo "catch block";
} finally {
    echo 'finally block';
}

echo "end";

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
         4    > THROW                                         0          $1
   5     5*     JMP                                                      ->8
         6  >   CATCH                                         8          'Exception', !0
   6     7      ECHO                                                     'catch+block'
   7     8      FAST_CALL                                                ->10
         9    > JMP                                                      ->12
   8    10*     ECHO                                                     'finally+block'
   9    11*     FAST_RET                                                 
  11    12  >   ECHO                                                     'end'
  12    13    > RETURN                                                   1</code></pre>
<p>When the executor comes to run the finally block, it then first runs the <code>ZEND_FAST_CALL</code> OPCode, it looks like this :</p>
<pre><code>ZEND_VM_HANDLER(162, ZEND_FAST_CALL, ANY, ANY)
{
    USE_OPLINE

    if ((opline->extended_value & ZEND_FAST_CALL_FROM_CATCH) &&
        UNEXPECTED(EG(prev_exception) != NULL)) {
        /* in case of unhandled exception jump to catch block instead of finally */
        ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[opline->op2.opline_num]);
        ZEND_VM_CONTINUE();
    }
    EX(fast_ret) = opline;
    ZEND_VM_SET_OPCODE(opline->op1.jmp_addr);
    ZEND_VM_CONTINUE();
}</code></pre>
<p>What we do in the normal flow, is memorize the current opcode beeing dispatched, that is ourselves : <code>ZEND_FAST_CALL</code>, we save this OPCode index (into the OPArray) using <code>EX(fast_ret)</code>.
Then, we make the executor go to the OPCode stored into a jump address computed by the compiler : we make the executor run the finally block, just normally.</p>
<p>The trick is that this finally block is finished by a <code>ZEND_FAST_RET</code> OPCode, the compiler generated it as we saw. Here it is :</p>
<pre><code>ZEND_VM_HANDLER(163, ZEND_FAST_RET, ANY, ANY)
{
    if (EX(fast_ret)) {
        ZEND_VM_SET_OPCODE(EX(fast_ret) + 1);
        if ((EX(fast_ret)->extended_value & ZEND_FAST_CALL_FROM_FINALLY)) {
            EX(fast_ret) = &EX(op_array)->opcodes[EX(fast_ret)->op2.opline_num];
        }
        ZEND_VM_CONTINUE();
    } else {
        /* special case for unhandled exceptions */
        USE_OPLINE

        if (opline->extended_value == ZEND_FAST_RET_TO_FINALLY) {
            ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[opline->op2.opline_num]);
            ZEND_VM_CONTINUE();
        } else if (opline->extended_value == ZEND_FAST_RET_TO_CATCH) {
            zend_exception_restore(TSRMLS_C);
            ZEND_VM_SET_OPCODE(&EX(op_array)->opcodes[opline->op2.opline_num]);
            ZEND_VM_CONTINUE();
        } else if (UNEXPECTED((EX(op_array)->fn_flags & ZEND_ACC_GENERATOR) != 0)) {
            zend_exception_restore(TSRMLS_C);
            ZEND_VM_DISPATCH_TO_HANDLER(ZEND_GENERATOR_RETURN);
        } else {
            zend_exception_restore(TSRMLS_C);
            ZEND_VM_DISPATCH_TO_HELPER(zend_leave_helper);
        }
    }
}</code></pre>
<p>So here now, if the exception was caught, <code>EX(fast_ret)</code> is still here. We fall into the <code>if</code> part and tell the executor to run the next OPCode using <code>ZEND_VM_SET_OPCODE(EX(fast_ret) + 1);</code> , and this next OPCode is a <code>ZEND_JMP</code> that will make it jump after the finally block.</p>
<p>If the exception was uncaught, that is we ran the finally block but no catch before, <code>ZEND_HANDLE_EXCEPTION</code> will have erased <code>EX(fast_ret)</code> setting it to NULL, we then fall into the <code>else</code> part and will barely return.</p>
<h3 id="uncaught-exceptions">Uncaught Exceptions<a href="#uncaught-exceptions" class="anchor">#</a></h3>
<p>Uncaught Exceptions are easy to understand. Like we have seen in the past chapters, uncaught exceptions are managed by the executor calling <code>zend_leave_helper</code> , which will make it return from the current execute context.</p>
<p>At the end of the just-run context, we simply sniff the <em>exception slot</em>. If it is filled in with an exception, well, this one has not been handled (caught).
We then whether call the user exception handler, or generate our fatal error with a call to <code>zend_exception_error()</code> :</p>
<pre><code>/* ... */
if (EG(exception)) {
    if (EG(user_exception_handler)) {
        zval *orig_user_exception_handler;
        zval **params[1], *retval2, *old_exception;
        old_exception = EG(exception);
        EG(exception) = NULL;
        params[0] = &old_exception;
        orig_user_exception_handler = EG(user_exception_handler);
        if (call_user_function_ex(CG(function_table), NULL, orig_user_exception_handler, &retval2, 1, params, 1, NULL TSRMLS_CC) == SUCCESS) {
            if (retval2 != NULL) {
                zval_ptr_dtor(&retval2);
            }
            if (EG(exception)) {
                zval_ptr_dtor(&EG(exception));
                EG(exception) = NULL;
            }
            zval_ptr_dtor(&old_exception);
        } else {
            EG(exception) = old_exception;
            zend_exception_error(EG(exception), E_ERROR TSRMLS_CC);
        }
    } else {
        zend_exception_error(EG(exception), E_ERROR TSRMLS_CC);
    }
}</code></pre>
<p>Note also that if we failed calling the user exception handler, we end with a fatal error about uncaught exception as well.</p>
<h2 id="php-exceptions-tips-and-tricks">PHP Exceptions tips and tricks<a href="#php-exceptions-tips-and-tricks" class="anchor">#</a></h2>
<p>Ok, here we go. Like always, PHP is not perfect, and can't be either. There are some scenarios that are known to be a little bit strange.</p>
<h3 id="stack-traces">Stack traces<a href="#stack-traces" class="anchor">#</a></h3>
<p>We've seen that the stack trace generation -which itself is a heavy and complex subject into the Zend Engine- is generated when the Exception object gets constructed. The stack trace is added to the <code>trace</code> private attribute. This is to be remembered, because now, when you will try to serialize an Exception (if you want to), then any of its attribute will get serialized (that's PHP default behavior you know about), but what about this <code>trace</code> attribute ?
The trick is that this latter may not be serializable, if the stack trace of the Exception contains something which is not serializable, like a SimpleXMLElement object, or a PDO one.</p>
<p>Have a look :</p>
<pre><code>$xml = new SimpleXMLElement('<foo></foo>');

function hey($arg)
{
  $s = serialize(new Exception());
}

hey($xml);</code></pre>
<p>This code lead to this error :</p>
<pre><code>Fatal error: Uncaught exception 'Exception' with message 'Serialization of 'SimpleXMLElement' is not allowed' in foo.php</code></pre>
<p>Now you know why. If you want to serialize Exception for whatever reason, take care that the stack trace into the Exception object may be huge and not serializable.</p>
<h3 id="exception-thrown-without-a-stack-frame">Exception thrown without a stack frame<a href="#exception-thrown-without-a-stack-frame" class="anchor">#</a></h3>
<p>This used to be a strange behavior in PHP < 5.3. Since PHP 5.3 however, this error should not show again with vanilla PHP, but some badly designed custom extensions could still lead to such an error message to appear.</p>
<h3 id="using-reflection-to-crash-php-with-exceptions">Using Reflection to crash PHP with Exceptions.<a href="#using-reflection-to-crash-php-with-exceptions" class="anchor">#</a></h3>
<p>This code crashes the engine :</p>
<pre><code>$e  = new ReflectionClass('Exception');
$ex = new Exception('foo');

$file = $e->getProperty('trace');
$file->setAccessible(true);
$file->setValue($ex, new stdclass);

throw $ex;</code></pre>
<p>And this is perfectly normal if you followed the whole article.
The Exception class (object), is a very particular object that the Engine will manipulate internally for its own work.
The engine does not expect the Exception object to have its <code>trace</code> property beeing something else that a well formed array.
If you use the reflection API to change one of its private member's type, you are very likely to generate bad behavior, such as memory access failures into the engine, and crash it like the script above does.</p>
<p>We have been reported such a bug in the past, and we decided not to fix it, mainly for always the same reasons here :</p>
<ul><li>This is a very tricky use case, which may not be used everyday</li>
<li>This code snippet trying to change the Exception internals brings nothing useful but is clearly hackish</li>
<li>Fixing such a case would lead to a massive code change all over the engine, which tells us it is not worth the use case, too uncommon.</li>
</ul><p>PHP is a tradeoff you know, like every computer program.</p>
<h2 id="end">End<a href="#end" class="anchor">#</a></h2>
<p>This post tried to explain you how Exceptions have been handled into the engine. We saw some Zend Compiler generated code, and analyzed Zend Executor handlers code to understand how things work into the VM.
As you know, the Zend VM is a big dispatcher loop which control flow may be altered at any time, using some macros such as <code>ZEND_VM_SET_OPCODE()</code>, <code>ZEND_VM_RETURN()</code> etc...
That's how Exceptions have been designed; with a little bit more tricky <em>finally</em> feature, requiring some extra OPCodes and some JMP playings.</p>
<p>Once more, the goal was to have a nice feature, usefull to people, but also performant : we've seen that once more, many hard and slow work is done into the compiler : <em>try-catch-finally</em> OPCode browsing loops, jump address computations, etc...
We can then say that Exceptions are not a slow feature into PHP, but a well optimized one. You may use them whenever you want, take care however of some little bit strange but uncommon behaviors about them.</p>]]></content>
    </entry>
        <entry>
        <title>Zoom on PHP objects and classes (PHP 5)</title>
                <id>http://jpauli.github.io//2015/03/24/zoom-on-php-objects.html</id>
                <updated>2015-03-24T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/03/24/zoom-on-php-objects.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="php-objects-introduction">PHP objects introduction<a href="#php-objects-introduction" class="anchor">#</a></h2>
<p>Everybody uses objects nowadays. Something that was not that easy to bet on when PHP 5 got released 10 years ago (2005).
I still remember this day, I wasn't involved in internals code yet, so I didn't know much things about how all this big machine
could work. But I had to note at this time, when using this new release of the language, that jumps had been made compared to old
PHP 4.
The major point advanced for PHP 5 adoption was : "it has a new very powerful object model". That wasn't lies.
Today, 10 years later, something like 90% of the PHP source code involving objects haven't changed since PHP 5.0.
That shows how resulted this object model was when released. Sure it got improved through time, with new features especially.</p>
<p>Here, I will show you as usual how all this stuff works internally. The goal is always the same : you understand and master
what happens in the low level, to make a better usage of the language everyday.
Also, I will show you how memory usage has been really worked hard about objects, and how objects are nice about memory, compared
to equivalent arrays (when possible).</p>
<p>We will focus on PHP 5, starting with PHP 5.4, for this article. The statements will be true for 5.5 and 5.6, which have changed
nearly nothing in object model internals. This is not the case of PHP 5.3, which has a less resulted object model, nice improvements (both in term of user features, and general performances) were added back in PHP 5.4.</p>
<p>About PHP 7, the object model has not been reworked deeply, only tidy up things on
surface. Why ? Because we don't need to : it works. Of course, userland features were added but here we don't care about those : only the
internal design (the truth) scores :-)</p>
<h2 id="starter-example">Starter example<a href="#starter-example" class="anchor">#</a></h2>
<p>Ok so let's start with some synthetic benchmarks to demonstrate things :</p>
<pre><code>class Foo {
    public $a = "foobarstring";
    public $b;
    public $c = ['some', 'values'];
}

for ($i=0; $i<1000; $i++) {
    $m = memory_get_usage();
    ${'var'.$i} = new Foo;
    echo memory_get_usage() - $m"\n";
}</code></pre>
<p>This code declares a simple 3 attributes class, and then in a loop, it creates 1000 objects of this class, showing the memory usage diff
between allocations.</p>
<p>That are 262 bytes diff at every object creation (LP64). Creating an object of class Foo, plus creating a PHP variable to store the object into it, allocate 262 bytes in PHP's heap memory (LP64).</p>
<p>Let's try now to turn this object into an equivalent array, some kind of :</p>
<pre><code>for ($i=0; $i<1000; $i++) {
    $m = memory_get_usage();
    ${'var'.$i} = [['some', 'values'], null, 'foobarstring'];
    echo memory_get_usage() - $m . "\n";
}</code></pre>
<p>The array embeds the same values : an array, a null and a foobar string.
The difference between arrays creation is 1160 bytes (LP64) : that is something like 4 to 5 times more memory eaten.</p>
<p>Let's do another quick bench :</p>
<pre><code>$class = <<<'CL'
class Foo {
    public $a = "foobarstring";
    public $b;
    public $c = ['some', 'values'];
}
CL;
echo memory_get_usage() . "\n";
eval($class);
echo memory_get_usage() . "\n";</code></pre>
<p>As class declaration is honorred at compile time, we use an <code>eval()</code> statement to declare it at runtime and measure - with the PHP memory manager - its memory usage - just for it - we haven't created any object of it in this code (yet).</p>
<p>The diff memory is 2216 bytes, aka about 2Kb (assuming LP64).</p>
<p>Now, we are going to dive into PHP's sources to show you what happens, and to confirm our practice by some theory. </p>
<h2 id="it-all-begins-with-a-class">It all begins with a class...<a href="#it-all-begins-with-a-class" class="anchor">#</a></h2>
<p>A class is represented internally by the <em>zend_class_entry</em> structure. Here it is :</p>
<pre><code>struct _zend_class_entry {
    char type;
    const char *name;
    zend_uint name_length;
    struct _zend_class_entry *parent;
    int refcount;
    zend_uint ce_flags;

    HashTable function_table;
    HashTable properties_info;
    zval **default_properties_table;
    zval **default_static_members_table;
    zval **static_members_table;
    HashTable constants_table;
    int default_properties_count;
    int default_static_members_count;

    union _zend_function *constructor;
    union _zend_function *destructor;
    union _zend_function *clone;
    union _zend_function *__get;
    union _zend_function *__set;
    union _zend_function *__unset;
    union _zend_function *__isset;
    union _zend_function *__call;
    union _zend_function *__callstatic;
    union _zend_function *__tostring;
    union _zend_function *serialize_func;
    union _zend_function *unserialize_func;

    zend_class_iterator_funcs iterator_funcs;

    /* handlers */
    zend_object_value (*create_object)(zend_class_entry *class_type TSRMLS_DC);
    zend_object_iterator *(*get_iterator)(zend_class_entry *ce, zval *object, int by_ref TSRMLS_DC);
    int (*interface_gets_implemented)(zend_class_entry *iface, zend_class_entry *class_type TSRMLS_DC); /* a class implements this interface */
    union _zend_function *(*get_static_method)(zend_class_entry *ce, char* method, int method_len TSRMLS_DC);

    /* serializer callbacks */
    int (*serialize)(zval *object, unsigned char **buffer, zend_uint *buf_len, zend_serialize_data *data TSRMLS_DC);
    int (*unserialize)(zval **object, zend_class_entry *ce, const unsigned char *buf, zend_uint buf_len, zend_unserialize_data *data TSRMLS_DC);

    zend_class_entry **interfaces;
    zend_uint num_interfaces;

    zend_class_entry **traits;
    zend_uint num_traits;
    zend_trait_alias **trait_aliases;
    zend_trait_precedence **trait_precedences;

    union {
        struct {
            const char *filename;
            zend_uint line_start;
            zend_uint line_end;
            const char *doc_comment;
            zend_uint doc_comment_len;
        } user;
        struct {
            const struct _zend_function_entry *builtin_functions;
            struct _zend_module_entry *module;
        } internal;
    } info;
};</code></pre>
<p>Huge isn't it ? Its size, assuming an LP64 platform, is <strong>568 bytes</strong>.</p>
<blockquote>
<p>Everytime PHP needs to declare a class, it must allocate a <em>zend_class_entry</em>, and that will raise its memory heap usage of barely half a kilobyte, just for the class structure, not talking about everything behind it.</p>
</blockquote>
<p>And of course that is not finished, because like you can see, this <em>zend_class_entry</em> structure is full of pointers, that need to be allocated.</p>
<blockquote>
<p>The first thing one may remember is that a PHP class (not a PHP object), is a "heavy" thing to store in memory.
In fact, classes are much more heavy in memory that related future objects to create from it.</p>
</blockquote>
<p>Also, a class is not alone : it declares attributes (static or not, whatever), methods and constants.
Those will consume memory as well. For methods, the computation is not really easy to make, but obviously, the bigger the method body, the more memory this method will eat, because the bigger its OPArray will be. Also, static variables declared into a method (if any) will eat memory.</p>
<blockquote>
<p>Internally a method is strictly the same as a function, there is no difference in term of performance or memory usage in both.</p>
</blockquote>
<p>Then come the attributes. Those later will also allocate memory, depending on their default values : an integer will be light, but a big static array will eat more memory.</p>
<p>There is a last thing to take care of, which is detailed into the <em>zend_class_entry</em> source code as well : PHP comments.
PHP comments, also known as annotations, are strings, in C : <em>char *</em> buffers, and they need to be allocated and are really easy to compute, as in C not using Unicode like PHP does : <strong>one character = one byte</strong>. For more information about how PHP manages strings internally, please read the <a href="http://jpauli.github.io/2015/09/18/php-string-management.html">dedicated article</a>.</p>
<blockquote>
<p>The more annotations you have in your class, the more memory will be eaten when the class is created (parsed). Same thing for methods or attributes.</p>
</blockquote>
<p>The <em>doc_comment</em> field is used and retains the class annotations. For methods : their structure also has a <em>doc_comment</em> field, and same for attributes.</p>
<h3 id="user-classes-vs-internal-classes">User classes VS internal classes<a href="#user-classes-vs-internal-classes" class="anchor">#</a></h3>
<p>Everybody spotted it : a user class is a class defined using PHP, an internal class in a class defined hacking PHP's source, or provided by any extension.</p>
<blockquote>
<p>The biggest difference to know, is that user classes allocate request-bound memory whereas internal classes allocate "permanent" memory</p>
</blockquote>
<p>That means that when PHP finishes to treat the actual web HTTP request, it will deallocate and destroy every user classes it knows, to leave the room blank for the next request. This is known as <em>the share nothing architecture</em>, this is how PHP has been designed since the begining, and there is no plan to change it.</p>
<p>So everytime you start a request and make PHP parse classes : it allocates memory for your class. Then you use your class, and then PHP destroys everything about it.
So you really should be sure to use every class you declared, if not : you are wasting memory.
Use an autoloader, because autoloaders delay class parsing/declaration at runtime, when PHP really needs the dedicated class.
An autoloader will slow down runtime, but will be smart about your process memory usage, as it will not be triggered if the class is not actually really used.</p>
<p>This is not the case at all for internal classes : their memory is allocated permanently, weither or not they will ever be used, and they will only be destroyed when PHP itself will die : when it has finished treating the number of requests you asked it for (assuming web SAPI, like PHP-FPM f.e), usually, a PHP web worker treats several thousands of requests before dying.
That's a point why internal classes are more performant than user classes. (Only static attributes will be destroyed at the end of every request, nothing more).</p>
<pre><code>if (EG(full_tables_cleanup)) {
    zend_hash_reverse_apply(EG(function_table), (apply_func_t) clean_non_persistent_function_full TSRMLS_CC);
    zend_hash_reverse_apply(EG(class_table), (apply_func_t) clean_non_persistent_class_full TSRMLS_CC);
} else {
    zend_hash_reverse_apply(EG(function_table), (apply_func_t) clean_non_persistent_function TSRMLS_CC);
    zend_hash_reverse_apply(EG(class_table), (apply_func_t) clean_non_persistent_class TSRMLS_CC);
}

static int clean_non_persistent_class(zend_class_entry **ce TSRMLS_DC)
{
    return ((*ce)->type == ZEND_INTERNAL_CLASS) ? ZEND_HASH_APPLY_STOP : ZEND_HASH_APPLY_REMOVE;
}</code></pre>
<p>Note that even with an OPCode cache, like OPCache, class creation and destruction still happen at every request for user declared classes. OPCache only speeds up those two steps.</p>
<blockquote>
<p>Internal class are more performant than user declared classes, just by the fact that they get allocated only once for all, whereas userland declared classes need to be destroyed and reloaded at every request. Internal classes also got many possibilities not available to user classes.</p>
</blockquote>
<p>So you have noted, if you activate many PHP extensions that each declare many classes, but you just use a small part of them : you are wasting memory as well.
Remember that PHP extensions declare their classes at the time PHP starts, even if in later requests to come those classes will not be used.
That's why we usually tell users to not keep enabled PHP extensions they just don't use : that's a pure memory waste, especially if the extension declares many classes (among other things extension may allocate as well).</p>
<h3 id="classes-interfaces-or-traits-are-all-the-same">Classes, interfaces or traits are all the same<a href="#classes-interfaces-or-traits-are-all-the-same" class="anchor">#</a></h3>
<p>PHP uses the same <em>zend_class_entry</em> structure internally to manage PHP classes, PHP interfaces and PHP traits.
So everytime you declare an interface or a trait, the <em>zend_class_entry</em> will be used as well.</p>
<blockquote>
<p>Internally, PHP classes, interfaces and traits are managed by the exact same structure : <em>zend_class_entry</em></p>
</blockquote>
<p>And as you've seen, the structure is heavy.
Sometimes in code, users declare interfaces to be able to use their name in PHP catch blocks. That allows them to catch one kind of exception only.
Something like this :</p>
<pre><code>interface BarException { }
class MyException extends Exception implements BarException { }

try {
    $foo->bar():
} catch (BarException $e) { }</code></pre>
<p>What is pitty here, is that nearly one kilobyte is used, just to declare the <em>BarException</em> interface. Exactly 912 bytes (LP64) :</p>
<pre><code>$class = <<<'CL'
interface Bar { }
CL;
$m = memory_get_usage();
eval($class);
echo memory_get_usage() - $m . "\n"; /* 912 bytes */</code></pre>
<p>I'm not telling it is bad, nor silly, I'm not blaming anyone nor anything. I just show you facts you perhaps were not aware of.</p>
<p>So remember, internally, classes and interfaces (and traits), are exactly used the same way. Simply, an interface will not be able to be added attributes, the PHP parser or compiler will forbid this to you, but the <em>zend_class_entry</em> structure is still used, just that its <em>static_members_table</em> and other fields will not be allocated pointers, that's all.</p>
<blockquote>
<p>Declaring a class or an equivalent trait or equivalent interface, will barely use the same memory amount, as internally, those 3 concepts share the same structure.</p>
</blockquote>
<h3 id="class-binding">Class binding<a href="#class-binding" class="anchor">#</a></h3>
<p>Class binding is a hidden thing PHP users are usually not aware of, until they wonder how things work.
This concept is yet really important to understand, we could define it as "the process that prepares a class and every piece of related data for it to be fully usable by the PHP user".</p>
<p>This process is very easy and cheap when we talk about a single class, that is a class not extending anyone, not using any trait, and not implementing any interface. The binding process for such class will be entirely done at compile time, that means that it will be very optimized and won't consume some PHP runtime.</p>
<p>Please, notice here that we're interested in the user-declared-class binding process. For internal classes, the same process is done when the classes are registered by PHP Core or PHP extensions, this happens very soon before the user scripts are run, and this happens only once in PHP lifetime, thus the userland runtime never suffers from that in term of performance.</p>
<blockquote>
<p>Binding a single class is entirely done at compile time. On this point, performances tend to reach internal classes'.</p>
</blockquote>
<p>Things become much more complicated when we talk about interfaces implementations, or class inheritance.
In such case, class binding will mainly copy every thing of interest from the parent to the child, would both be classes or interfaces. Let's see that :</p>
<pre><code>/* Single class */
case ZEND_DECLARE_CLASS:
    if (do_bind_class(CG(active_op_array), opline, CG(class_table), 1 TSRMLS_CC) == NULL) {
        return;
    }
    table = CG(class_table);
    break;</code></pre>
<p>In case of a simple class declaration, we run <code>do_bind_class()</code>. This function just registers the already-fully-defined class into the class table for further use at runtime, and performs checks about eventual abstract methods into it, like this :</p>
<pre><code>void zend_verify_abstract_class(zend_class_entry *ce TSRMLS_DC)
{
    zend_abstract_info ai;

    if ((ce->ce_flags & ZEND_ACC_IMPLICIT_ABSTRACT_CLASS) && !(ce->ce_flags & ZEND_ACC_EXPLICIT_ABSTRACT_CLASS)) {
        memset(&ai, 0, sizeof(ai));

        zend_hash_apply_with_argument(&ce->function_table, (apply_func_arg_t) zend_verify_abstract_class_function, &ai TSRMLS_CC);

        if (ai.cnt) {
            zend_error(E_ERROR, "Class %s contains %d abstract method%s and must therefore be declared abstract or implement the remaining methods (" MAX_ABSTRACT_INFO_FMT MAX_ABSTRACT_INFO_FMT MAX_ABSTRACT_INFO_FMT ")",
                ce->name, ai.cnt,
                ai.cnt > 1 ? "s" : "",
                DISPLAY_ABSTRACT_FN(0),
                DISPLAY_ABSTRACT_FN(1),
                DISPLAY_ABSTRACT_FN(2)
                );
        }
    }
}</code></pre>
<p>Nothing to add, that was the easy case.</p>
<p>Now, things become more complicated about interface implementation, here are the task needed to be done to bind a class implementing an interface :</p>
<ul><li>Check if the interface is not already implemented</li>
<li>Check if the class that wants to implement the interface, is actually a class, and not an interface itself (remember that both are treated the same)</li>
<li>Copy the constants from interface into the class, checking possible collisions</li>
<li>Copy the methods from the interface into the class
<ol><li>Checking for possible collisions</li>
<li>Checking mismatch in declaration (turning an interface method into static in child class, f.e)</li>
</ol></li>
<li>Add the interface and all its possible mother interfaces to the interface list the class implements</li>
</ul><p>But take care, when we say "copy", this is not a full deep copy, constants, attributes and functions are all refcounted : the refcount is just incremented by one, meaning one more entity into memory is using the item.</p>
<blockquote>
<p>Binding a class, is barely copying every constant/attributes/methods from its parent, and its interfaces into the current class body - while performing checks.
The class needs to be fully resolved and ready for use at runtime.
Constants, attributes and functions are all refcounted, no real copies take place, but the binding process is still not a light step in terms of performance.</p>
</blockquote>
<pre><code>ZEND_API void zend_do_implement_interface(zend_class_entry *ce, zend_class_entry *iface TSRMLS_DC)
{
    /* ... ... */

    } else {
        if (ce->num_interfaces >= current_iface_num) { /* resize the vector if needed */
            if (ce->type == ZEND_INTERNAL_CLASS) {
                ce->interfaces = (zend_class_entry **) realloc(ce->interfaces, sizeof(zend_class_entry *) * (++current_iface_num));
            } else {
                ce->interfaces = (zend_class_entry **) erealloc(ce->interfaces, sizeof(zend_class_entry *) * (++current_iface_num));
            }
        }
        ce->interfaces[ce->num_interfaces++] = iface; /* Add the interface to the class */

        /* Copy every constants from the interface constants table to the current class constants table */
        zend_hash_merge_ex(&ce->constants_table, &iface->constants_table, (copy_ctor_func_t) zval_add_ref, sizeof(zval *), (merge_checker_func_t) do_inherit_constant_check, iface);
        /* Copy every methods from the interface methods table to the current class methods table */
        zend_hash_merge_ex(&ce->function_table, &iface->function_table, (copy_ctor_func_t) do_inherit_method, sizeof(zend_function), (merge_checker_func_t) do_inherit_method_check, ce);

        do_implement_interface(ce, iface TSRMLS_CC);
        zend_do_inherit_interfaces(ce, iface TSRMLS_CC);
    }
}</code></pre>
<p>Notice the difference between internal classes and user ones ? The former will use <code>realloc()</code> to allocate memory, while the later will use <code>erealloc()</code>. Like I said : <code>realloc()</code> will allocate "permanent" memory, whereas <code>erealloc()</code> will allocate "request-bound" memory.</p>
<p>So, you can see that when the two constant tables are merged (the interface one and the class one), <code>zval_add_ref</code> is used as merge callback : it will not copy the constant from one table to another, but share its pointer just adding a refcount.</p>
<p>For the functions tables (methods), <code>do_inherit_method</code> is run for any of them. Here it is :</p>
<pre><code>static void do_inherit_method(zend_function *function)
{
    function_add_ref(function);
}

ZEND_API void function_add_ref(zend_function *function)
{
    if (function->type == ZEND_USER_FUNCTION) {
        zend_op_array *op_array = &function->op_array;

        (*op_array->refcount)++;
        if (op_array->static_variables) {
            HashTable *static_variables = op_array->static_variables;
            zval *tmp_zval;

            ALLOC_HASHTABLE(op_array->static_variables);
            zend_hash_init(op_array->static_variables, zend_hash_num_elements(static_variables), NULL, ZVAL_PTR_DTOR, 0);
            zend_hash_copy(op_array->static_variables, static_variables, (copy_ctor_func_t) zval_add_ref, (void *) &tmp_zval, sizeof(zval *));
        }
        op_array->run_time_cache = NULL;
    }
}</code></pre>
<p>The function's OPArray is added a refcount, and every possible static variables declared in the function (which here is a method) is also copied, again also using <code>zval_add_ref</code>.</p>
<p>Thus, the overall copy process is heavy in term of CPU because it involves many loops and checks, but in term of memory usage, we are really kind here.
Unfortunately, the interface binding is nowadays fully delayed at runtime, and you will suffer from it at every request.</p>
<p>When it comes to talk about inheritance, well the process is barely the same as interface implementation, thus it is even more complicated because it involves more stuff.
What is interesting to note however, is that the binding is done at compile time if PHP already knows about the class, and in runtime for the opposite case</p>
<blockquote>
<p>The inheritance binding is done at compile time if PHP already knows the parent class, and in runtime for the opposite case.</p>
</blockquote>
<p>So you'd better declare things like this :</p>
<pre><code>/* good */
class A { }
class B extends A { }</code></pre>
<p>Instead of :</p>
<pre><code>/* bad */
class B extends A { }
class A { }</code></pre>
<p>If you use an autoloader and one-class-per-file rule, PHP will likely never known one class' ancestors when it comes to parse it, and thus, will delay the class binding at runtime.</p>
<p>Class binding routine can even lead to very strange behaviors, like :</p>
<pre><code>/* this code snippet works */
class B extends A { }
class A { }

/* this code snippet doesn't work :
Fatal error: Class 'B' not found */
class C extends B { }
class B extends A { }
class A { }</code></pre>
<p>I already explained such a case in <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">another article</a>.</p>
<p>In case one, the binding of class B is delayed at runtime, because when the compiler reaches the class B declaration, it knows nothing about A yet. When runtime fires, it binds the class to A and it finds A, because the compiler compiled A, as A is a single class, the compiler could take care of it entirely.</p>
<p>In case two, things are different. The binding of C is delayed at runtime, because the compiler knows nothing about B when it tries to compile B.
But when the runtime fires to bind C, it looks for B, which doesn't exist, because the compiler couldn't compile it neither, as B itself extends someone. "Class B doesn't exist" , end of story.</p>
<h2 id="then-come-objects">...then come objects<a href="#then-come-objects" class="anchor">#</a></h2>
<p>Ok, now you know several statements :</p>
<ul><li>Classes are heavy items in memory</li>
<li>Internal classes are more optimized than user classes, because those latter will need to be created/destroyed at every request, internal classes are permanent.</li>
<li>Classes, interfaces or traits use the exact same structure and same procedures, very little differences</li>
<li>When doing inheritance or implementations, the binding process is heavy and long for CPU, but light about memory usage as many things are shared and not duplicated. Also, you'd better have class binding fire at compile time</li>
</ul><p>Now let's talk about our objects.</p>
<p>Our first chapter showed the creation of a "classical" object from a "classical" user class (that is : there is nothing special in there), the object creation was very light in term of memory, something like a ridiculous amount of 200 bytes on LP64 platform.</p>
<p>This, is because of the class.
The class itself has been compiled, and this latter eats memory; but that's for the good : this is to make every single object eat less memory.</p>
<p>An object is in fact a ridiculously tiny set of tiny structures.</p>
<h3 id="object-methods-management">Object methods management<a href="#object-methods-management" class="anchor">#</a></h3>
<blockquote>
<p>Reminder: Methods and functions are exactly the same into the engine : a <em>zend_function</em> structure (union). This is just vocabulary, and the fact that methods are the only place where <code>$this</code> can be used.</p>
</blockquote>
<p>Methods are represented by an union (<em>zend_function</em>). Methods are compiled by the PHP compiler, and added to the <em>function_table</em> attribute of the <em>zend_class_entry</em>. So at runtime every method is present, this is just a matter of fetching back its pointer to execute it.</p>
<pre><code>typedef union _zend_function {
    zend_uchar type;

    struct {
        zend_uchar type;
        const char *function_name;
        zend_class_entry *scope;
        zend_uint fn_flags;
        union _zend_function *prototype;
        zend_uint num_args;
        zend_uint required_num_args;
        zend_arg_info *arg_info;
    } common;

    zend_op_array op_array;
    zend_internal_function internal_function;
} zend_function;</code></pre>
<p>When an object tries to invoke a method, the engine will by default lookup into the object's class function table to invoke it, and if the method doesn't exist, it will invoke the magic <code>__call()</code>. It will also check visibility (public/protected/private), and act accordingly :</p>
<pre><code>static union _zend_function *zend_std_get_method(zval **object_ptr, char *method_name, int method_len, const zend_literal *key TSRMLS_DC)
{
    zend_function *fbc;
    zval *object = *object_ptr;
    zend_object *zobj = Z_OBJ_P(object);
    ulong hash_value;
    char *lc_method_name;
    ALLOCA_FLAG(use_heap)

    if (EXPECTED(key != NULL)) {
        lc_method_name = Z_STRVAL(key->constant);
        hash_value = key->hash_value;
    } else {
        lc_method_name = do_alloca(method_len+1, use_heap);
        zend_str_tolower_copy(lc_method_name, method_name, method_len);
        hash_value = zend_hash_func(lc_method_name, method_len+1);
    }
    /* If the method is not found */
    if (UNEXPECTED(zend_hash_quick_find(&zobj->ce->function_table, lc_method_name, method_len+1, hash_value, (void **)&fbc) == FAILURE)) {
        if (UNEXPECTED(!key)) {
            free_alloca(lc_method_name, use_heap);
        }
        if (zobj->ce->__call) { /* if the class has got a __call() handler */
            return zend_get_user_call_function(zobj->ce, method_name, method_len); /* call the __call() handler */
        } else {
            return NULL; /* else return NULL, which will likely lead to a fatal error : method not found */
        }
    }

    /* Check access level */
    if (fbc->op_array.fn_flags & ZEND_ACC_PRIVATE) {
        zend_function *updated_fbc;
        updated_fbc = zend_check_private_int(fbc, Z_OBJ_HANDLER_P(object, get_class_entry)(object TSRMLS_CC), lc_method_name, method_len, hash_value TSRMLS_CC);
        if (EXPECTED(updated_fbc != NULL)) {
            fbc = updated_fbc;
        } else {
            if (zobj->ce->__call) {
                fbc = zend_get_user_call_function(zobj->ce, method_name, method_len);
            } else {
                zend_error_noreturn(E_ERROR, "Call to %s method %s::%s() from context '%s'", zend_visibility_string(fbc->common.fn_flags), ZEND_FN_SCOPE_NAME(fbc), method_name, EG(scope) ? EG(scope)->name : "");
            }
        }
    } else {

    /* ... ... */
}</code></pre>
<p>You may spot an interesting thing, look at the first lines :</p>
<pre><code>if (EXPECTED(key != NULL)) {
        lc_method_name = Z_STRVAL(key->constant);
        hash_value = key->hash_value;
    } else {
        lc_method_name = do_alloca(method_len+1, use_heap);
        /* Create a zend_copy_str_tolower(dest, src, src_length); */
        zend_str_tolower_copy(lc_method_name, method_name, method_len);
        hash_value = zend_hash_func(lc_method_name, method_len+1);
    }</code></pre>
<p>This is PHP case insensibility. PHP must turn every function to lowercase (<code>zend_str_tolower_copy()</code>), before calling it. This is not a heavy step, but it can seem pretty wasteful, considering it must happen for every method call for every class. This will burn some more CPU cycles for nothing really usefull, and you'd better prevent it.</p>
<p>Look carefully at the code, there is an <code>if</code> statement. The <code>key</code> variable prevents the code from running the case lowering function (the <code>else</code> part), and this <code>key</code> is an optimization that has been added starting from PHP 5.4. If the method call is not dynamic, the compiler has already computed the key, and the runtime will have less job to do.</p>
<pre><code>class Foo { public function BAR() { } }
$a = new Foo;
$b = 'bar';

$a->bar(); /* static call : good */
$a->$b(); /* dynamic call : bad */</code></pre>
<p>When the compiler compiles a function/method, it immediately lowercases it. The above function <code>BAR()</code> is turned into <code>bar()</code> by the compiler, when it adds the method to the class function table.</p>
<blockquote>
<p>The compiler turns every function/method name to lowercase when it compiles it. PHP really is case-insensible when we talk about functions/methods.</p>
</blockquote>
<p>When the method call happens, on the example above, the first call is static : the compiler have computed the <code>key</code> for the string "bar", and then when it comes to run the method call, it has less job to do.
The second call above however, is dynamic; the compiler knows nothing about "$b" : it can't compute a <code>key</code> for the method call, we will then fall into the <code>else</code> case at runtime, and we will have to both turn the string to lowercase, and to compute its hash (<code>zend_hash_func()</code>) at runtime, which is not especially what you're looking for if we talk about performances.</p>
<p>About <code>__call()</code>, it is not that bad about performances, there is however more work to do than calling an existing function though.</p>
<h3 id="object-attributes-management">Object attributes management<a href="#object-attributes-management" class="anchor">#</a></h3>
<p>Here is what happens :</p>
<p><img src="../../../img/php-objects/PHP-objects-and-class-attributes.png" alt="PHP-objects-and-class-attributes"></p>
<p>As you can see, when you create several objects of the same class, the engine will make every attribute point on the same pointer as the one defined into the class attributes.
The class stores the attributes, not only its own static attributes - but also objects ones - for the life of the class : forever for internal classes, request bound lifetime for user classes. Creating an object does not involve creating its attributes, thus, that's a fast and memory saver approach.
Only at the time an object is going to change one of its attribute, the engine will create a new one and affect it, assuming you change the $a attribute on the object Foo #2 :</p>
<p><img src="../../../img/php-objects/PHP-objects-cow.png" alt="PHP-objects-cow"></p>
<p>So creating an object, is in fact "just" creating a <em>zend_object</em> structure, which weight 32 bytes under LP64...</p>
<pre><code>typedef struct _zend_object {
    zend_class_entry *ce;
    HashTable *properties;
    zval **properties_table;
    HashTable *guards; /* protects from __get/__set ... recursion */
} zend_object;</code></pre>
<p>...add this new <em>zend_object</em> to the object store. The object store is a <em>zend_object_store</em> structure : it is the global Zend Engine registry of objects, the place where in every object is stored exactly once :</p>
<pre><code>ZEND_API zend_object_value zend_objects_new(zend_object **object, zend_class_entry *class_type TSRMLS_DC)
{
    zend_object_value retval;

    *object = emalloc(sizeof(zend_object));
    (*object)->ce = class_type;
    (*object)->properties = NULL;
    (*object)->properties_table = NULL;
    (*object)->guards = NULL;

    /* Add the object into the store */
    retval.handle = zend_objects_store_put(*object, (zend_objects_store_dtor_t) zend_objects_destroy_object, (zend_objects_free_object_storage_t) zend_objects_free_object_storage, NULL TSRMLS_CC);

    retval.handlers = &std_object_handlers;
    return retval;
}</code></pre>
<p>Then, the engine creates the properties vector of our object :</p>
<pre><code>ZEND_API void object_properties_init(zend_object *object, zend_class_entry *class_type)
{
    int i;

    if (class_type->default_properties_count) {
        object->properties_table = emalloc(sizeof(zval*) * class_type->default_properties_count);
        for (i = 0; i < class_type->default_properties_count; i++) {
            object->properties_table[i] = class_type->default_properties_table[i];
            if (class_type->default_properties_table[i]) {
#if ZTS
                ALLOC_ZVAL( object->properties_table[i]);
                MAKE_COPY_ZVAL(&class_type->default_properties_table[i], object->properties_table[i]);
#else
                Z_ADDREF_P(object->properties_table[i]);
#endif
            }
        }
        object->properties = NULL;
    }
}</code></pre>
<p>Like you can see, we allocate a pure C table/vector of <code>zval*</code> based on the object's class declared properties, and, in case of non thread safe PHP, we just add a refcount to the property, whereas using Zend thread safety (ZTS), we must deeply copy the zval.
That's one of the numerous point that confirms that ZTS mode is slower and more resource user than a non ZTS PHP.</p>
<blockquote>
<p>PHP running with ZendThreadSafety activated (ZTS) is both slower and less memory friendly than a non-ZTS PHP.</p>
</blockquote>
<p>Now you wonder two things :</p>
<ul><li>What's the difference bewteen <em>properties_table</em> and <em>properties</em> in the <em>zend_object</em> structure ?</li>
<li>If we affected our object's attributes in a C vector, how will we fetch them back ? Browse the vector every time ? (counter-performant)</li>
</ul><p>The answer to both those questions relies in a clever trick : <em>zend_property_info</em>.</p>
<p>Here is <em>zend_property_info</em> :</p>
<pre><code>typedef struct _zend_property_info {
    zend_uint flags;
    const char *name;
    int name_length;
    ulong h;
    int offset;
    const char *doc_comment;
    int doc_comment_len;
    zend_class_entry *ce;
} zend_property_info;</code></pre>
<p>Every <strong>declared</strong> attribute(property) of an object has a corresponding property info that has been added to its <em>zend_class_entry</em>, into the <em>property_info</em> field. The compiler created this when it compiled the declared attributes in the class :</p>
<pre><code>class Foo
{
    public $a = 'foo';
    protected $b;
    private $c;
}
struct _zend_class_entry {
        /* ... ... */
        HashTable function_table;
        HashTable properties_info; /* here are the properties infos about $a, $b and $c */
        zval **default_properties_table; /* and here, we'll find $a, $b and $c with their default values */
        int default_properties_count; /* this will have the value of 3 : 3 properties */
        /* ... ... */</code></pre>
<p>The <em>properties_infos</em> is a table that will both tell the object if the attribute it asks access for exists, and if it exists, what is its index number in the <em>object->properties</em> pure C array. Clever and fast way of accessing attributes.
If the attribute doesn't exist, and if we try to write into it : we try to call <code>__set()</code> if possible, if not, we create a dynamic attribute, and this one will be stored into <em>object->property_table</em> field. If the attribute exists, we then check the visibility and scope access (public/protected/private).</p>
<pre><code>property_info = zend_get_property_info_quick(zobj->ce, member, (zobj->ce->__set != NULL), key TSRMLS_CC);

if (EXPECTED(property_info != NULL) &&
    ((EXPECTED((property_info->flags & ZEND_ACC_STATIC) == 0) &&
     property_info->offset >= 0) ?
        (zobj->properties ?
            ((variable_ptr = (zval**)zobj->properties_table[property_info->offset]) != NULL) :
            (*(variable_ptr = &zobj->properties_table[property_info->offset]) != NULL)) :
        (EXPECTED(zobj->properties != NULL) &&
          EXPECTED(zend_hash_quick_find(zobj->properties, property_info->name, property_info->name_length+1, property_info->h, (void **) &variable_ptr) == SUCCESS)))) {
/* ... ... */
} else {
    zend_guard *guard = NULL;
        if (zobj->ce->__set && /* class has a __set() ? */
        zend_get_property_guard(zobj, property_info, member, &guard) == SUCCESS &&
        !guard->in_set) {
        Z_ADDREF_P(object);
        if (PZVAL_IS_REF(object)) {
            SEPARATE_ZVAL(&object);
        }
        guard->in_set = 1; /* prevent circular setting */
        if (zend_std_call_setter(object, member, value TSRMLS_CC) != SUCCESS) { /* call __set() */
        }
        guard->in_set = 0;
        zval_ptr_dtor(&object);
    /* ... ... */</code></pre>
<p>So, until you write to your object, its memory consumption will not vary. When you write to it, you start making it bigger, as it will retain the attributes you wrote into it, until it dies. Methods do not consume any memory related to the object, but they belong to the class.</p>
<h2 id="objects-acting-as-references-thanks-to-the-object-store">Objects acting as references, thanks to the object store<a href="#objects-acting-as-references-thanks-to-the-object-store" class="anchor">#</a></h2>
<p>Objects are not references. I demonstrate it in a small script :</p>
<pre><code>function foo($var) {
    $var = 42;
}
$o = new MyClass;
foo($o);
var_dump($o); /* this is still an object, not the integer 42 */</code></pre>
<p>Everybody says that "objects are references in PHP 5", even the official manual sometimes suggests this ;-) This is horribly wrong technically.
However, objects borrow references behavior, as when you pass a variable which is an object to a function, this function can modify the same object.</p>
<blockquote>
<p>Objects are <strong>not</strong> passed by references, this is <strong>wrong</strong>. However, they borrow the same behavior as PHP variables references.</p>
</blockquote>
<p>This is because in the zval you pass to the function, you don't pass an object precisely, but its unique identifier, that will serve to look it up into the global object store, thus effectively leading to the same object at the end.
You can end up having 3 different zvals in memory, they can all store into them the same object handle, and then they will lead to the same object into memory.</p>
<pre><code>object(MyClass)#1 (0) { } /* #1 is the object handle (number), it is unique */</code></pre>
<p><img src="../../../img/php-objects/PHP-objects-zvals.png" alt="PHP-objects-zvals"></p>
<p>So you carry in your variables the same object handle, and then it will lead to the same object.
The <em>zend_object_store</em> takes care of memorizing objects only once in memory. The only way to write into the store, is to create a new object, weither with the <code>new</code> keyword, the <code>unserialize()</code> function, the reflection API or the <code>clone</code> keyword. Every other operation will never duplicate or create a new object into the store.</p>
<pre><code>typedef struct _zend_objects_store {
    zend_object_store_bucket *object_buckets;
    zend_uint top;
    zend_uint size;
    int free_list_head;
} zend_objects_store;

typedef struct _zend_object_store_bucket {
    zend_bool destructor_called;
    zend_bool valid;
    zend_uchar apply_count;
    union _store_bucket {
        struct _store_object {
            void *object;
            zend_objects_store_dtor_t dtor;
            zend_objects_free_object_storage_t free_storage;
            zend_objects_store_clone_t clone;
            const zend_object_handlers *handlers;
            zend_uint refcount;
            gc_root_buffer *buffered;
        } obj;
        struct {
            int next;
        } free_list;
    } bucket;
} zend_object_store_bucket;</code></pre>
<h2 id="what-is-this">What is $this ?<a href="#what-is-this" class="anchor">#</a></h2>
<p>You know <code>$this</code> from PHP. Internally, <code>$this</code> is not very complex to understand, but there is code related to it in several parts of the engine, in fact, at every needed stage : at compile time, in execution time variable fetching code, etc...
As <code>$this</code> is "magical", appears and disappears when it has to, automaticaly owns the current object, then that means that internal code to manage <code>$this</code> does everything for you. Let's have a look.</p>
<p>First, the compiler will forbid you to write to <code>$this</code>. For that, it checks every assignation you try to do, and if you assign <code>$this</code>, you'll generate a fatal error.</p>
<pre><code>/* ... ... */
 if (opline_is_fetch_this(last_op TSRMLS_CC)) {
    zend_error(E_COMPILE_ERROR, "Cannot re-assign $this");
}
/* ... ... */

static zend_bool opline_is_fetch_this(const zend_op *opline TSRMLS_DC)
{
    if ((opline->opcode == ZEND_FETCH_W) && (opline->op1_type == IS_CONST)
        && (Z_TYPE(CONSTANT(opline->op1.constant)) == IS_STRING)
        && ((opline->extended_value & ZEND_FETCH_STATIC_MEMBER) != ZEND_FETCH_STATIC_MEMBER)
        && (Z_HASH_P(&CONSTANT(opline->op1.constant)) == THIS_HASHVAL)
        && (Z_STRLEN(CONSTANT(opline->op1.constant)) == (sizeof("this")-1))
        && !memcmp(Z_STRVAL(CONSTANT(opline->op1.constant)), "this", sizeof("this"))) {
        return 1;
    } else {
        return 0;
    }
}</code></pre>
<p>You can trick that by many ways, though it's useless to do so ;-)</p>
<p>Now how is <code>$this</code> managed ?
When you call a method - which is the only place where you are allowed to use <code>$this</code> - the compiler emits an <code>INIT_METHOD_CALL</code> OPCode.
You can read <a href="http://jpauli.github.io/2015/01/22/on-php-function-calls.html">On PHP function calls</a> or <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">getting into the Zend execution engine</a> about OPCodes for functions.
In the <code>INIT_METHOD_CALL</code>, the engine knows who is calling the method, for <code>$a->foo()</code> : it is <code>$a</code>.
It then fetches <code>$a</code>'s value, and memorize it in a global space. Then, it calls the method, issuing a <code>DO_FCALL</code> OPCode. In this OPcode, we fetch back the value memorized (the object calling the method), and we assign it to the internally-global <code>$this</code> pointer : <code>EG(This)</code> :</p>
<pre><code>if (fbc->type == ZEND_USER_FUNCTION || fbc->common.scope) {
    should_change_scope = 1;
    EX(current_this) = EG(This);
    EX(current_scope) = EG(scope);
    EX(current_called_scope) = EG(called_scope);
    EG(This) = EX(object); /* fetch the object prepared in previous INIT_METHOD opcode and affect it to EG(This) */
    EG(scope) = (fbc->type == ZEND_USER_FUNCTION || !EX(object)) ? fbc->common.scope : NULL;
    EG(called_scope) = EX(call)->called_scope;
}</code></pre>
<p>Now, when the method is called, if you use <code>$this</code> in its body to affect a variable or call a method, like <code>$this->a = 8</code>, that leads to the <code>ZEND_ASSIGN_OBJ</code> OPCode, that fetches back <code>$this</code> from <code>EG(This)</code>.</p>
<pre><code>static zend_always_inline zval **_get_obj_zval_ptr_ptr_unused(TSRMLS_D)
{
    if (EXPECTED(EG(This) != NULL)) {
        return &EG(This);
    } else {
        zend_error_noreturn(E_ERROR, "Using $this when not in object context");
        return NULL;
    }
}</code></pre>
<p>In case you were using <code>$this</code> to issue a method call like <code>$this->foo()</code>, or to pass <code>$this</code> to another function call like <code>$this->foo($this);</code> the engine will try to fetch <code>$this</code> from the current symbol table, like it does for every standard variable.
But this one has been specially prepared, when the current function stack frame has been built :</p>
<pre><code>if (op_array->this_var != -1 && EG(This)) {
    Z_ADDREF_P(EG(This));
    if (!EG(active_symbol_table)) {
        EX_CV(op_array->this_var) = (zval **) EX_CV_NUM(execute_data, op_array->last_var + op_array->this_var);
        *EX_CV(op_array->this_var) = EG(This);
    } else {
        if (zend_hash_add(EG(active_symbol_table), "this", sizeof("this"), &EG(This), sizeof(zval *), (void **) EX_CV_NUM(execute_data, op_array->this_var))==FAILURE) {
            Z_DELREF_P(EG(This));
        }
    }
}</code></pre>
<p>Last thing : the scopes.
When we call a method, the engine changes the scope :</p>
<pre><code>if (fbc->type == ZEND_USER_FUNCTION || fbc->common.scope) {
    /* ... ... */
    EG(scope) = (fbc->type == ZEND_USER_FUNCTION || !EX(object)) ? fbc->common.scope : NULL;
    /* ... ... */
}</code></pre>
<p><code>EG(scope)</code> is of type <code>zend_class_entry</code> : this is the class the method you ask for belongs to, and this one will be used for whatever object operation you will now perform into the method body; when the engine checks the visibility :</p>
<pre><code>static zend_always_inline int zend_verify_property_access(zend_property_info *property_info, zend_class_entry *ce TSRMLS_DC)
{
    switch (property_info->flags & ZEND_ACC_PPP_MASK) {
        case ZEND_ACC_PUBLIC:
            return 1;
        case ZEND_ACC_PROTECTED:
            return zend_check_protected(property_info->ce, EG(scope));
        case ZEND_ACC_PRIVATE:
            if ((ce==EG(scope) || property_info->ce == EG(scope)) && EG(scope)) {
                return 1;
            } else {
                return 0;
            }
            break;
    }
    return 0;
}</code></pre>
<p>That's why you can access private members of objects that are not yours, but descendant of your current scope :</p>
<pre><code>class A
{
    private $a;

    public function foo(A $obj)
    {
        $this->a = 'foo';
        $obj->a  = 'bar'; /* yes, this is possible */
    }
}

$a = new A;
$b = new A;
$a->foo($b);</code></pre>
<p>This strangeness has lead to many bugs reported by users, but that's the rule in PHP object model : we don't actually define an object based scope, but a class based scope.
So in a class "Foo", you can play with every private of every other eventual "Foo" , not only yourself, like the above example demonstrates.</p>
<blockquote>
<p>PHP's object model scope is class based, not object based.</p>
</blockquote>
<h2 id="on-destructors">On destructors<a href="#on-destructors" class="anchor">#</a></h2>
<p>Destructors are dangerous. Don't rely on them, because PHP will even not call them in case of fatal errors :</p>
<pre><code>class Foo { public function __destruct() { echo "byebye foo"; } }
$f = new Foo;
thisfunctiondoesntexist();
/* fatal error, function not found, the Foo's destructor is NOT run */</code></pre>
<p>And how about the order the destructors are called, when are they called ?
The rule is clear into the source code :</p>
<pre><code>void shutdown_destructors(TSRMLS_D)
{
    zend_try {
        int symbols;
        do {
            symbols = zend_hash_num_elements(&EG(symbol_table));
            zend_hash_reverse_apply(&EG(symbol_table), (apply_func_t) zval_call_destructor TSRMLS_CC);
        } while (symbols != zend_hash_num_elements(&EG(symbol_table)));
        zend_objects_store_call_destructors(&EG(objects_store) TSRMLS_CC);
    } zend_catch {
        /* if we couldn't destruct cleanly, mark all objects as destructed anyway */
        zend_objects_store_mark_destructed(&EG(objects_store) TSRMLS_CC);
    } zend_end_try();
}

static int zval_call_destructor(zval **zv TSRMLS_DC)
{
    if (Z_TYPE_PP(zv) == IS_OBJECT && Z_REFCOUNT_PP(zv) == 1) {
        return ZEND_HASH_APPLY_REMOVE;
    } else {
        return ZEND_HASH_APPLY_KEEP;
    }
}</code></pre>
<p>As you can see, this is a three step destructor calling strategy :</p>
<ul><li>Loop backwards the global symbol table and call destructors for objects where refcount = 1</li>
<li>Then loop forward the global symbol table and call destructors for all the other objects (refcount > 1)</li>
<li>If a problem happens in step 1 or 2, stop calling the remaining destructors</li>
</ul><p>So, that leads to those behaviors :</p>
<pre><code>class Foo { public function __destruct() { var_dump("destroyed Foo"); } }
class Bar { public function __destruct() { var_dump("destroyed Bar"); } }</code></pre>
<p>Case 1 :</p>
<pre><code>$a = new Foo;
$b = new Bar;
"destroyed Bar"
"destroyed Foo"</code></pre>
<p>Case 1 again :</p>
<pre><code>$a = new Bar;
$b = new Foo;
"destroyed Foo"
"destroyed Bar"</code></pre>
<p>Case 2 :</p>
<pre><code>$a = new Bar;
$b = new Foo;
$c = $b; /* increment $b's object refcount */
"destroyed Bar"
"destroyed Foo"</code></pre>
<p>Case 3 :</p>
<pre><code>class Foo { public function __destruct() { var_dump("destroyed Foo"); die();} } /* notice the die() here */
class Bar { public function __destruct() { var_dump("destroyed Bar"); } }

$a = new Foo;
$a2 = $a;
$b = new Bar;
$b2 = $b;

destroyed Foo</code></pre>
<p>This procedure has not been randomly chosen. We do things this way, to be extra sure about everything.
You don't like it ? Destroy your own objects by yourself ! This is the only way to master <code>__destruct()</code> calls. If you leave PHP destroy your objects for you, don't come complaining about the procedure that has been matured for years, you always have the choice of destroying yourself your objects, to master the order of destructs (I tell this because here again, we've been filled tons of bug reports about PHP objects destructors beeing called "strangely").</p>
<p>However, in case of any fatal error, PHP will not call any destructor, because a fatal error is likely to have left the Zend Engine in an unstable state, and calling destructors will run user code that may access pointers that are invalid now, and then crash PHP.
We prefer having something stable, and thus we chose not to call destructors in such cases.</p>
<blockquote>
<p>In case of fatal error, PHP will not call any destructor</p>
</blockquote>
<p>About recursion also : PHP has not many recursion protection. The only ones that exist are about <code>__get()</code> and <code>__set()</code>.
If you happen, somewhere in the stack frame of your destructor, to destroy an object of your own : you'll find yourself into an infinite recursion loop that will exaust your process stack size (usually 8Kb, <em>ulimit -s</em>), and crash PHP.</p>
<pre><code>class Foo
{
    public function __destruct() { new Foo; } /* you will crash */
}</code></pre>
<p>So, to sum up things in short : do not put critical code into destructors, such as lock mechanism management, because PHP could not call your destructor, or call in an order that's hard to master. If you have critical code in destructors, and rely on them, then manage your objects lifetime by yourself, PHP will call your destructor when your object's refcount falls down to zero, meaning the object is not used anywhere else, and it is safe now to destroy it.</p>
<h2 id="end">End<a href="#end" class="anchor">#</a></h2>
<p>Here we are for PHP object model internal design tour. I hope you have a better glance of what happens when you manipulate objects everyday in PHP. Objects are light in term of memory, and their handling is very optimized into the engine. Feel free to use them. Use a well designed autoloader to boost your memory usage, declare your classes in the logical inheritance order, and if you can turn some of the most complex ones into C extensions, you'll be able to optimize many things and increase even more the overall performances of such classes.</p>]]></content>
    </entry>
        <entry>
        <title>PHP&#039;s OPCache extension review</title>
                <id>http://jpauli.github.io//2015/03/05/opcache.html</id>
                <updated>2015-03-05T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/03/05/opcache.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="reminder-on-opcodes-caches">Reminder on OPCodes caches<a href="#reminder-on-opcodes-caches" class="anchor">#</a></h2>
<p>PHP is a scripting language, that by default will compile any file you ask it to run, obtain <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">OPCodes</a> from compilation, run them, and trash them away immediately.
PHP has been designed like that : it "forgets" everything it's done in request R-1, when it comes to run request R.</p>
<p>On production servers, the PHP code is very unlikely to change between several requests, thus, the compilation step will always read the same source code, leading to the very exact same OPCode to be run. This is a big waste of time and resources, as the PHP compiler is invoked for every request, for every script.</p>
<p><img src="../../../img/opcache/php-compile-execute-process.png" alt="php-compile-execute-process"></p>
<p>Knowing that compilation can really take a lot of time, OPCode cache extensions have been designed. Their main goal is to <strong>compile once and only once</strong> each PHP script, and cache the resulting OPCodes into shared memory, so that every other PHP worker of your production worker pool (usually using PHP-FPM) can make use of the OPCodes by reading them and executing then back.</p>
<p>The result is a massive boost in overall performance of the language, dividing time to run a script by a factor of at least 2 (very depend on the script), usually more than 2, as PHP now doesn't have to compile again and again the same PHP scripts.</p>
<p>The boost is higher as the application is more complex. If you take applications running tons of files, like framework based applications, or products like wordpress, you will experience a factor of 10-15 or so. This is because the PHP compiler is slow, and this is just a normal situation : a compiler is slow, whatever it is, because its work is to turn a syntax into another, trying to understand what you asked, and somehow to optimize the generated code for it to later run the fastest as possible ; so yes, compiling a PHP script is really slow and eats a lot of memory. Profilers like <a href="https://blackfire.io">Blackfire</a> allows you to know the compile time.</p>
<p><img src="../../../img/opcache/compile-execute.png" alt="compile-time"></p>
<h2 id="introducing-opcache">Introducing OPCache<a href="#introducing-opcache" class="anchor">#</a></h2>
<p>OPCache has been opensourced since 2013, and is bundled into PHP's source starting from PHP 5.5.0
It has thus become a standard for PHP OPcode cache solutions. There exists other solutions, such as XCache, APC, Eaccelerator and others. I will not talk about those other solutions, as I myself don't know them except APC : APC support has been discontinued in favor of OPCache. Short : if you were using APC before, please, use OPCache now.
<strong>OPCache has become the real official recommanded OPCode cache solution by the developpers of PHP</strong>. You may still use other solutions if you want, however, <strong>never ever activate more than one OPCode cache extension at the same time</strong> : you will likely crash PHP.</p>
<p>Be aware that new development involving OPCache won't target PHP 5 branch, but PHP 7 branch which is the nowadays stable branch.
This article will target OPCache for PHP 5 and PHP 7, so that you may spot the differences (which are not that big).</p>
<p>So OPCache is an extension, a <em>zend_extension</em> more precisely, which is shipped into the PHP source code, starting from PHP 5.5.0 (Pecl for others), and that must be activated through the normal php.ini process of activating an extension. For distros, please refer to your distribution manual to know how PHP and OPCache have been bundled.</p>
<h3 id="two-features-into-one-product">Two features into one product<a href="#two-features-into-one-product" class="anchor">#</a></h3>
<p>OPCache is an extension which provides two main features :</p>
<ul><li>OPCodes caching</li>
<li>OPCodes optimization</li>
</ul><p>Because OPCache triggers the PHP compiler, to get OPCodes and cache them, it could use this step to optimize the OPCodes.
Optimizations are basically about compiler optimizations, and share many concepts of this computer science discipline. OPCache optimizer is a multi pass compiler optimizer.</p>
<p><img src="../../../img/opcache/cache-optimization-steps.png" alt="php-compile-execute-process"></p>
<h2 id="opcache-in-deep">OPCache in deep<a href="#opcache-in-deep" class="anchor">#</a></h2>
<p>Let's now see together how OPCache works internally. If you want to follow the code, you can fetch it from the PHP source code, <a href="https://github.com/php/php-src/tree/PHP-7.0/ext/opcache">here it is for PHP 7.0</a>.</p>
<p>Unlike what you can think, OPCode caching is not a that hard concept to analyze and understand. You must have a good knowledge on how the Zend Engine works and has been designed, then you should start spotting places where the job can be done.</p>
<h3 id="shared-memory-models">Shared memory models<a href="#shared-memory-models" class="anchor">#</a></h3>
<p>As you know, there exists many shared memory models under the different Operating Systems. Under modern Unixes, there exists several ways of sharing memory through processes, most commonly used are :</p>
<ul><li>System-V shm API</li>
<li>POSIX API</li>
<li>mmap API</li>
<li>Unix socket API</li>
</ul><p>OPCache is able to use the first three of them, as soon as your OS supports the layer. The INI setting <em>opcache.preferred_memory_model</em> allows you to explicitly select the memory model you want.
If you leave the parameter to null value, OPCache will select the first model which works for your platform, iterating through its table :</p>
<pre><code>static const zend_shared_memory_handler_entry handler_table[] = {
#ifdef USE_MMAP
    { "mmap", &zend_alloc_mmap_handlers },
#endif
#ifdef USE_SHM
    { "shm", &zend_alloc_shm_handlers },
#endif
#ifdef USE_SHM_OPEN
    { "posix", &zend_alloc_posix_handlers },
#endif
#ifdef ZEND_WIN32
    { "win32", &zend_alloc_win32_handlers },
#endif
    { NULL, NULL}
};</code></pre>
<p>So by default, <em>mmap</em> should be used. It's a nice memory model, mature and robust. However it is less informative to sysadmin that System-V SHM model is, and its <code>ipcs</code> and <code>ipcrm</code> commands.</p>
<p>As soon as OPCache starts (as soon as PHP starts), OPCache will try a shared memory model, and will allocate one big memory segment that it will then divide and manage on its side. However, it will never free this segment back, nor will it try to resize it.</p>
<blockquote>
<p>OPCache allocates one segment of shared memory when PHP starts, once for all, and never frees it nor fragments it.</p>
</blockquote>
<p>The size of the memory segment can be told using the <em>opcache.memory_consumption</em> INI setting (Megabytes). Size it big, don't hesitate to give space. <strong>Never ever run out of shared memory space</strong>, if you do, you will lock your processes, we'll get back to that later.</p>
<p>Size the shared memory segment according to your needs, don't forget that a production server dedicated to PHP processes may bundle several dozens of Gigabytes of memory, just for PHP. Having a 1Gb shared memory segment (or more) is not uncommon, it will depend on your needs, but if you use a modern application stack, aka framework based, with lots of dependencies etc... , then use at least 1Gb of shared memory.</p>
<p>The shared memory segment will be used for several things in OPCache :</p>
<ul><li>Script's datastructure caching, involving obviously OPCodes caching but not only</li>
<li>Shared interned strings buffer</li>
<li>Cached scripts HashTable</li>
<li>Global OPCache shared memory state</li>
</ul><p>So remember, the shared memory segment size will not only contain raw OPCodes, but other things needed for OPCache internals.
Measure on your side and size it accordingly.</p>
<p><img src="../../../img/opcache/opcache-shm.png" alt="opcache-shm"></p>
<h3 id="opcodes-caching">OPCodes caching<a href="#opcodes-caching" class="anchor">#</a></h3>
<p>Here we go to detail how the caching mechanism works.</p>
<p>The overall idea is to copy into shared memory (shm) every pointer data that won't change from request to request, aka immutable things. And there are many of them.
After, once loading back the same script : restore every pointer data from shared memory to standard process memory, tied to the current request.
When the PHP compiler is working, it uses Zend Memory Manager (ZMM) to allocate every pointer. This kind of memory used is request bound as ZMM will automaticaly attempt to free those pointers as soon as the current request finishes. Also, those pointers are allocated from the current process' heap, that is this is some privately mapped memory and thus can't be shared with other PHP processes. Hence, OPCache's job is to browse every structure returned by the PHP compiler, and not leave one single pointer allocated onto this pool, but copy it into a shared memory allocated pool.
And here we talk about compile time, whatever has been allocated by the compiler, is assumed to be immutable. Non-immutable data will be created at runtime by the <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">Zend Virtual Machine</a>, so it is safe to save everything that the Zend Compiler created, into shared memory. Examples of such created things : functions and classes, those are functions' name pointers, functions' OPArray pointers, classes' constants, classes's declared variable names and eventually their default content... There are really many things that are created in memory by the PHP compiler.</p>
<p>Such a memory model is used to prevent locks at maximum. We'll go back to locks in a later subject, but basically, OPCache does its job all at once, before runtime, so that during the runtime of the script, OPCache has nothing more to do : volatile data will be created on the classical process heap using ZMM, and immutable data would have been restored from shared memory.</p>
<p>So, OPCache hooks into the compiler, and replaces the structure this latter should fill-in while compiling PHP scripts, by its own.
It then makes the compiler fills a <code>persistent_script</code> structure, instead of it filling directly the Zend Engine tables and internal structures.</p>
<p>Here is a <code>persistent_script</code> structure :</p>
<pre><code>typedef struct _zend_persistent_script {
    ulong          hash_value;
    char          *full_path;              /* full real path with resolved symlinks */
    unsigned int   full_path_len;
    zend_op_array  main_op_array;
    HashTable      function_table;
    HashTable      class_table;
    long           compiler_halt_offset;   /* position of __HALT_COMPILER or -1 */
    int            ping_auto_globals_mask; /* which autoglobals are used by the script */
    accel_time_t   timestamp;              /* the script modification time */
    zend_bool      corrupted;
#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO
    zend_uint      early_binding;          /* the linked list of delayed declarations */
#endif

    void          *mem;                    /* shared memory area used by script structures */
    size_t         size;                   /* size of used shared memory */

    /* All entries that shouldn't be counted in the ADLER32
     * checksum must be declared in this struct
     */
    struct zend_persistent_script_dynamic_members {
        time_t       last_used;
        ulong        hits;
        unsigned int memory_consumption;
        unsigned int checksum;
        time_t       revalidate;
    } dynamic_members;
} zend_persistent_script;</code></pre>
<p>And here is how OPCache replaces the compiler structure by the <code>persistent_script</code> ones, simple function pointers switch :</p>
<pre><code>new_persistent_script = create_persistent_script();

/* Save the original values for the op_array, function table and class table */
orig_active_op_array = CG(active_op_array);
orig_function_table = CG(function_table);
orig_class_table = CG(class_table);
orig_user_error_handler = EG(user_error_handler);

/* Override them with ours */
CG(function_table) = &ZCG(function_table);
EG(class_table) = CG(class_table) = &new_persistent_script->class_table;
EG(user_error_handler) = NULL;

zend_try {
    orig_compiler_options = CG(compiler_options);
    /* Configure the compiler */
    CG(compiler_options) |= ZEND_COMPILE_HANDLE_OP_ARRAY;
    CG(compiler_options) |= ZEND_COMPILE_IGNORE_INTERNAL_CLASSES;
    CG(compiler_options) |= ZEND_COMPILE_DELAYED_BINDING;
    CG(compiler_options) |= ZEND_COMPILE_NO_CONSTANT_SUBSTITUTION;
    op_array = *op_array_p = accelerator_orig_compile_file(file_handle, type TSRMLS_CC); /* Trigger PHP compiler */
    CG(compiler_options) = orig_compiler_options;
} zend_catch {
    op_array = NULL;
    do_bailout = 1;
    CG(compiler_options) = orig_compiler_options;
} zend_end_try();

/* Restore originals */
CG(active_op_array) = orig_active_op_array;
CG(function_table) = orig_function_table;
EG(class_table) = CG(class_table) = orig_class_table;
EG(user_error_handler) = orig_user_error_handler;</code></pre>
<p>As we can see, the PHP compiler is fully isolated and disconnected from the tables it usually fills : it will now fill the <code>persistent_script</code> structures. Then OPCache will have to browse those structures, and replace request allocated pointers to shm ones. OPCache is interested in :</p>
<ul><li>The script functions</li>
<li>The script classes</li>
<li>The script main OPArray</li>
<li>The script path</li>
<li>The script structure itself</li>
</ul><p><img src="../../../img/opcache/opcache-shm-detailed.png" alt="opcache-shm-detailed"></p>
<p>The compiler is also told some options to disable some optimizations it does, like <code>ZEND_COMPILE_NO_CONSTANT_SUBSTITUTION</code> and <code>ZEND_COMPILE_DELAYED_BINDING</code>. That would add more work to OPCache. Remember that OPCache hooks into the Zend Engine, it is not a source code patch.</p>
<p>Now that we have a <code>persitent_script</code> structure, we must cache its informations. Remember that the PHP Compiler has filled-in our structures, but it allocated the memory behind this using the Zend Memory Manager : this memory will be freed at the end of the current request. We then need to browse this memory, and copy all of it into the shared memory segment, so that the informations we just gathered will now persist through several requests and won't need to be recomputed every time.</p>
<p>The process is as follow :</p>
<ul><li>Take the PHP script to cache, and compute every variable data size (every pointer target)</li>
<li>Reserve into already allocated shared memory one big block of this precise size</li>
<li>Iterate over the PHP script variable structures, and for each variable-data pointer target, copy it into the just-allocated shared memory block</li>
<li>Do the exact opposite for script loading, when this comes to play.</li>
</ul><p>So OPCache is clever about shared memory, and will not fragment it by freeing it and compacting it.
For every script, it computes the exact size this script needs to store informations into shared memory, and then copies the data into the segment. <strong>The memory is never freed nor given back to the OS by OPCache</strong> , thus the memory is perfectly aligned and never fragmented. This gives a big boost in performance of shared memory, as there is no linked-list or BTree to store and traverse when managing memory that can be freed (like malloc/free do). OPcache keeps storing things into the shared memory segment, and when the data become stale (because of script revalidation) : it does not free the buffers but mark them as "wasted". When the max wasted percentage is reached, OPCache triggers a restart. This model is very different from the old APC extension, for example, and has the big advantage of providing the same performances as time runs, because the memory buffer from SHM is never managed (freed, compacted, etc...), memory management operations are trully technically stuff which brings nothing to functionnalities, but performance penalty as they run. <strong>OPCache has been designed with highest possible performance in mind for the PHP environment runtime</strong>, not touching back the shared memory segment provides as well a very good rate of CPU caches hits (especially L1 and L2, as OPCache also aligns the memory pointers for them to better find a hit in an L1/L2 line).</p>
<p>Caching a script thus involves -as a first step- computing the exact size of its data. Here is the algorithm :</p>
<pre><code>uint zend_accel_script_persist_calc(zend_persistent_script *new_persistent_script, char *key, unsigned int key_length TSRMLS_DC)
{
    START_SIZE();

    ADD_SIZE(zend_hash_persist_calc(&new_persistent_script->function_table, (int (*)(void* TSRMLS_DC)) zend_persist_op_array_calc, sizeof(zend_op_array) TSRMLS_CC));
    ADD_SIZE(zend_accel_persist_class_table_calc(&new_persistent_script->class_table TSRMLS_CC));
    ADD_SIZE(zend_persist_op_array_calc(&new_persistent_script->main_op_array TSRMLS_CC));
    ADD_DUP_SIZE(key, key_length + 1);
    ADD_DUP_SIZE(new_persistent_script->full_path, new_persistent_script->full_path_len + 1);
    ADD_DUP_SIZE(new_persistent_script, sizeof(zend_persistent_script));

    RETURN_SIZE();
}</code></pre>
<p>I repeat : what we have to cache are :</p>
<ul><li>The script functions</li>
<li>The script classes</li>
<li>The script main OPArray</li>
<li>The script path</li>
<li>The script structure itself</li>
</ul><p>For functions, classes and OPArray, the iterating algorithm is deep searching : it caches every pointer data.
For example for the functions in PHP 5, we must copy into shared memory (shm) :</p>
<ul><li>The functions HashTable
<ol><li>The functions HashTable buckets table (Bucket **)</li>
<li>The functions HashTable buckets (Bucket *)</li>
<li>The functions HashTable buckets' key (char *)</li>
<li>The functions HashTable buckets' data pointer (void *)</li>
<li>The functions HashTable buckets' data (*)</li>
</ol></li>
<li>The functions OPArray
<ol><li>The OPArray filename (char *)</li>
<li>The OPArray literals (names (char <em>) and values (zval </em>))</li>
<li>The OPArray OPCodes (zend_op *)</li>
<li>The OPArray function name (char *)</li>
<li>The OPArray arg_infos (zend_arg_info <em>, and the name and class name as both char </em>)</li>
<li>The OPArray break-continue array (zend_brk_cont_element *)</li>
<li>The OPArray static variables (Full deep HashTable and zval *)</li>
<li>The OPArray doc comments (char *)</li>
<li>The OPArray try-catch array (zend_try_catch_element *)</li>
<li>The OPArray compiled variables (zend_compiled_variable *)</li>
</ol></li>
</ul><p>I did not detail all, and this changes for PHP 7 as the structures (such as the hashtable) are different.
The idea is as I expressed it : copy in shared memory every pointer data. As deep copies may involve recursive structures, OPCache uses a translate table for pointer storage : everytime it copies a pointer from regular request-bound memory to shared memory, it saves the association between the old pointer address, and the new pointer address.
The copy process, before copying, looks up this translate table to know if it has already copied the data, if so, it reuses the old pointer data so that it never duplicates any pointer data :</p>
<pre><code>void *_zend_shared_memdup(void *source, size_t size, zend_bool free_source TSRMLS_DC)
{
    void **old_p, *retval;

    if (zend_hash_index_find(&xlat_table, (ulong)source, (void **)&old_p) == SUCCESS) {
        /* we already duplicated this pointer */
        return *old_p;
    }
    retval = ZCG(mem);;
    ZCG(mem) = (void*)(((char*)ZCG(mem)) + ZEND_ALIGNED_SIZE(size));
    memcpy(retval, source, size);
    if (free_source) {
        interned_efree((char*)source);
    }
    zend_shared_alloc_register_xlat_entry(source, retval);
    return retval;
}</code></pre>
<p><code>ZCG(mem)</code> represents the fixed-size shared memory segment and is filled-in as elements are added. It then has already been allocated, there is no need to allocate memory on each copy (which would have been less performant), but simply fill-in the memory, and move forward the pointer address border.</p>
<p>We detailed the script caching algorithm, which role is to take any request-bound heap memory pointer and data and duplicate it into shared memory, if not already copied.
The loading algorithm does the exact opposite : it gets the <code>persistent_script</code> back from shared memory and browse every of its dynamic structures to duplicate every shared pointer to a request-bound allocated pointer.
The script is then ready to be run by the Zend Engine Executor, as it now doesn't embed any shared pointer address (which would lead to massive bugs of one script modifing the structure of its brother). The Zend Engine is tricked (hooked by OPCache) : it has seen nothing of the pointers replacement happening before the execution happens.</p>
<p>This process of copying from regular memory to shared memory (cache script), or the opposite (load script), is highly optimized, and even if it involves many memory copies or hash lookups, which are not really nice in term of performance, we are way faster than triggering the PHP compiler every time.</p>
<h3 id="sharing-interned-strings">Sharing interned strings<a href="#sharing-interned-strings" class="anchor">#</a></h3>
<p>Interned strings is a nice memory optimisation that's been added to PHP 5.4. This may feel like some comonsense : every time PHP meets an immutable string (a char*), it stores it into a special buffer and reuses the pointer for every occurence of this same string next to come. You may learn more about interned strings <a href="http://jpauli.github.io/2015/09/18/php-string-management.html#interned-strings">from this article</a>. Interned strings are about immutable strings, and thus are nearly exclusively used into the PHP compiler.</p>
<p>Interned strings work like this :</p>
<p><img src="../../../img/opcache/PHP-interned-strings.png" alt="PHP-interned-strings"></p>
<p>The same instance of a string is shared to every pointer. But there still is a problem with that : this interned string buffer is a per-process buffer, it is managed by the PHP compiler mainly. That means that in a PHP-FPM pool, every PHP worker will store its own copy of this buffer, something like this :</p>
<p><img src="../../../img/opcache/PHP-interned-strings-pools.png" alt="PHP-interned-strings-pools"></p>
<p>This leads to a massive waste of memory, especially in case you have tons of workers (you're likely to have), and you use very big strings in your PHP code (tip: PHP's annotation comments are strings). What OPCache takes care of, is sharing this buffer between every PHP worker of a pool. Something like this :</p>
<p><img src="../../../img/opcache/PHP-interned-strings-pools-shared.png" alt="PHP-interned-strings-pools-shared"></p>
<p>Et voila! OPCache shares the interned string buffers of all the PHP-FPM worker of the same pools, and uses its shm segment to store those.
Thus, you need to size the shm segment according to your interned strings usage as well. Also, OPCache allows you to tune the interned strings shm usage using <em>opcache.interned_strings_buffer</em> INI setting. Monitor OPCache and once more : make sure you have enough memory.
However here, if you run out of interned strings memory space (<em>opcache.interned_strings_buffer</em> setting is too low), OPCache will not trigger a restart, because it still has some shm available, only interned strings buffer is full, which is not blocking to continue processing request, you'll simply end up having some strings interned and shared, and some other that use PHP worker's memory. I don't recommand that for performance.</p>
<p>Read your logs, when you run out of interned string memory, OPCache warns you :</p>
<pre><code>if (ZCSG(interned_strings_top) + ZEND_MM_ALIGNED_SIZE(sizeof(Bucket) + nKeyLength) >=
        ZCSG(interned_strings_end)) {
        /* no memory, return the same non-interned string */
        zend_accel_error(ACCEL_LOG_WARNING, "Interned string buffer overflow");
        return arKey;
    }</code></pre>
<blockquote>
<p>Interned strings are about every piece of immutable string the PHP compiler is going to meet while doing its job : variable names, "php strings", function names, class names... PHP comments, nowadays used and called "annotations", are strings as well, and they are usually huge strings, that will eat most of your interned strings buffer. Think about them as well.</p>
</blockquote>
<h3 id="the-locking-mechanism">The locking mechanism<a href="#the-locking-mechanism" class="anchor">#</a></h3>
<p>As soon as we talk about shared memory (shm), we must talk about memory locking mecanisms.
The base line is simple : <strong>every PHP process that is willing to write into shared memory will lock every other process willing to write into shared memory as well</strong>. So the critical section is done on write operations, and not read operations. You may happen to have 150 PHP processes reading the shared memory, only one of them may write into the shm at the same time, write operation doesn't prevent read operation but another write operation.</p>
<p>So, <strong>there should be no dead-lock in OPCache, until you don't prime your cache smoothly</strong> . If, after your code deployment, you open your webserver to trafic, then there will be a massive rush on your scripts to compile and cache them, and as the cache write-to-shm operation is done under exclusive lock, you will probably lock every processes once the first lucky one has obtained a lock to write. When this latter will release the lock, every process waiting for it will then see that the file they just compiled is already stored into shm , and then they will trash the compilation result to load it from shm. This is a big waste of resources.</p>
<pre><code>/* exclusive lock */
zend_shared_alloc_lock(TSRMLS_C);

/* Check if we still need to put the file into the cache (may be it was
 * already stored by another process. This final check is done under
 * exclusive lock) */
bucket = zend_accel_hash_find_entry(&ZCSG(hash), new_persistent_script->full_path, new_persistent_script->full_path_len + 1);
if (bucket) {
    zend_persistent_script *existing_persistent_script = (zend_persistent_script *)bucket->data;

    if (!existing_persistent_script->corrupted) {
        if (!ZCG(accel_directives).revalidate_path &&
            (!ZCG(accel_directives).validate_timestamps ||
             (new_persistent_script->timestamp == existing_persistent_script->timestamp))) {
            zend_accel_add_key(key, key_length, bucket TSRMLS_CC);
        }
        zend_shared_alloc_unlock(TSRMLS_C);
        return new_persistent_script;
    }
}</code></pre>
<p>What you should do, is cut off your server from external webtraffic, deploy your new code, curl some of your most heavy URLs, so that your curl requests will smoothly prime the shm. When you think you are done with the big majority of your scripts, you may now open your webserver to traffic, so that now this one will massively read shm, which is a lock-free operation. Sure there may still be some little scripts not compiled yet, but as soon as they are uncommon, there is no pressure on the write lock.</p>
<p>What you should avoid, is writing PHP files at runtime, and then make use of them. For the exact same reason : as soon as you write a new PHP file onto your production server documentroot, and you make use of it, chances are that it will be rushed by thousands of PHP workers trying to compile and cache it into shm : you will lock.
Those dynamically generated PHP files should be added to the OPCache blacklist, using the <em>opcache.blacklist-filename</em> INI setting (which accepts glob patterns).</p>
<p>Technically speaking, the lock mecanism is not very strong, but it works on many flavors of Unix : it uses the famous <code>fcntl()</code> call</p>
<pre><code>void zend_shared_alloc_lock(TSRMLS_D)
{
    while (1) {
        if (fcntl(lock_file, F_SETLKW, &mem_write_lock) == -1) {
            if (errno == EINTR) {
                continue;
            }
            zend_accel_error(ACCEL_LOG_ERROR, "Cannot create lock - %s (%d)", strerror(errno), errno);
        }
        break;
    }
    ZCG(locked) = 1;
    zend_hash_init(&xlat_table, 100, NULL, NULL, 1);
}</code></pre>
<p>I here talked about memory locks happening on normal process : nothing bad, if you take care, no more than one PHP process should be writing to the shm at the same time, so you won't suffer from any lock waiting times.</p>
<p>There exists however another lock that you should prevent from happening : the memory exhausted lock. This is the next chapter</p>
<h3 id="understanding-the-opcache-memory-consumption">Understanding the OPCache memory consumption<a href="#understanding-the-opcache-memory-consumption" class="anchor">#</a></h3>
<p>So I remind you with facts :</p>
<ul><li>OPCache creates one unique segment of shared memory, once for all, at PHP startup (when you start PHP-FPM)</li>
<li>OPCache never frees some shm into this segment, the segment is allocated at startup, then filled-in according to the needs</li>
<li>OPCache locks shm when it writes into it</li>
<li>shm is used for several purposes :
<ol><li>Script's datastructure caching, involving obviously OPCodes caching but not only</li>
<li>Shared interned strings buffer</li>
<li>Cached scripts HashTable</li>
<li>Global OPCache shared memory state</li>
</ol></li>
</ul><p>If you use validation of your scripts, OPCache will check their modification date at every access (not every, check <em>opcache.revalidate_freq</em> INI setting), and will have a hint of wheither the file is fresh or stale. This check is cached : it is <strong>not</strong> costly as opposed to what you could think. OPCache comes into the scene some time after PHP, and PHP has already <code>stat()</code>ed the file : OPCache just reuses this information and does not issue a costly <code>stat()</code> call to the filesystem again for its own use.</p>
<p>If you use timestamp validation, via <em>opcache.validate_timestamps</em> and <em>opcache.revalidate_freq</em>, and your file has effectively changed, then OPCache will simply invalidate it, and flag all of its shm data as invalid. It will not free anything from shm. OPCache flags the shm parts as "wasted". <strong>Only when OPCache runs out of shm on an allocation AND when wasted memory reaches the <em>opcache.max_wasted_percentage</em> INI setting value, OPCache will trigger a full restart, which is something you must absolutely prevent from happening</strong> No other scenario.</p>
<pre><code>/* Calculate the required memory size */
memory_used = zend_accel_script_persist_calc(new_persistent_script, key, key_length TSRMLS_CC);

/* Allocate shared memory */
ZCG(mem) = zend_shared_alloc(memory_used);
if (!ZCG(mem)) {
    zend_accel_schedule_restart_if_necessary(ACCEL_RESTART_OOM TSRMLS_CC);
    zend_shared_alloc_unlock(TSRMLS_C);
    return new_persistent_script;
}</code></pre>
<p><img src="../../../img/opcache/opcache-wasted-shm.png" alt="opcache-wasted-shm"></p>
<p>The picture above details what your shm segment could look like after some time has passed and some scripts have changed. The changed scripts' memory has been marked as "wasted", and OPCache will simply now ignore those memory areas, as well as it will recompile your changed scripts and create a new memory segment for their informations.</p>
<p>When enough wasted memory is reached, a restart will happen, OPCache will then lock shm, reset the shm segment (empty it entirely), and release the lock. This will let your server in a situation like if it has just started : every PHP worker is going to stress the lock now, because every worker will try to compile some files : your web server will now suffer from a very poor performance because of locks. The more the load, the less performance, this is unfortunately the rule with locks. So your server may really suffer for long seconds now.</p>
<blockquote>
<p><strong>Never run out of shared memory</strong></p>
</blockquote>
<p>More generally, what you should do is disable script modification tracking on production server, that way you are sure the cache will never trigger a restart (this is not entirely true as OPCache may still run out of persistent script key space, we'll see that later). A classic deployment should follow the rules :</p>
<ul><li>take out the server from load (disconnect it from your load balancer)</li>
<li>empty opcache (call <code>opcache_reset()</code>) or directly shut down FPM (better, we'll detail in few minutes)</li>
<li>deploy a new version of your application at once</li>
<li>restart your FPM pool if needed and prime your new cache smoothly by triggering curl request on major application entry points</li>
<li>open back your server to traffic</li>
</ul><p>All this can be done with a 50 line shell script that can be turned very robust playing with <code>lsof</code> and <code>kill</code> in case some hard requests don't seem to finish. Bring your Unix knowledge ;-) </p>
<p>You can even see what happens using one of the numerous GUI frontends for OPCache available anywhere on the web and Github, they all make use of the <code>opcache_get_status()</code> function:</p>
<p><img src="../../../img/opcache/opcache-frontend.png" alt="opcache-frontend"></p>
<p>This is not the full story though, there is another thing to clearly keep in mind : <strong>cache keys</strong>.</p>
<p>When OPCache stores a cached script into SHM, it stores its into a HashTable, to be able to find the script back after. But it has to choose a key to index the HashTable. What index/key does OPCache use to achieve this goal ? This highly depends on both the configuration, and the way your app has been designed.</p>
<p>Normally, OPCache resolves the full path to the script, but take care as it uses <a href="http://jpauli.github.io/2014/06/30/realpath-cache.html">the PHP's realpath cache</a> and you may suffer from it. If you change your documentroot using a symlink, put <em>opcache.revalidate_path</em> to 1 and empty your realpath cache (which may be hard to do as it is bound to the PHP worker process handling the current request).</p>
<p>So OPCache resolves the path to the file, and when resolved, <strong>it uses the realpath string as cache key for the script</strong>, and that's all, assuming you have  <em>opcache.revalidate_path</em> INI setting turned to 1. If not, OPCache will also use the <strong>unresolved path</strong> as a cache key, and that will lead to problems if you were using symlinks, because if you then change the symlink target, OPCache will not notice it, as it will still use the unresolved path as key to find the old targetted script (this is to save a symlink resolution call).</p>
<p>By turning <em>opcache.use_cwd</em> to 1, you tell OPCache to prepend the <code>cwd</code> to every key, in case you use <em>relative paths</em> to include your files, like <code>require_once "./foo.php";</code>. I suggest, if you use relative paths and host several applications on the same PHP instance (which you shouldn't do), to always put <em>opcache.use_cwd</em> to 1. Also, if you happen to play with symlinks, turn <em>opcache.revalidate_path</em> to 1. But even with those settings on, you will suffer from <a href="http://jpauli.github.io/2014/06/30/realpath-cache.html">PHP's realpath cache</a>, and you may change the <em>www</em> symlink to another target, it won't be noticed by OPCache, even if you empty the cache by using <code>opcache_reset()</code>.</p>
<blockquote>
<p>Because of PHP's realpath cache, you may experience problems if using symlinks to handle your documentroot for deployment. Turn <em>opcache.use_cwd</em> and <em>opcache.revalidate_path</em> to 1, but even with those settings, bad symlink resolutions may happen, this is because PHP answers OPCache realpath resolution requests with a wrong answer, comming from its realpath_cache mechanism.</p>
</blockquote>
<p>If you want to be extra safe in your deployment, the first option is to not use symlinks to manage your documentroot.
If not, then use a double FPM pool, and use a FastCGI load balancer to balance between the two pools when deploying. Lighttpd and Nginx have this feature enabled by default as far as I remember :</p>
<ul><li>take out the server from load (disconnect it from your load balancer)</li>
<li>shut down FPM, you will kill PHP (and then OPCache) and will be extra safe especially about PHP's realpath cache, which may trick you. This latter will be cleared if you shut down FPM. Monitor the eventual workers that may be stuck, and kill them if necessary.</li>
<li>deploy a new version of your application at once</li>
<li>restart your FPM pool. Don't forget to prime your new cache smoothly by triggering curl requests on major application entry points before</li>
<li>open back your server to traffic</li>
</ul><p>If you don't want to take your server out of the balancer, what can be done then, is :</p>
<ul><li>Deploy your new code into another directory, as your PHP server has one FPM pool still active and serving production requests</li>
<li>Start another FPM pool, listening on another port, while still having the first FPM pool active and serving production requests</li>
<li>Now you have two FPM pools, one hot and working, one idle, waiting to be bound to requests</li>
<li>Change your documentroot symlink target to target the new deploy path, and immediately after, stop the first FPM pool. If you told your webserver about your two pools, it should notice the first pool is dying, and should load balance traffic to the new pool now, with no traffic interruption nor failing requests. The second pool will then be triggered, will resolve the new docroot symlink (as it is fresh and has a cleared realpath cache), and serve your new content. This clearly works, I used that on production servers many times, a ~80 lines well written shell script can take care of all this job.</li>
</ul><p>So depending on the settings, one unique script may lead to several keys computed by opcache. But the key store is not infinite : it is also allocated into shared memory, and may get full, in which case even if there is still lot of room into the shm, because the persistent script hashtable is full, OPCache will behave like if it had no more memory, and will trigger a restart for next requests. </p>
<blockquote>
<p>You always should monitor the number of keys in the key store, for it never to be full.</p>
</blockquote>
<p>OPCache gives you this information with the use of <code>opcache_get_status()</code>, a function the different GUIs rely on. The <em>num_cached_keys</em> dimension returned by this function gives the info. You should preconfigure the number of keys, as a hint, using <em>opcache.max_accelerated_files</em> INI setting. Take care as the name suggests a number of files, in fact it is the number of keys that OPCache will compute, and as we've seen, one file may lead to several keys beeing computed. Monitor it, and use the right number. Avoid using relative paths in require_once statements, it makes OPCache generate more keys. Using an autoloader is recommanded, as this one, if well configured, will always issue include_once calls with full paths, and not relative ones.</p>
<blockquote>
<p>OPCache preallocates the HashTable to store future persistent scripts when it starts (when PHP starts), and never tries to resize it. If it gets full, it will then trigger a restart. This is done for performance reasons.</p>
</blockquote>
<p>So this is why you may see a <em>num_cached_scripts</em> dimension which is different from the <em>num_cached_keys</em> dimension, from OPcache status report. Only the <em>num_cached_keys</em> info is relevant, if it reaches <em>max_cached_keys</em>, you'll be in trouble with a restart pending.</p>
<p>Do not forget that you can understand what happens by lowering OPCache's log level (<em>opcache.log_verbosity_level</em> INI). It tells you if it runs out of memory, and which kind of OOM (OutOfMemory) error it generated : if it is related to the shm beeing full, or if it is the keys Hashtable which is full.</p>
<p><img src="../../../img/opcache/opcache-log.png" alt="opcache-log"></p>
<pre><code>static void zend_accel_add_key(char *key, unsigned int key_length, zend_accel_hash_entry *bucket TSRMLS_DC)
{
    if (!zend_accel_hash_find(&ZCSG(hash), key, key_length + 1)) {
        if (zend_accel_hash_is_full(&ZCSG(hash))) {
            zend_accel_error(ACCEL_LOG_DEBUG, "No more entries in hash table!");
            ZSMMG(memory_exhausted) = 1;
            zend_accel_schedule_restart_if_necessary(ACCEL_RESTART_HASH TSRMLS_CC);
        } else {
            char *new_key = zend_shared_alloc(key_length + 1);
            if (new_key) {
                memcpy(new_key, key, key_length + 1);
                if (zend_accel_hash_update(&ZCSG(hash), new_key, key_length + 1, 1, bucket)) {
                    zend_accel_error(ACCEL_LOG_INFO, "Added key '%s'", new_key);
                }
            } else {
                zend_accel_schedule_restart_if_necessary(ACCEL_RESTART_OOM TSRMLS_CC);
            }
        }
    }
}</code></pre>
<p>So, to conclude about memory usage, here is the picture :</p>
<p><img src="../../../img/opcache/OPCache-memory-structure.png" alt="OPCache-memory-structure"></p>
<p>When you start PHP, you start OPCache, it allocates immediately <em>opcache.memory_consumption</em> Megabytes of shared memory (shm) from the OS.
It then starts using this space, and stores into it the interned strings buffer (<em>opcache.interned_strings_buffer</em>). After that, it preallocates the HashTable for future persistent scripts and their keys to be stored. The space used depends on the <em>opcache.max_accelerated_files</em>.</p>
<p>Now, a part of the shm is used by OPCache internals, and the non-occupied space left is dedicated to you : to your scripts datastructures. This (actually free) memory segment will then be filled in, and as your scripts will change and OPCache will recompile them (assuming you told it to), the space will slowly become "wasted"; except if you tell OPCache not to recompile changed scripts (recommanded).</p>
<p>That may look like something like that :</p>
<p><img src="../../../img/opcache/OPCache-memory-structure-hot.png" alt="OPCache-memory-structure-hot"></p>
<p>If persistent scripts HashTable becomes full, or if free SHM runs out : OPCache will trigger a restart (which you'd want to prevent absolutely).</p>
<h3 id="configuring-opcache">Configuring OPCache<a href="#configuring-opcache" class="anchor">#</a></h3>
<p>If you use a framework based application, like a Symfony based application, I strongly suggest :</p>
<ul><li>you turn off revalidation mechanism on production (turn <em>opcache.validate_timestamps</em> to 0)</li>
<li>you deploy using a full new runtime of your scripts, this is the case with Symfony applications</li>
<li>you size correctly your buffers
<ol><li><em>opcache.memory_consumption</em>, the most important</li>
<li><em>opcache.interned_strings_buffer</em> , monitor your usage, and size accordingly, take care if you tell OPCache to save comments, which you will likely do if you use PHP "annotations" (<em>opcache.save_comments = 1</em>), those are strings, big strings, that will eat your interned strings buffer</li>
<li><em>opcache.max_accelerated_files</em> , numbers of keys to preallocate, once more : monitor and size accordingly</li>
</ol></li>
<li>You turn off <em>opcache.opcache.revalidate_path</em> and <em>opcache.use_cwd</em>. That will save some key space</li>
<li>You turn on <em>opcache.enable_file_override</em> , this will accelerate the autoloader</li>
<li>You fill-in <em>opcache.blacklist_filename</em> list with the script names you are likely to generate during runtime; shouldn't be too many of them anyway</li>
<li>You turn off <em>opcache.consistency_checks</em>, this basically checks a control sum on your scripts, that eats perf</li>
</ul><p>With those settings, your memory should never get wasted, then <em>opcache.max_wasted_percentage</em> is not very useful in this case.
With those settings, you'll need to turn off your main FPM instance when deploying. You may play with several FPM pools to prevent service downtime, like explained earlier.</p>
<p>That should be enough.</p>
<h3 id="opcache-compiler-s-optimizer">OPCache compiler's optimizer<a href="#opcache-compiler-s-optimizer" class="anchor">#</a></h3>
<h4 id="introducing">Introducing<a href="#introducing" class="anchor">#</a></h4>
<p>So we talked about caching OPCodes into shm and loading them back later. Just before caching them, OPCache may also run optimizer passes.
To fully understand the optimizer, you have to have a good knowledge of <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html">how the Zend VM Executor works</a>. Also, you may bring your compiler knowledge, if you are very new to such concepts, perhaps starting <a href="https://msdn.microsoft.com/en-us/magazine/dn904673.aspx">reading some articles on the subject</a> may help ? Or at least the mandatory-reading <a href="http://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools">Dragon Book</a> ? Anyway I'll try to make the subject understandable and fun to read.</p>
<p>Basically, the optimizer is given the whole OPArray structure, and may now browse it, find flaws, and fix them. But as we are analyzing OPCodes <strong>at compile time</strong>, we have no clue at all on everything tied to a "PHP variable". Basically, we don't know yet what will be stored in any <em>IS_VAR</em> or <em>IS_CV</em> operand, but only in <em>IS_CONST</em> or sometimes in <em>IS_TMP_VAR</em>.
Like in any compiler for every languages : we must create the most optimized structure to be run at runtime, so that the runtime will be the fastest as possible.</p>
<p>OPCache optimizer can optimize a lot of things in <em>IS_CONST</em>; We can also replace some OPCodes by others (more optimized at runtime), we also find and trash dead code branches by using a CFG (control flow graph) analysis, but we don't unroll loops, or process to loop invariant motions as such optimizations are hard to apply to PHP.
We also have other possibilities related to PHP internals : we may change the way classes are bound to optimize a bit the process in some specific cases, but we have absolutely not the possibility to do some cross file optimizations, because OPCache plays with OPArrays coming from file compilation (among other functions' OPArrays), and there is a total isolation of those OPArrays. PHP has never been built on a cross file based VM : the Virtual Machine and the language is file bound : when compiling a file, we have absolutely no information about the files that already got compiled, and those to come next.
We then must try to optimize on a file-by-file basis, and must not assume for example that class A will be present in the future, if it is not at the moment. This is very different from Java or C++ that compile using compilation units and allowing cross-file optimizations; PHP simply won't do that, it's not been designed like that.</p>
<blockquote>
<p>The PHP compiler acts on a file basis and has no shared state through file compilations, it doesn't compile a project in its whole, but a file, followed by others.
There is no room for cross file optimizations.</p>
</blockquote>
<p>OPCache optimization passes can be enabled on a case-by-case basis, using the INI setting <em>opcache.optimization_level</em>. It should represent a mask for optimizations you'd like to see enabled, based on their binary values :</p>
<pre><code>/* zend_optimizer.h */
#define ZEND_OPTIMIZER_PASS_1       (1<<0)   /* CSE, STRING construction     */
#define ZEND_OPTIMIZER_PASS_2       (1<<1)   /* Constant conversion and jumps */
#define ZEND_OPTIMIZER_PASS_3       (1<<2)   /* ++, +=, series of jumps      */
#define ZEND_OPTIMIZER_PASS_4       (1<<3)   /* INIT_FCALL_BY_NAME -> DO_FCALL */
#define ZEND_OPTIMIZER_PASS_5       (1<<4)   /* CFG based optimization       */
#define ZEND_OPTIMIZER_PASS_6       (1<<5)
#define ZEND_OPTIMIZER_PASS_7       (1<<6)
#define ZEND_OPTIMIZER_PASS_8       (1<<7)   
#define ZEND_OPTIMIZER_PASS_9       (1<<8)   /* TMP VAR usage                */
#define ZEND_OPTIMIZER_PASS_10      (1<<9)   /* NOP removal                 */
#define ZEND_OPTIMIZER_PASS_11      (1<<10)  /* Merge equal constants       */
#define ZEND_OPTIMIZER_PASS_12      (1<<11)  /* Adjust used stack           */
#define ZEND_OPTIMIZER_PASS_13      (1<<12)
#define ZEND_OPTIMIZER_PASS_14      (1<<13)
#define ZEND_OPTIMIZER_PASS_15      (1<<14)  /* Collect constants */

#define ZEND_OPTIMIZER_ALL_PASSES   0xFFFFFFFF

#define DEFAULT_OPTIMIZATION_LEVEL  "0xFFFFBFFF"</code></pre>
<h4 id="known-constant-statements-and-branch-trashing">Known constant statements and branch trashing<a href="#known-constant-statements-and-branch-trashing" class="anchor">#</a></h4>
<p>Note that many compile-time known constant statements are NOT computed by the compiler but by OPCache, for PHP 5.
In PHP 7, those are computed in the compiler.</p>
<p>Here we go with examples :</p>
<pre><code>if (false) {
    echo "foo";
} else {
   echo "bar";
}</code></pre>
<p>This leads in classical compilation to :</p>
<p><img src="../../../img/opcache/optimizer/1.png" alt="OPCache-optimizer-1"></p>
<p>And optimized compilation :</p>
<p><img src="../../../img/opcache/optimizer/1-opt.png" alt="OPCache-optimizer-1-opt"></p>
<p>As we can see, the dead code in the <code>if(false)</code> branch has been trashed, the Zend VM executor will then simply have to run a <code>ZEND_ECHO</code> OPcode. We then saved some memory, because we threw away some OPCodes, and we may save a little bit of CPU cycles at runtime as well.</p>
<p>I recall you that we cannot know the content of any variable yet, as we are still at compile time (we are between compilation and execution). A code with an <em>IS_CV</em> operand instead of <em>IS_CONST</em>, could not have been optimized :</p>
<pre><code>/* That cant be optimized, what's in $a ? */
if ($a) {
    echo "foo";
} else {
   echo "bar";
}</code></pre>
<p>Let's take another example so that you see the differences between PHP 5 and PHP 7 :</p>
<pre><code>if (__DIR__ == '/tmp') {
    echo "foo";
} else {
   echo "bar";
}</code></pre>
<p>In PHP 7, the constant <code>__DIR__</code> will be substituted and the equality check will be performed by the PHP 7 compiler, that is without OPCache. However, the branch analysis and the branch dead code removing is still done by an OPCache optimizer pass.
In PHP 5 however, the constant <code>__DIR__</code> is still substituted, but the equality check is not performed by PHP 5 compiler. This latter is performed by OPCache.</p>
<p>So here to sum up things, if you run both PHP 5 and PHP 7 with OPCache optimizer activated, you will end up to the exact same optimized OPCodes. But if you don't run OPCache optimizer, then the PHP 5 compiled code will be less efficient than the equivalent PHP 7 one, because the PHP 5 compiler doesn't perform any evaluation, whereas PHP 7 compiler computes a lot of things by itself (without the need of OPCache optimizer that would come later).</p>
<h4 id="constant-functions-pre-evaluation">Constant functions pre-evaluation<a href="#constant-functions-pre-evaluation" class="anchor">#</a></h4>
<p>However, OPCache is able to turn some <em>IS_TMP_VAR</em> to <em>IS_CONST</em>. That is, OPCache can compute itself at compile time, some known values.
Some functions can be run at compile time, because their result will be constant. This is the case of several of them :</p>
<ul><li><code>function_exists()</code> and <code>is_callable()</code>, for internal functions only</li>
<li><code>extension_loaded()</code>, if <code>dl()</code> is disabled in userland</li>
<li><code>defined()</code> and <code>constant()</code> for internal constants only</li>
<li><code>dirname()</code> if the argument is constant</li>
<li><code>strlen()</code> and <code>dirname()</code> with constant argument (PHP 7 only)</li>
</ul><p>So look at that example :</p>
<pre><code>if (function_exists('array_merge')) {
    echo 'yes';
}</code></pre>
<p>Here, if the optimizer is diabled, the compiler generates many work to do for the runtime :</p>
<p><img src="../../../img/opcache/optimizer/7.png" alt="OPCache-optimizer-7"></p>
<p>Optimized as :</p>
<p><img src="../../../img/opcache/optimizer/7-opt.png" alt="OPCache-optimizer-7-opt"></p>
<p>Notice that those functions don't compute userland-based. For example :</p>
<pre><code>if function_exists('my_custom_function')) { }</code></pre>
<p>is not optimized, because you are very likely to have (or not) defined the 'my_custom_function' is another file. And remember, the PHP compiler and OPCache optimizer only works on a file basis. Even if you do that :</p>
<pre><code>function my_custom_function() { }
if function_exists('my_custom_function')) { }</code></pre>
<p>That will not be optimized, because this is too unlikely to happen, the function call optimizer only works for <em>internal</em> types (internal functions, internal constants).</p>
<p>Another example with <code>dirname()</code> (PHP 7 only) :</p>
<pre><code>if (dirname(__FILE__) == '/tmp') {
    echo 'yo';
}</code></pre>
<p>Not optimized :</p>
<p><img src="../../../img/opcache/optimizer/8.png" alt="OPCache-optimizer-8"></p>
<p>Optimized :</p>
<p><img src="../../../img/opcache/optimizer/7-opt.png" alt="OPCache-optimizer-8-opt"></p>
<p>Again, <code>strlen()</code> is optimized in PHP 7. If we chain them together, we obviously meet a nice optimization. Like this :</p>
<pre><code>if (strlen(dirname(__FILE__)) == 4) {
    echo "yes";
} else {
    echo "no";
}</code></pre>
<p>Not optimized :</p>
<p><img src="../../../img/opcache/optimizer/10.png" alt="OPCache-optimizer-10"></p>
<p>Optimized :</p>
<p><img src="../../../img/opcache/optimizer/10-opt.png" alt="OPCache-optimizer-10-opt"></p>
<p>For the example above, you can notice that every statement have been computed at compile/optimization time, and then OPCache optimizer trashed all the 'false' branch (assuming obviously that the 'true' part was chosen).</p>
<h4 id="transtyping">Transtyping<a href="#transtyping" class="anchor">#</a></h4>
<p>OPCache optimizer may switch your <em>IS_CONST</em> operand types, when it knows runtime will have to transtype them. That effectively saves some CPU cycles at runtime :</p>
<pre><code>$a = 8;
$c = $a + "42";
echo $c;</code></pre>
<p>Classical compilation :</p>
<p><img src="../../../img/opcache/optimizer/2.png" alt="OPCache-optimizer-2"></p>
<p>Optimized compilation :</p>
<p><img src="../../../img/opcache/optimizer/2-opt.png" alt="OPCache-optimizer-2-opt"></p>
<p>Look at the second operand true type of <code>ZEND_ADD</code> operation : it has switched from a string to an int. The optimizer did the job of transtyping the argument type for the math add operation. If it had not : the runtime VM would have done it again, and again, and again as the code is run again, and again, and again. This saves some CPU cycles involved in the transtyping operation.</p>
<p>Here is the OPCache optimizer code that does such a job :</p>
<pre><code>if (ZEND_OPTIMIZER_PASS_2 & OPTIMIZATION_LEVEL) {
    zend_op *opline;
    zend_op *end = op_array->opcodes + op_array->last;

    opline = op_array->opcodes;
    while (opline < end) {
        switch (opline->opcode) {
            case ZEND_ADD:
            case ZEND_SUB:
            case ZEND_MUL:
            case ZEND_DIV:
                if (ZEND_OP1_TYPE(opline) == IS_CONST) {
                    if (ZEND_OP1_LITERAL(opline).type == IS_STRING) {
                        convert_scalar_to_number(&ZEND_OP1_LITERAL(opline) TSRMLS_CC);
                    }
                }
                /* break missing *intentionally* - the assign_op's may only optimize op2 */
            case ZEND_ASSIGN_ADD:
            case ZEND_ASSIGN_SUB:
            case ZEND_ASSIGN_MUL:
            case ZEND_ASSIGN_DIV:
                if (opline->extended_value != 0) {
                    /* object tristate op - don't attempt to optimize it! */
                    break;
                }
                if (ZEND_OP2_TYPE(opline) == IS_CONST) {
                    if (ZEND_OP2_LITERAL(opline).type == IS_STRING) {
                        convert_scalar_to_number(&ZEND_OP2_LITERAL(opline) TSRMLS_CC);
                    }
                }
                break;
    /* ... ... */</code></pre>
<p>You should note however, that such optimization has been merged into the PHP 7 compiler. That means that even with OPCache disabled (or optimizations disabled), PHP 7 compiler already performs such an optimization, as well as many more that were not performed by the PHP 5 compiler.      </p>
<p>A little bit more silly, but adding two <em>IS_CONST</em> expressions, the result can then be computed at compile time, something the PHP compiler does not do by default in PHP 5, OPCache optimizer is needed :</p>
<pre><code>$a = 4 + "33";
echo $a;</code></pre>
<p>Classical compilation :</p>
<p><img src="../../../img/opcache/optimizer/3.png" alt="OPCache-optimizer-3"></p>
<p>Optimized compilation :</p>
<p><img src="../../../img/opcache/optimizer/3-opt.png" alt="OPCache-optimizer-3-opt"></p>
<p>The optimizer computed the maths for <code>4 + 33</code>, and erased the <code>ZEND_ADD</code> operation to be run by replacing it directly by the result. This saves again some CPU at runtime, as the VM executor now has less job to do. Here again, this is done in PHP 7 by the compiler, whereas in PHP 5 you would need OPCache optimizer to do that.</p>
<h4 id="optimized-opcodes-substitution">Optimized OPCodes substitution<a href="#optimized-opcodes-substitution" class="anchor">#</a></h4>
<p>Now let's dive deeper into OPCodes. Sometimes (rarely), it is possible to substitue a following of OPCodes by other ones, more optimized. Look at that :</p>
<pre><code>$i = "foo";
$i = $i + 42;
echo $i;</code></pre>
<p>Classical compilation :</p>
<p><img src="../../../img/opcache/optimizer/4.png" alt="OPCache-optimizer-4"></p>
<p>Optimized compilation :</p>
<p><img src="../../../img/opcache/optimizer/4-opt.png" alt="OPCache-optimizer-4-opt"></p>
<p>Here, our knowledge of the Zend VM executor leads us to substitue a <code>ZEND_ADD</code> plus a <code>ZEND_ASSIGN</code>, into a <code>ZEND_ASSIGN_ADD</code>, usually involved in statements such as <code>$i+=3;</code>
<code>ZEND_ASSIGN_ADD</code> is more optimized, it is one OPCode instead of two (which usually is better, but not every time)</p>
<p>On the same subject :</p>
<pre><code>$j = 4;
$j++;
echo $j;</code></pre>
<p>Classical compilation :</p>
<p><img src="../../../img/opcache/optimizer/5.png" alt="OPCache-optimizer-5"></p>
<p>Optimized compilation :</p>
<p><img src="../../../img/opcache/optimizer/5-opt.png" alt="OPCache-optimizer-5-opt"></p>
<p>Here, OPCache optimizer replaced the <code>$i++</code> by a <code>++$i</code> statement, because it had the same meaning in this piece of code. <code>ZEND_POST_INC</code> is not very nice OPCode, because it must read the value, return it as-is, but increment a temporary value in memory, whereas <code>ZEND_PRE_INC</code> plays with the value itself, and reads it, increments it and returns it (this is just the PRE vs POST incrementation difference).
Because the intermediate value returned by <code>ZEND_POST_INC</code> is not used in the script above, the compiler must issue a <code>ZEND_FREE</code> OPCode, to free it from memory. OPCache optimizer turns the structure into a <code>ZEND_PRE_INC</code>, and removes the useless <code>ZEND_FREE</code> : less job to figure out at runtime.</p>
<h4 id="constant-substitution-and-precomputing">Constant substitution and precomputing<a href="#constant-substitution-and-precomputing" class="anchor">#</a></h4>
<p>What about PHP constants ? They are more complex that what you think (much more in fact). So some optimizations that may seems obvious actually don't happen for many reasons, but let's see the actual ones :</p>
<pre><code>const FOO = "bar";
echo FOO;</code></pre>
<p><img src="../../../img/opcache/optimizer/6.png" alt="OPCache-optimizer-6"></p>
<p>Optimized compilation :</p>
<p><img src="../../../img/opcache/optimizer/6-opt.png" alt="OPCache-optimizer-6-opt"></p>
<p>This is part of temporary variables optimizations, as we can see, here, once again, one OPCode have been trashed, the result of constant reading is directly figured out at compile time, into the optimizer, and the runtime will have less work to do.</p>
<p>Also, that ugly <code>define()</code> function can be replaced by a <code>const</code> statement, if its argument is constant :</p>
<pre><code>define('FOO', 'bar');
echo FOO;</code></pre>
<p>The non optimized OPCodes from this little script are horrible in term of performance :</p>
<p><img src="../../../img/opcache/optimizer/9.png" alt="OPCache-optimizer-9"></p>
<p>Optimized, is as expected :</p>
<p><img src="../../../img/opcache/optimizer/6-opt.png" alt="OPCache-optimizer-9-opt"></p>
<p><code>define()</code> is ugly, because it declares a constant but runs such a job at runtime, issuing a function call (<code>define()</code> is really a function). This is very bad.
The <code>const</code> keyword leads to a <code>DECLARE_CONST</code> OPCode. <a href="http://jpauli.github.io/2015/02/05/zend-vm-executor.html#define-and-const">More on that in my ZendVM article</a>. Note that in PHP 7, <code>define()</code> may lead to a const construct into the compiler directly (no optimizer needed).</p>
<h4 id="multiple-jump-target-resolution">Multiple jump target resolution<a href="#multiple-jump-target-resolution" class="anchor">#</a></h4>
<p>This is actually a little bit hard to detail, but as usual with a simple example, you'll understand.
This optimization is about jump targets in jump opcodes (there are several flavors of them). Everytime the VM must jump, a jump address is computed by the compiler and stored into the VM operand. A jump is the result of a decision when the VM meets a decision point.
There are lots of jumps into PHP scripts. <code>if</code>, <code>switch</code>, <code>while</code>, <code>try</code>, <code>foreach</code>, <code>?:</code>  ... are PHP statements making decision, if the decision is true : jump to branch A, if not, jump to branch B.</p>
<p>Such algorithms can be optimized if the jump target is itself a jump. The landing jump will then make the VM jump again, to a final landing jump.
Multiple jump target resolution is about directly making the VM jump to the final target.</p>
<p>Something like that :</p>
<pre><code>if ($a) {
    goto a;
} else {
    echo "no";
}

a:
echo "a";</code></pre>
<p>With classical compilation, we end up with such OPCodes :</p>
<p><img src="../../../img/opcache/optimizer/11.png" alt="OPCache-optimizer-11"></p>
<p>Translated (just read it) as : "if the result of $a evaluation is zero, jump to target 3, in target 3 echo "no". If not, continue, and meet a jump to 4. In 4, echo "a".</p>
<p>This is something like "Jump to 3, and in 3, jump to 4". Why not "jump to 4" directly then ?
This is what the optimization does :</p>
<p><img src="../../../img/opcache/optimizer/11-opt.png" alt="OPCache-optimizer-11-opt"></p>
<p>Here, we can translate that by "if $a evaluation is not zero, jump to 2 which echoes "a", if not, echo "no".  Much simpler isn't it ?
This optimization shows true power in case of very complex scripts with many levels of decisions. Like having a <code>while</code> into an <code>if</code>, in which a <code>goto</code> is performed, leading to a <code>switch</code> which performs <code>try-catches</code> , etc...
Without this optimization, the overall OPArray may contain tons of OPCodes. Those will mainly be jumps, but probably jumps leading to jumps. Activating this optimization can sometimes (depend on the script) reduce significantely the number of OPCodes and ease the path the VM will branch ; leading in little gain of performances at runtime.</p>
<h4 id="concluding">Concluding<a href="#concluding" class="anchor">#</a></h4>
<p>I did not show you all the work done by the optimizer. It can also optimize embeded loops by issuing "early returns" for example. Same for embed try catch blocks or switch-breaks. PHP function calls, which is a heavy process into the engine, is also optimized when possible.</p>
<blockquote>
<p>The main difficulty in optimizer passes, is to never change the meaning of the script, and especially its control flow.</p>
</blockquote>
<p>The main difficulty in optimizer passes, is to never change the meaning of the script, and especially its control flow. Bugs were found about this some time ago in OPCache, and it is all but cool when you come to see that PHP executor doesn't behave the way it should, having your little PHP script written under your eyes... In fact, the OPCodes generated have been altered by the optimizer and the engine just runs something which is wrong. Not cool.</p>
<p>Nowadays, OPCache optimizer is pretty stable but still under developpment for next PHP versions. It had to be patched in deep for PHP 7 as that latter changed many things in internal structures design, as well as having a PHP 7 compiler doing much more optimization job (the most trivial however) than PHP 5 used to do (PHP 5 compiler really does not optimize anything).</p>
<blockquote>
<p>The PHP 7 compiler is much more efficient that PHP 5's. A lot of optimizations before performed in PHP 5 OPCache are now embeded directly into PHP 7's heart.</p>
</blockquote>
<h3 id="end">End<a href="#end" class="anchor">#</a></h3>
<p>We've seen that OPCache has finally become the standard recommanded PHP OPCode caching solution. We detailed how it works, not that hard to understand, but error prone yet. Nowadays, OPCache is very mature/stable and achieves its goal of boosting dramatically the overall performance of the PHP language by both canceling the time needed to compile a script and by optimizing the OPCodes resulting of the compilation. Shared memory is used for every process of a PHP pool to be able to access structures that have been added by others. Interned strings buffer is also managed in shared memory, leading to even more memory savings in a PHP pool of workers - typically using PHP-FPM SAPI.</p>]]></content>
    </entry>
        <entry>
        <title>Getting into the Zend Execution engine (PHP 5)</title>
                <id>http://jpauli.github.io//2015/02/05/zend-vm-executor.html</id>
                <updated>2015-02-05T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/02/05/zend-vm-executor.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="php-an-interpreted-language">PHP : an interpreted language<a href="#php-an-interpreted-language" class="anchor">#</a></h2>
<p>PHP is often defined as a "scripting language" or an "interpreted language". What's that ?</p>
<p>Well, it is a language that won't turn its instructions (its syntax) directly into native machine language, but into an intermediate form, that obviously won't be directly run by the CPU (as this one wouldn't understand the instructions), but by an intermediate code base, itself being written using native machine instructions this time (we use the C language for that nowadays).</p>
<p>That's basically the definition of a <em>software virtual machine</em>. Quoting Wikipedia :</p>
<blockquote>
<p>(...) process virtual machines are designed to execute a single computer program by providing an abstracted and platform-independent program execution environment.
A process VM, sometimes called an application virtual machine, or Managed Runtime Environment (MRE), runs as a normal application inside a host OS and supports a single process. It is created when that process is started and destroyed when it exits. Its purpose is to provide a platform-independent programming environment that abstracts away details of the underlying hardware or operating system, and allows a program to execute in the same way on any platform.</p>
</blockquote>
<p>So, the PHP language, like any interpreted language, is a program that is designed to run abstract instructions in a cross platform way, abstracting away as much of the underlying OS details as possible.
This is technically speaking. It's functional domain is the web (PHP is aimed to solve Web related problems).</p>
<p>Other programming languages relying on a software virtual machine are (non exhaustive list) : Java, Python, C#, Ruby, Pascal, Lua, Perl, Javascript... (and many more).
Basically, every language that is not directly and fully turned into native machine instructions, makes use of a software virtual machine.
Software virtual machines are however allowed - to boost their own performance - to turn some of (but not all) the language instructions they support to direct host machine instructions : this process is called "JIT compilation". PHP does not make use of JIT compilation at the time the lines you are reading are written, but experimentations have been done and such an idea has always been analyzed/talked about.</p>
<p>We nowadays use software virtual machine because we don't want to write those thousands of C lines of code everytime we want to say "Hello" on the user screen.
Software virtual machines advantages over native platform programming :</p>
<ul><li>Ease of use and speed of development</li>
<li>Very often if not in 100% cases : automatic memory management</li>
<li>Abstracts target data types, no low level maths to figure out, no code to rewrite when switching target hardware, etc.</li>
</ul><p>And we could write some drawbacks :</p>
<ul><li>No accuracy on memory management or more generally of global resources usage (trust the VM or die)</li>
<li>Slower than native code : more CPU cycles needed to achieve the same task (JIT tries to narrow the gap, but will never make it disappear)</li>
<li>May abstract too many things, often the programmer is too far from its hardware, which leads to diffculties in understanding the exact impact of the code, especially when the load raises</li>
</ul><p>The last line of drawbacks is why I write such an article.
The more the time passes, the more I note this fact : less and less people master the exact impact of the code they write onto the hardware and the network, which in my opinion is not a good thing.
This often makes me think about someone connecting two wires together, crossing his fingers for the overall system behind him not to blow up. It's not about mastering the whole chain, which is not humanely possible, but at least know what we talk about.</p>
<p>So, let me try to show you what PHP does with the code you write. And when you'll have that good understanding, you can extract it and apply it to any other "interpreted" programming languages, as those may be designed a little bit differently from PHP, they all share a very huge part of the concepts. Usually, the main differences you'll find studying other interpreted languages is about using JIT or not, parallelism of the VM code (using threads mainly, PHP does not make use of any parallelism technic) and memory pooling / garbage collecting algorithms.</p>
<h2 id="the-zend-software-virtual-machine">The Zend software virtual machine<a href="#the-zend-software-virtual-machine" class="anchor">#</a></h2>
<p>The main virtual machine (Zend Virtual Machine) is divided into two huge parts, which are tied together :</p>
<ul><li>A compile stack : understands and turns the PHP language instructions into an intermediate form of any abstract kind</li>
<li>An execution stack : takes the intermediate form of code instructions and run them through a dedicated engine, itself written in C or assembly</li>
</ul><p>We won't talk about part 1 here, but <strong>concentrate on the Zend Virtual machine executor</strong>, a very interesting piece of software, highly optimized, crossplatform, runtime hookable, technically highly challenging. Several thousands of C lines of code are involved in this component design, which is reworked partly at every new PHP version release.</p>
<p>We'll assume PHP 5.6 for our examples.</p>
<p>I admit that there are so many things to say, that I had difficulties on where to start, what to show you and in which order for this article. This is a pretty uncommon situation I'm not really used to, but I can't shrink this blog subject into several ones, because all the pieces are really tied together.
As it is perfectly valid to try understanding the executor without having any knowledge of the compiler, even if those two pieces are narrow bound together; when it comes to dissect the huge executor subject so that you will fully understand every concept, well, it's not that easy.</p>
<p>So remember, its not bad that you ignore how PHP compiler works, you don't need those details to study the executor part. Perhaps I'll write a further article about the PHP compiler some time in the future ?</p>
<p>Let's go.</p>
<h3 id="opcode">OPCode<a href="#opcode" class="anchor">#</a></h3>
<p>You hear this word very often if you read PHP internals stuff, or my blog posts for example. We must first define an "OPCode".
Quoting Wikipedia :</p>
<blockquote>
<p>Opcodes can also be found in so-called byte codes and other representations intended for a software interpreter rather than a hardware device. These software based instruction sets often employ slightly higher-level data types and operations than most hardware counterparts, but are nevertheless constructed along similar lines.</p>
</blockquote>
<p><em>ByteCode</em> and <em>OPCode</em> are two different words of different meanings, but we usually allow swapping them for the same meaning.</p>
<p>We'll assume that <strong>a Zend VM OPCode is one low level virtual machine operation</strong>.
The Zend virtual machine contains many OPCodes : it is able to do many things. As PHP evolves, more and more OPCodes are added, because PHP is able to do more and more things.
You can list all the OPCodes by displaying the content of the <a href="http://lxr.php.net/xref/PHP_5_6/Zend/zend_vm_opcodes.h">Zend/zend_vm_opcodes.h</a> file of the PHP source.</p>
<p>Usually, an OPCode name is self-describing. Examples :</p>
<ul><li>ZEND_ADD : Perform a math addition of its two operands</li>
<li>ZEND_NEW : Create an object (a PHP object)</li>
<li>ZEND_EXIT : Exit PHP</li>
<li>ZEND_FETCH_DIM_W : Fetch the dimension of one operand for Writting purpose</li>
</ul><p>etc... PHP 5.6 owns 167 OPCodes, and we can therefore say that the PHP 5.6 virtual machine executor is able to compute 167 different kinds of operations.</p>
<p>An OPCode, internally, is reprensented by the <em>zend_op</em> structure:</p>
<pre><code>struct _zend_op {
    opcode_handler_t handler; /* The true C function to run */
    znode_op op1; /* operand 1 */
    znode_op op2; /* operand 2 */
    znode_op result; /* result */
    ulong extended_value; /* additionnal little piece of information */
    uint lineno;
    zend_uchar opcode; /* opcode number */
    zend_uchar op1_type; /* operand 1 type */
    zend_uchar op2_type; /* operand 2 type */
    zend_uchar result_type; /* result type */
};</code></pre>
<p>When you want to understand an OPCode, you have to <em>think about a simple calculator machine</em> (really): it is fed by two operands (op1 and op2), you ask it to do exactly one operation (handler), and it gives you a result (result), eventually owning a deduction because of an overflow in the maths operation (extended_value).</p>
<p>That's all, nothing more to add, that is a really easy to understand concept.</p>
<p>Every Zend VM OPCode works exactly the same way : there is a handler, which is a C function that owns the code to run (like "add", which will basicaly perform a maths "+" operation).
This handler can use 0, 1 or 2 operands : op1 and op2, and when you run it, it computes something giving you a result, and eventually an additionnal single piece of information (extended_value).</p>
<p>Let's now see together what the ZEND_ADD OPCode looks like :</p>
<pre><code>ZEND_VM_HANDLER(1, ZEND_ADD, CONST|TMP|VAR|CV, CONST|TMP|VAR|CV)
{
    USE_OPLINE
    zend_free_op free_op1, free_op2;

    SAVE_OPLINE();
    fast_add_function(&EX_T(opline->result.var).tmp_var,
        GET_OP1_ZVAL_PTR(BP_VAR_R),
        GET_OP2_ZVAL_PTR(BP_VAR_R) TSRMLS_CC);
    FREE_OP1();
    FREE_OP2();
    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>Abstract the lines you can read above, because they are not even C valid syntax (we'll come back to this later). However, they are pretty easy to spot.</p>
<p>Like you can see, <code>fast_add_function()</code> is called in this ZEND_ADD OPCode handler (this is a classical C function stored somewhere), and it is passed the result, op1 and op2.
Thus, the code that performs the math addition is stored into this <code>fast_add_function()</code>, no need to open this latter.</p>
<p>At the end, CHECK_EXCEPTION() is called, and ZEND_VM_NEXT_OPCODE(). Let's detail this latter instruction now.</p>
<h3 id="a-giant-loop">A giant loop<a href="#a-giant-loop" class="anchor">#</a></h3>
<p>When a PHP script is compiled, its PHP syntax is turned into several OPCodes, following each other. This is the compiler role, and we won't detail it here.</p>
<p>That means that a PHP script does several things : We talk about a PHP script being turned to "an OP array", which is an array of several OPCodes.
Each OPCode code is ended by ZEND_VM_NEXT_OPCODE(), which tells the executor to fetch the immediately next OPCode, and run it. And so on.</p>
<p>All this happens in a loop, which is detailed here (a little bit simplified) :</p>
<pre><code>ZEND_API void execute_ex(zend_execute_data *execute_data TSRMLS_DC)
{
    zend_bool original_in_execution;
    original_in_execution = EG(in_execution);
    EG(in_execution) = 1;

zend_vm_enter:
    execute_data = i_create_execute_data_from_op_array(EG(active_op_array), 1 TSRMLS_CC);

    while (1) {  /* infinite dispatch loop */
        int ret;

        if ((ret = execute_data->opline->handler(execute_data TSRMLS_CC)) > 0) { /* do the job */
            switch (ret) {
                case 1:
                    EG(in_execution) = original_in_execution;
                    return; /* exit from the infinite loop */
                case 2:
                    goto zend_vm_enter;
                    break;
                case 3:
                    execute_data = EG(current_execute_data);
                    break;
                default:
                    break;
            }
        }

    } /* end of infinite dispatch loop */

    zend_error_noreturn(E_ERROR, "Arrived at end of main loop which shouldn't happen");
}</code></pre>
<p>This is what's called the main <strong>Zend Executor dispatch loop</strong>, a while(true), which executes a handler() function, terminated by an instruction (ZEND_VM_NEXT_OPCODE()) telling to change
the <em>execute_data->opline</em> to the next one into the OPArray.</p>
<pre><code>#define ZEND_VM_NEXT_OPCODE() \
CHECK_SYMBOL_TABLES() \
ZEND_VM_INC_OPCODE(); \
ZEND_VM_CONTINUE()

#define ZEND_VM_INC_OPCODE() \
OPLINE++

#define OPLINE execute_data->opline

#define ZEND_VM_CONTINUE()         return 0
#define ZEND_VM_RETURN()           return 1
#define ZEND_VM_ENTER()            return 2
#define ZEND_VM_LEAVE()            return 3</code></pre>
<p>Basically, that's a <em>"do operation 1, do operation 2, do operation 3, ..., return and exit"</em> scenario.
We will see how loops are implemented later, for the moment, just think about a basic series of operations.</p>
<h4 id="quick-example">Quick example<a href="#quick-example" class="anchor">#</a></h4>
<p>Here is an easy example to show the main line :</p>
<pre><code>$a = 8;
$b = 'foo';
echo $a + $b;</code></pre>
<p>This little simple script gets compiled into this OPArray (generated with the help of <a href="pecl.php.net/package/vld">ext/vld</a>) :</p>
<pre><code>compiled vars:  !0 = $a, !1 = $b
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   2     0  >   ASSIGN                                                   !0, 8
   3     1      ASSIGN                                                   !1, 'foo'
   4     2      ADD                                              ~2      !0, !1
         3      ECHO                                                     ~2
   5     4    > RETURN                                                   1</code></pre>
<p><img src="../../../img/zend-vm-executor/opcodes.png" alt="opcodes"></p>
<p>Everyone is OK with that ? We could interpret it as :</p>
<ul><li>Assign 8 to $a</li>
<li>Assign 'foo' to $b</li>
<li>Add the content of $a and $b into a temp variable "~2"</li>
<li>Echo the temp variable "~2"</li>
<li>Return</li>
</ul><p>You may notice a strange RETURN OPCode, the last one. What's that ? Where does this come from ? Well it is easy.</p>
<p>Remember the giant while() loop ? This one is infinite : while(1), go back to analyze this simple loop, you'll notice that the only way to finish it is that the handler() function
returns 1, getting the code into the case 1 of the switch, which holds the 'return' instruction, effectively exiting from the loop.
The RETURN OPCode does nothing else than returning 1, making the Zend VM Executor dispatch loop end, and return.
So yes : every script will end with a RETURN OPCode, if not : the loop would be executed infinitely, not a very good idea right ?</p>
<p>So the PHP compiler has been designed, so that whatever code it compiles, it will end the resulting OP Array with a RETURN statement.
That is to say that compiling a PHP script which is empty (no code at all), will lead to an OPArray containing one unique OPCode : the ZEND_RETURN OPCode. When it is loaded into the VM execution dispatch loop, this latter executes the only RETURN handler code, making the VM return : your empty PHP script does nothing.</p>
<h3 id="oparray">OPArray<a href="#oparray" class="anchor">#</a></h3>
<p>We have used this "OPArray" word many times, let's now define it. We suggested in our usage of this word, that an OPArray is a simple array containing OPCodes to be run sequencialy.
Something like this :</p>
<p><img src="../../../img/zend-vm-executor/oparray-1.png" alt="oparray"></p>
<p>Well, this is not absolutely true, but it's not far from reality.
Here is an OPArray :</p>
<pre><code>struct _zend_op_array {
    /* Common elements */
    zend_uchar type;
    const char *function_name;
    zend_class_entry *scope;
    zend_uint fn_flags;
    union _zend_function *prototype;
    zend_uint num_args;
    zend_uint required_num_args;
    zend_arg_info *arg_info;
    /* END of common elements */

    zend_uint *refcount;
    zend_op *opcodes;
    zend_uint last;
    zend_compiled_variable *vars;
    int last_var;
    zend_uint T;
    zend_uint nested_calls;
    zend_uint used_stack;
    zend_brk_cont_element *brk_cont_array;
    int last_brk_cont;
    zend_try_catch_element *try_catch_array;
    int last_try_catch;
    zend_bool has_finally_block;
    HashTable *static_variables;
    zend_uint this_var;
    const char *filename;
    zend_uint line_start;
    zend_uint line_end;
    const char *doc_comment;
    zend_uint doc_comment_len;
    zend_uint early_binding;
    zend_literal *literals;
    int last_literal;
    void **run_time_cache;
    int  last_cache_slot;
    void *reserved[ZEND_MAX_RESERVED_RESOURCES];
};</code></pre>
<p>As you can see, this is much more things that just a simple array containing OPCodes. This array containing our OPCodes is effectively stored into the zend_op_array structure : at the <em>opcodes</em> index, here :</p>
<pre><code>struct _zend_op_array {
    /* ... */
    zend_op *opcodes; /* Here is the array of OPCodes */
    /* ... */
}</code></pre>
<p>Remember that when the engine compiles a PHP script, the compiler returns an OPArray like this one, this is its only job.</p>
<p>So, an "OPArray" is not just a classic C array of zend_op (OPCodes), it contains in reality some different statistic informations as well as everything that will help every OPCode to run in the most efficient possible maner : <strong>the executor must be as fast as possible, for the PHP script to take as less time as possible to execute</strong>.</p>
<p>Let's detail some of those OPArray informations (the most important ones) :</p>
<ul><li>The current script filename, the line it starts and ends into the PHP script that's been compiled to this OPArray</li>
<li>Informations about documentation comments : the "/**" in PHP</li>
<li>A refcount, as the OPArray itself may be shared elsewhere</li>
<li>A list of compiled variables. Compiled variables are every PHP variable used ($something)</li>
<li>A list of temporary variables. Temp vars are used to hold temporary results not explicitely used into the PHP script (not accessed by $something, but real intermediate data)</li>
<li>Informations about the try-catch-finally eventually compiled into this OPArray, the executor will need those to perform the right jumps to the right places</li>
<li>Informations about the break-continue language constructs eventually compiled into this OPArray, the executor will need those to perform the right jumps to the right places</li>
<li>A list of static variables used, if any. Static variables are specially handled, because they need to retain there info until the very last moment of PHP's life (simplified)</li>
<li>The literals used. Literals represent every compile-time known value, like when we use the string "foo", or the integer 42</li>
<li>Runtime cache slots : This is a place where the engine will cache things it knows it will need later.</li>
</ul><p>Ok, that seems to be many things into this solo structure right ?</p>
<p>There is something important I didn't tell you : <strong>OPArray structures are used both to compile PHP scripts and PHP user functions</strong> and also everything passed to the <code>eval()</code> PHP language construct.
When you write a function in PHP, its whole body will itself be turned into its own OPArray, owning itself the compiled variables used in the function body, the try-catch-finally info used in the function body, etc...</p>
<p>The OPArray structure is the result that the Zend compiler gives when it compiles both a PHP script or a PHP user function/method. That's why you can read informations that seem to be related only to a PHP function, but not to a PHP script : the PHP documentor comment blocks for example.</p>
<p>Ok, back to the point, let's see what our OPArray looks like when it comes to compile our simple little example :</p>
<pre><code>$a = 8;
$b = 'foo';
echo $a + $b;</code></pre>
<p><img src="../../../img/zend-vm-executor/oparray-compiled.png" alt="oparray"></p>
<p>As you can see from the picture above, this OPArray now contains everything needed for it to be passed into the executor. Remember that the more we compute now (at compile time, that is : while generating the OPArray), the less the executor will have to compute, and it will be able to concentrate on the "real" job : execute the compiled PHP code. We can see that every literal used has been compiled into the <em>literals</em> array (you may spot the integer 1, which comes from the ZEND_RETURN opcode compilation, this latter returning 1), every compiled variable used has been stored into <em>vars</em>, and the compiled OPCodes are here (at <em>opcodes</em> index)</p>
<p>The other zend_op_array fields are mainly empty (zeroed), because the script we compiled is very tiny : it doesn't make any function call, it doesn't contain any try-catch structure, or any break-continue. It is not the result of the compilation of a PHP function, but a PHP script. The OPArray would have been different in such cases, with many of its other fields filled.</p>
<h3 id="zend-vm-operand-types">Zend VM operand types<a href="#zend-vm-operand-types" class="anchor">#</a></h3>
<p>This is the next concept to understand before analyzing in detail the different OPCode handlers.</p>
<p>We know every OPCode handler can use up to two operands : op1 and op2. Each operand represents an OPCode "parameter". For example, the ZEND_ASSIGN OPCode takes as first parameter the PHP variable in which you want to store a value, and as second operand the value you want to assign to the PHP variable. Its result is not used.</p>
<p>The two operands may be of different types, depending what they represent and how they will be used :</p>
<ul><li>IS_CV      : Compiled Variable : this operand type represents a PHP variable : $something</li>
<li>IS_VAR     : Internal VM usage variable that can be reused through other OPCodes, very similar to a $php_variable, but for internal VM usage only</li>
<li>IS_TMP_VAR : Internal VM usage variable that can not be reused through other OPCodes</li>
<li>IS_CONST   : Represents a constant value, frozen, immutable, read-only</li>
<li>IS_UNUSED  : There is no value : the operand holds nothing of interest, ignore it and don't try to read/fetch it</li>
</ul><p>This type specification is important as <strong>it plays a big role in performance and memory management of the overall executor</strong>.
When an OPCode handler wants to fetch (read) the information stored into one of its operand, it won't run the same code to fetch this info : it will run some specialized fetch code depending on the operand type.</p>
<p>Why ? For example, when an OPCode handler wants to fetch an operand (op1 or op2) of type IS_CV, representing a true PHP $variable, it will at the very first time lookup into the symbol table, storing every possible declared variable. Once the lookup is finished, assuming this one succeeds, as it is a Compiled Variable, it is very very likely that one of the next OPCode to be run in the same OPArray will ask as well to fetch this piece of information. So the first fetch caches the pointer result into the OPArray so that any further fetch of this variable value will be much more quick than the very first one.</p>
<p>This was an explanation for IS_CV, but the same applies for every specialized type : we can optimize every access to every OPCode handler operands if we know information about their type (is it shared ? does it need to be freed ? Is it likely to be reused in few time ? etc...).</p>
<p>Now I'm going to detail when the PHP compiler will use each type, for a very simple addition case :</p>
<pre><code>$a + $b; // IS_CV + IS_CV
1 + $a;  // IS_CONST + IS_CV
foo() + 3 // IS_VAR + IS_CONST
!$a + 3;  // IS_TMP + IS_CONST (2 opcodes involved here, but only one showed)</code></pre>
<h3 id="opcode-specialized-handlers">OPCode specialized handlers<a href="#opcode-specialized-handlers" class="anchor">#</a></h3>
<p>Now we know that each OPCode handler - accepting up to 2 operands (params) - may fetch those operands value in many different ways depending on their type.
If each OPCode handler would have to make a switch() on its two operands, to run a special fetch code depending on their type, we would highly drop performance, because the CPU would have to branch off routines at each OPCode handler run that could not be optimized, because of the highly changing-dynamic nature of them.</p>
<p>Something like this, will just not work in term of performance (pseudo code simplified) :</p>
<pre><code>int ZEND_ADD(zend_op *op1, zend_op *op2)
{
    void *op1_value;
    void *op2_value;

    switch (op1->type) {
        case IS_CV:
            op1_value = read_op_as_a_cv(op1);
        break;
        case IS_VAR:
            op1_value = read_op_as_a_var(op1);
        break;
        case IS_CONST:
            op1_value = read_op_as_a_const(op1);
        break;
        case IS_TMP_VAR:
            op1_value = read_op_as_a_tmp(op1);
        break;
        case IS_UNUSED:
            op1_value = NULL;
        break;
    }
    /* ... same thing to do for op2 .../

    /* do something with op1_value and op2_value (perform a math addition ?) */
}</code></pre>
<p>Remember, we are designing an OPCode handler, <strong>which could be called thousands of time in a PHP script</strong>. If for each call, we must analyze the
op1 and op2 type, just to run a different fetch/read code, that would not be very nice in term of performance (not dramatic, but still).</p>
<p>A pretty nice solution instead have been developped.</p>
<p>Remember the ZEND_ADD OPCode definition from the source code ? :</p>
<pre><code>ZEND_VM_HANDLER(1, ZEND_ADD, CONST|TMP|VAR|CV, CONST|TMP|VAR|CV)
{
    USE_OPLINE
    zend_free_op free_op1, free_op2;

    SAVE_OPLINE();
    fast_add_function(&EX_T(opline->result.var).tmp_var,
        GET_OP1_ZVAL_PTR(BP_VAR_R),
        GET_OP2_ZVAL_PTR(BP_VAR_R) TSRMLS_CC);
    FREE_OP1();
    FREE_OP2();
    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>Look at the signature of this strange function that is not even some C valid syntax (and thus cant be compiled as-is by a C compiler).</p>
<pre><code>ZEND_VM_HANDLER(1, ZEND_ADD, CONST|TMP|VAR|CV, CONST|TMP|VAR|CV)</code></pre>
<p>This tells that the OPCode handler ZEND_ADD, may accept an op1 of type CONST or TMP or VAR or CV. Same for op2.</p>
<p>Now, here is the magical stuff : the file this code is written in, <a href="http://lxr.php.net/xref/PHP_5_6/Zend/zend_vm_def.h">zend_vm_def.h</a> , is just a template, that is passed into a processor, which will produce some C valid code (this time) for every handler, <strong>for every combinaison of every operand type</strong>.</p>
<p>Maths ? 5 different types for op1 multiplied by 5 different types for op2 : ZEND_ADD will be declined as 25 different sepcialized handler functions, and those ones will be written into a file that will itself be compiled as part of the PHP source code.</p>
<p>This file is named <a href="http://lxr.php.net/xref/PHP_5_6/Zend/zend_vm_execute.h">zend_vm_execute.h</a>, and be carefull as you may have guessed : <strong>it is horribly huge</strong>.</p>
<p>Maths ? We support 167 OPCodes as of PHP 5.6 , imagine all those 167 OPCode handlers accept the full 5 possible combinaisons for both their op1 and op2 ...
That gives 4175 C functions to store into this file.</p>
<p>In fact, every OPCode handler will not accept the 5 different possible types of operands, and will lead to less specialized declinations.
For example :</p>
<pre><code>ZEND_VM_HANDLER(84, ZEND_FETCH_DIM_W, VAR|CV, CONST|TMP|VAR|UNUSED|CV)</code></pre>
<p>ZEND_FETCH_DIM_W (fetch a composite entity (array/object) dimension for writing) accepts as op1 only 2 kind : IS_VAR or IS_CV.</p>
<p>But <em>zend_vm_execute.h</em> still counts about <em>45.000</em> lines of C code, get prepared when you want to open this file, it may take more time than usual.</p>
<p>So to sum up :</p>
<ul><li><em>zend_vm_def.h</em> is not valid C file. It describes every OPCode handler flavour (using a custom syntax not far from C), depending on both their op1 and op2 possible types, with a maximum of 5 different type for each operand</li>
<li><em>zend_vm_def.h</em> is passed to a <a href="http://lxr.php.net/xref/PHP_5_6/Zend/zend_vm_gen.php">PHP script called zend_vm_gen.php</a>, stored into the PHP source code, and this file will analyze the special syntax of <em>zend_vm_def.h</em>, using many regular expression matching, and will produce at the end, the final <em>zend_vm_execute.h</em> file you need.</li>
<li><em>zend_vm_def.h</em> is then not part of the PHP compilation process (this file is obviously excluded when it comes to compile PHP)</li>
<li><em>zend_vm_execute.h</em> is the result of the parsing of <em>zend_vm_def.h</em>, and holds valid C syntax, it represents the middle heart of the PHP VM executor : every OPCode handler specialization function is stored into it, this file is absolutely critical.</li>
<li>When you compile PHP from sources, we provide a default <em>zend_vm_execute.h</em>, but if you want to hack, and for example add a new OPCode or modify an existing OPCode behavior, you'll have to hack <em>zend_vm_def.h</em>, and regenerate <em>zend_vm_execute.h</em> from it.</li>
</ul><blockquote>
<p>The funny fact : PHP Virtual Machine Executor is generated using the PHP language itself, aha !</p>
</blockquote>
<p>Here is an example :</p>
<p>We define in <em>zend_vm_def.h</em> the ZEND_ADD OPCode, as this :</p>
<pre><code>ZEND_VM_HANDLER(1, ZEND_ADD, CONST|TMP|VAR|CV, CONST|TMP|VAR|CV)</code></pre>
<p>Passing <em>zend_vm_def.h</em> to the <em>zend_vm_gen.php</em> script, will result into a new <em>zend_vm_execute.h</em> file, which will contain the specialized handlers for this OPCode, and those look like this :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_ADD_SPEC_CONST_CONST_HANDLER(ZEND_OPCODE_HANDLER_ARGS) { /* handler code */ }
static int ZEND_FASTCALL  ZEND_ADD_SPEC_CONST_TMP_HANDLER(ZEND_OPCODE_HANDLER_ARGS) { /* handler code */ }
static int ZEND_FASTCALL  ZEND_ADD_SPEC_CONST_VAR_HANDLER(ZEND_OPCODE_HANDLER_ARGS) { /* handler code */ }
static int ZEND_FASTCALL  ZEND_ADD_SPEC_CONST_CV_HANDLER(ZEND_OPCODE_HANDLER_ARGS) { /* handler code */ }
static int ZEND_FASTCALL  ZEND_ADD_SPEC_TMP_CONST_HANDLER(ZEND_OPCODE_HANDLER_ARGS) { /* handler code */ }
static int ZEND_FASTCALL  ZEND_ADD_SPEC_TMP_TMP_HANDLER(ZEND_OPCODE_HANDLER_ARGS)  { /* handler code */ }

/* etc... I won't write here the 25 declinations ! */</code></pre>
<p>So, the specialized handler will be run depending on the op1 and op2 types, for example :</p>
<pre><code>$a + 2;  /* IS_CV + IS_CONST */

/* ZEND_ADD_SPEC_CV_CONST_HANDLER() will be run in the VM */</code></pre>
<p>The function name is built dynamically, following this simple model : <em>ZEND_{OPCODE-NAME}_SPEC_{OP1-TYPE}_{OP2-TYPE}_HANDLER()</em></p>
<p>You may wonder then : but if we must choose which specialized function to run for each op1 and op2 types, won't we end up having a huge switch to make such a choice, cancelling the need to have specialized handlers ?</p>
<p>The answer is no : <em>this is resolved at compile time</em> , and as you use an OPCode cache, you won't suffer from the compile time at all.</p>
<p>When the PHP compiler generates OPCodes from the source PHP code, it knows for each of them the type of their respective op1 and op2 (as it is a compiler, it is its role). So the PHP compiler generates an OPArray directly storing the right specialized handler : the execution step has absolutely no choice, no switch() to do : it will be fast, using directly the right specialized handler for each OPCode to run.
If now you change your source code, well, you have to recompile it to generate a new OPArray, this is what OPCode cache solution do.</p>
<p>Ok now, why not see the difference between those handlers ?</p>
<p>Not surprisingly, the only thing that changes in each declination of a same handler, is the way op1 and op2 are fetched. Look :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_ADD_SPEC_CONST_CONST_HANDLER(ZEND_OPCODE_HANDLER_ARGS) /* CONST_CONST */
{
    USE_OPLINE
    SAVE_OPLINE();
    fast_add_function(&EX_T(opline->result.var).tmp_var,
        opline->op1.zv, /* fetch op1 value */
        opline->op2.zv TSRMLS_CC); /* fetch op2 value */
    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}

static int ZEND_FASTCALL  ZEND_ADD_SPEC_CV_CV_HANDLER(ZEND_OPCODE_HANDLER_ARGS) /* CV_CV */
{
    USE_OPLINE
    SAVE_OPLINE();
    fast_add_function(&EX_T(opline->result.var).tmp_var,
        _get_zval_ptr_cv_BP_VAR_R(execute_data, opline->op1.var TSRMLS_CC), /* fetch op1 value */
        _get_zval_ptr_cv_BP_VAR_R(execute_data, opline->op2.var TSRMLS_CC) TSRMLS_CC); /* fetch op2 value */
    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>In the CONST_CONST handler (both op1 and op2 are CONST vars), we read them directly using the operand zval value. There is nothing to do such as incrementing or decrementing a counter, freeing the operand value : the value is immutable : simply read it, and we're done.</p>
<p>However, for the CV_CV handler (both op1 and op2 are CV, compiled variables), we must access the value, increment its refcount (because we're gonna use it now) and cache the access for an eventual further read : <code>_get_zval_ptr_cv_BP_VAR_R()</code> does that.
And as it is a "R" fetch : for reading, if the variable doesn't exist, this function will generate a notice : undefined variable. Things would have been different for a "W" access, where if the variable doesn't exist, well, we just need to create it without any warning or notice, isn't that how PHP works ? ;-)</p>
<h3 id="additionnal-informations">Additionnal informations<a href="#additionnal-informations" class="anchor">#</a></h3>
<h4 id="compiler-optimizations">Compiler optimizations<a href="#compiler-optimizations" class="anchor">#</a></h4>
<p>The <em>zend_vm_gen.php</em> may sometimes generate some strange code in <em>zend_vm_execute.h</em>. For example :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_INIT_ARRAY_SPEC_CONST_CONST_HANDLER(ZEND_OPCODE_HANDLER_ARGS)
{
    USE_OPLINE

    array_init(&EX_T(opline->result.var).tmp_var);
    if (IS_CONST == IS_UNUSED) {
        ZEND_VM_NEXT_OPCODE();
#if 0 || IS_CONST != IS_UNUSED
    } else {
        return ZEND_ADD_ARRAY_ELEMENT_SPEC_CONST_CONST_HANDLER(ZEND_OPCODE_HANDLER_ARGS_PASSTHRU);
#endif
    }
}</code></pre>
<p>You may read silly statements : <em>if (IS_CONST == IS_UNUSED)</em> for example, or again : <em>#if 0 || IS_CONST != IS_UNUSED</em></p>
<p>This is because the original zend_vm_def.h template code that's been passed for generation of this speciliazed handler, have been written
in such a way, have a look at it :</p>
<pre><code>ZEND_VM_HANDLER(71, ZEND_INIT_ARRAY, CONST|TMP|VAR|UNUSED|CV, CONST|TMP|VAR|UNUSED|CV)
{
    USE_OPLINE

    array_init(&EX_T(opline->result.var).tmp_var);
    if (OP1_TYPE == IS_UNUSED) {
        ZEND_VM_NEXT_OPCODE();
#if !defined(ZEND_VM_SPEC) || OP1_TYPE != IS_UNUSED
    } else {
        ZEND_VM_DISPATCH_TO_HANDLER(ZEND_ADD_ARRAY_ELEMENT);
#endif
    }
}</code></pre>
<p>When the generator generated code for each specializer, it replaced the <em>OP1_TYPE</em> statement in the code above by each type, generating strange statements, such as <em>if (IS_CONST == IS_UNUSED)</em></p>
<p>But remember, the generated code in <em>zend_vm_execute.h</em> is compiled by a C compiler, and this one will optimize those useless statement by just making them dissapear, resulting in each OPCode handler being highly optimized when turned to machine code by the C compiler , like this :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_INIT_ARRAY_SPEC_CONST_CONST_HANDLER(ZEND_OPCODE_HANDLER_ARGS)
{
    array_init(&EX_T(opline->result.var).tmp_var);
}</code></pre>
<h4 id="zend-vm-executor-generation-customization">Zend VM executor generation customization<a href="#zend-vm-executor-generation-customization" class="anchor">#</a></h4>
<p>The script that generates the VM executor is <em>zend_vm_gen.php</em>, and this one accepts parameters, that means that you can change your PHP current executor code by generating another one. For example, when you pass <em>--without-specializer</em> to this script, it generates a VM executor with no specializers. That means that each OPCode handler will have only one declination (whatever its op1 and op2 types are), and this one will effectively do a big switch() on each operand op1/op2 type when trying to fetch its value :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_ADD_HANDLER(ZEND_OPCODE_HANDLER_ARGS)
{
    USE_OPLINE
    zend_free_op free_op1, free_op2;

    SAVE_OPLINE();
    fast_add_function(&EX_T(opline->result.var).tmp_var,
        get_zval_ptr(opline->op1_type, &opline->op1, execute_data, &free_op1, BP_VAR_R),
        get_zval_ptr(opline->op2_type, &opline->op2, execute_data, &free_op2, BP_VAR_R) TSRMLS_CC);
    FREE_OP(free_op1);
    FREE_OP(free_op2);
    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}

static inline zval *_get_zval_ptr(int op_type, const znode_op *node, const zend_execute_data *execute_data, zend_free_op *should_free, int type TSRMLS_DC)
{
/*  should_free->is_var = 0; */
    switch (op_type) {
        case IS_CONST:
            should_free->var = 0;
            return node->zv;
            break;
        case IS_TMP_VAR:
            should_free->var = TMP_FREE(&EX_T(node->var).tmp_var);
            return &EX_T(node->var).tmp_var;
            break;
        case IS_VAR:
            return _get_zval_ptr_var(node->var, execute_data, should_free TSRMLS_CC);
            break;
        case IS_UNUSED:
            should_free->var = 0;
            return NULL;
            break;
        case IS_CV:
            should_free->var = 0;
            return _get_zval_ptr_cv(node->var, type TSRMLS_CC);
            break;
        EMPTY_SWITCH_DEFAULT_CASE()
    }
    return NULL;
}</code></pre>
<p>Why do that ? For debugging and understanding purposes. The <em>zend_vm_execute.h</em> file resulting, with no specializer at all, is 10 times smaller in number of lines that the one with each specializer.
However, when you run some PHP code against this VM executor, it shows something like 10 to 15% performance drop compared to the one with specializers.</p>
<blockquote>
<p>Zend VM executor specializers have been added to PHP 5.1 (2005)</p>
</blockquote>
<p>Another switch is <em>--with-vm-kind=CALL|SWITCH|GOTO</em>.  CALL being the default value.</p>
<p>Remember the main executor while(1) loop we talked about when we introduced the VM ? I refresh your mind rewriting it here (simplified) :</p>
<pre><code>ZEND_API void execute_ex(zend_execute_data *execute_data TSRMLS_DC)
{
    /* ... simplified ... */
    while (1) {
        int ret;

        if ((ret = execute_data->opline->handler(execute_data TSRMLS_CC)) > 0) {
            switch (ret) {
                case 1:
                    EG(in_execution) = original_in_execution;
                    return;
                case 2:
                    goto zend_vm_enter;
                    break;
                case 3:
                    execute_data = EG(current_execute_data);
                    break;
                default:
                    break;
            }
        }
    }
    zend_error_noreturn(E_ERROR, "Arrived at end of main loop which shouldn't happen");
}</code></pre>
<p>This is the CALL strategy, it increments a pointer in execute_data->opline at the end of each OPCode handler, and goes back to the next iteration of the while(1). This is how we go from one OPcode to the next one, until the ZEND_RETURN one.</p>
<p>There exists other strategies to achieve the same goal. Why not use a C goto ? Or a giant C switch ?</p>
<p>This is <em>--with-vm-kind</em> role : it generates 3 different executor control flow strategies. Let's see the C goto one :</p>
<pre><code>ZEND_API void execute_ex(zend_execute_data *execute_data TSRMLS_DC)
{
    /* ... simplified ... */

    while (1) {
        goto *(void**)(execute_data->opline->handler);
    }
}</code></pre>
<p>You see that the while(1) is still here, but in the while this time, we goto a function pointer. So for one OPCode handler to give hand to the next one, we will have this time to increment a pointer and use a goto as well :</p>
<pre><code>#define ZEND_VM_INC_OPCODE() execute_data->opline++
#define ZEND_VM_CONTINUE() goto *(void**)(OPLINE->handler) /* here is the goto */
#define ZEND_VM_NEXT_OPCODE() \
CHECK_SYMBOL_TABLES() \
ZEND_VM_INC_OPCODE(); \
ZEND_VM_CONTINUE()</code></pre>
<p>CALL is the default strategy for the Zend Executor dispatch loop, because its the one that gives the more performance on an average of target platforms and C compilers. However, depending on your platform and C compiler specific feature, you may find better performance for other implementations, like the goto one, which can be written using specific assembly instructions on some CPU families.</p>
<h4 id="executor-jumps">Executor jumps<a href="#executor-jumps" class="anchor">#</a></h4>
<p>What happens when you use an <em>if</em> statement in PHP ? It is easy : instead of using ZEND_VM_NEXT_OPCODE() and linearly running each OPCode one after one - which prevents us from taking control over the executor path, and thus to implement ifs or loops - we just <strong>jump</strong> to a specific OPCode.</p>
<pre><code>$a = 8;
if ($a == 9) {
    echo "foo";
} else {
    echo "bar";
}

compiled vars:  !0 = $a
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   ASSIGN                                                   !0, 8
   5     1      IS_EQUAL                                         ~1      !0, 9
         2    > JMPZ                                                     ~1, ->5
   6     3  >   ECHO                                                     'foo'
   7     4    > JMP                                                      ->6
   8     5  >   ECHO                                                     'bar'
  10     6  > > RETURN                                                   1</code></pre>
<p>Notice those ZEND_JMP and ZEND_JMPZ OPCodes ? They just change the control flow :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_JMP_SPEC_HANDLER(ZEND_OPCODE_HANDLER_ARGS)
{
    USE_OPLINE
    ZEND_VM_SET_OPCODE(opline->op1.jmp_addr);
    ZEND_VM_CONTINUE();
}

#define ZEND_VM_SET_OPCODE(new_op) \
CHECK_SYMBOL_TABLES() \
execute_data->opline = new_op</code></pre>
<p>ZEND_VM_SET_OPCODE tells the executor main loop not to basically increment the opline to go and run the immediately next OPCode, but instead to jump the opline to the jump address (jmp_addr) stored into operand op1 of the ZEND_JMP OPCode handler.
This jump address value has been calculated at compile time.</p>
<h2 id="performance-tips">Performance tips<a href="#performance-tips" class="anchor">#</a></h2>
<p>I dont really like this, but I will show you how to optimize your code, based on generated OPcodes.</p>
<p>I don't like this because when people read that, they tend to apply the rules foolishly, without even understanding them, and they don't realize that this won't magically boost their 1200SQL-query-per-page app :-p. Let things into their context please.</p>
<p>However, if you run your code into loops, with thousands of iteration, you will see a difference.</p>
<h3 id="echo-a-concatenation">echo a concatenation<a href="#echo-a-concatenation" class="anchor">#</a></h3>
<p>We can read so many codes like this nowadays :</p>
<pre><code>$foo = 'foo';
$bar = 'bar';

echo $foo . $bar;</code></pre>
<p>Here is the resulting OPArray :</p>
<pre><code>compiled vars:  !0 = $foo, !1 = $bar
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   ASSIGN                                                   !0, 'foo'
   4     1      ASSIGN                                                   !1, 'bar'
   6     2      CONCAT                                           ~2      !0, !1
         3      ECHO                                                     ~2
   7     4    > RETURN                                                   1</code></pre>
<p>Interesting enough : the engine will concat (ZEND_CONCAT) both $a and $b value into a temporary variable (~2 in the output above), to finally echo it and trash it away.</p>
<p>That means that the engine will have to both create some space for a string into memory, and perform a complex operation : a concatenation - just to echo that and then free the memory back. That seems a little bit too much for such an operation no ?</p>
<p>Why not turn your code to something much like this ? :</p>
<pre><code>$foo = 'foo';
$bar = 'bar';

echo $foo , $bar;

compiled vars:  !0 = $foo, !1 = $bar
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   ASSIGN                                                   !0, 'foo'
   4     1      ASSIGN                                                   !1, 'bar'
   6     2      ECHO                                                     !0
         3      ECHO                                                     !1
   7     4    > RETURN                                                   1</code></pre>
<p>You see the difference ? Using a comma in echo in perfectly valid, the Zend compiler accepts as many parameters to the "echo" statement as possible (comma separated), and just generates one ZEND_ECHO OPCode for each of them. This is much lighter.</p>
<p>There is both no need to create a temporary buffer into memory, nor to perform a concatenation.</p>
<p>Here is a the ZEND_CONCAT OPCode detail :</p>
<pre><code>ZEND_VM_HANDLER(8, ZEND_CONCAT, CONST|TMP|VAR|CV, CONST|TMP|VAR|CV)
{
    USE_OPLINE
    zend_free_op free_op1, free_op2;

    SAVE_OPLINE();
    concat_function(&EX_T(opline->result.var).tmp_var,
        GET_OP1_ZVAL_PTR(BP_VAR_R),
        GET_OP2_ZVAL_PTR(BP_VAR_R) TSRMLS_CC);
    FREE_OP1();
    FREE_OP2();
    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>And here <a href="http://lxr.php.net/xref/PHP_5_6/Zend/zend_operators.c#1422">is the code for concat_function()</a>. It must :</p>
<ul><li>Check operand one for it to be a string, if not, convert it to string (heavy process)</li>
<li>Check operand two for it to be a string, if not, convert it to string (heavy process)</li>
<li>Allocate a buffer, size it, copy the concat result inside and return it</li>
</ul><p>Here is the code that effectively concats (from <code>concat_function()</code>) :</p>
<pre><code>int length = Z_STRLEN_P(op1) + Z_STRLEN_P(op2);
char *buf = (char *) emalloc(length + 1);

memcpy(buf, Z_STRVAL_P(op1), Z_STRLEN_P(op1));
memcpy(buf + Z_STRLEN_P(op1), Z_STRVAL_P(op2), Z_STRLEN_P(op2));
buf[length] = 0;
ZVAL_STRINGL(result, buf, length, 0);</code></pre>
<p>There is nothing easier to write.</p>
<p>If we provided both two strings, there still needs to access the main memory (code above). This leads to many CPU instructions, and usually (unfortunately), those string data won't be in CPU caches (L1/L2/L3), so the CPU will have to fetch those data from the main memory line. That will cost some nano-seconds (usually dozens), this is pretty light yes, but if the "echo" code concatenating were to be written into a while loop with thousands of iterations, here again, nano-seconds will turn to micro-seconds : just for that single echo line. I personnaly find this silly and would prefer using my CPU time for other things ;-)</p>
<h3 id="define-and-const">define() and const<a href="#define-and-const" class="anchor">#</a></h3>
<p>PHP 5.3 introduced the <code>const</code> keyword, and it has an important impact on execution time.</p>
<p>Simply said :</p>
<ul><li><code>define()</code> is a function call that will suffer from the overhead of a function call into the executor</li>
<li><code>const</code> is a keyword that won't generate a function call OPCode, thus is lighter than <code>define()</code></li>
</ul><p>Now you got it : never use <code>define()</code> to define compile-time known constants (basically, every constant you'll happen to manipulate).</p>
<pre><code>define('FOO', 'foo');
echo FOO;

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   SEND_VAL                                                 'FOO'
         1      SEND_VAL                                                 'foo'
         2      DO_FCALL                                      2          'define'
   5     3      FETCH_CONSTANT                                   ~1      'FOO'
         4      ECHO                                                     ~1
   6     5    > RETURN                                                   1</code></pre>
<p>That is awfull in term of performance.</p>
<p>I didnt detail how function calls work into the executor in this blog post, because this is terribly complex, and would require the writting of hundreds of additional blog lines.
However, <a href="http://jpauli.github.io/2015/01/22/on-php-funct">I already blogged on the heaviness of function calls into the engine</a>.</p>
<p><code>define()</code> will lead to function call, that will register the constant into the engine, and then the ZEND_FETCH_CONSTANT OPCode will simply read the value.</p>
<p>Look at the following involving <code>const</code> this time :</p>
<pre><code>const FOO = 'foo';
echo FOO;

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   DECLARE_CONST                                            'FOO', 'foo'
   5     1      FETCH_CONSTANT                                   ~0      'FOO'
         2      ECHO                                                     ~0
   6     3    > RETURN                                                   1</code></pre>
<p>All the function call (for <code>define()</code>) OPCodes have disappeared, and have been replaced by a pretty lighter DECLARE_CONST</p>
<p>There are however little glitches - which are logical, but still - about <code>const</code> and <code>define()</code> :</p>
<ul><li><code>const</code> can't declare conditionnal constants</li>
<li><code>const</code> (DECLARE_CONST) can't obviously use other operand types than IS_CONST</li>
</ul><p>That means that you can't do tings like that with <code>const</code>, but you may do with <code>define()</code> :</p>
<pre><code>if (foo()) {
    const FOO = 'foo'; /* A compiler rule disallows that */
}</code></pre>
<p>Nor you may write :</p>
<pre><code>$a = 'FOO';

const $a = 'foo';</code></pre>
<p>If the <code>const</code> structure is more optimized in term of performance, it has some drawbacks about the dynamism of your code.</p>
<h3 id="dynamic-function-calls">dynamic function calls<a href="#dynamic-function-calls" class="anchor">#</a></h3>
<p>No, I won't detail function calls into the engine executor, because they are very very complex to understand. But here, I will show you, without much details, things you should prevent in term of performance.</p>
<p>Prevent calling a function which name is dynamic ( != IS_CONST). When you make a function call, the OPCodes generated by the compiler are very different weither at the time you make the call, the compiler can know the function name, and know that your function exists (or not).</p>
<p>Have a look :</p>
<pre><code>function foo() { }
foo();

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   NOP                                                      
   5     1      DO_FCALL                                      0          'foo'
   6     2    > RETURN                                                   1</code></pre>
<p>NOP stands for "No Operation". The compiler generated it because of its long history :-). NOP is really 0 second to run, ignore it (OPCache optimizer trashes all of them).</p>
<p>There is here just a DO_FCALL OPCode, that will call to run the function foo()'s OPCode. All right, nothing more to add.</p>
<p>Let's now see a dynamic function call :</p>
<pre><code>function foo() { }
$a = 'foo';
$a();

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   NOP                                                      
   6     1      ASSIGN                                                   !0, 'foo'
   7     2      INIT_FCALL_BY_NAME                                       !0
         3      DO_FCALL_BY_NAME                              0          
   9     4    > RETURN                                                   1</code></pre>
<p>Ouch. You see that there are now 2 OPCodes about the function call, instead of one, that starts smelling bad for overall performances (but let's see what those OPCode handlers do before concluding).
What you should know, is that the extra INIT_FCALL_BY_NAME is here because the compiler, at its compile time, did not know what function you want it to call, because this time it is into a variable (dynamic function call).</p>
<blockquote>
<p>Remember that the compiler cannot interpret variables, the compiler doesn't know yet what is stored into your variables. Your PHP variables are compiled as CV, they are dynamic by definition, and may retain any kind of information (they could why not hold NULL or even be "undefined variables", who knows at compile time ?). So in this case, <strong>the compiler has no other choice than delaying at runtime the function preparation code and the tables lookup</strong>, which is bad for performance, because something that could be done at compile time, is now delayed at runtime.</p>
</blockquote>
<p>Look at this piece of code from INIT_FCALL_BY_NAME_SPEC_CV_HANDLER (our use case), which I recall, is run because we used a dynamic function call, instead of a compile-time-known function call :</p>
<pre><code>static int ZEND_FASTCALL  ZEND_INIT_FCALL_BY_NAME_SPEC_CV_HANDLER(ZEND_OPCODE_HANDLER_ARGS)
{

    USE_OPLINE
    zval *function_name;
    call_slot *call = EX(call_slots) + opline->result.num;

    char *function_name_strval, *lcname;
    int function_name_strlen;
    function_name = _get_zval_ptr_cv_BP_VAR_R(execute_data, opline->op2.var TSRMLS_CC);

    if (EXPECTED(Z_TYPE_P(function_name) == IS_STRING)) { /* Are we a string ? */
        function_name_strval = Z_STRVAL_P(function_name);
        function_name_strlen = Z_STRLEN_P(function_name);
        if (function_name_strval[0] == '\\') {
            function_name_strlen -= 1;
            lcname = zend_str_tolower_dup(function_name_strval + 1, function_name_strlen);
        } else {
            lcname = zend_str_tolower_dup(function_name_strval, function_name_strlen);
        }
        if (UNEXPECTED(zend_hash_find(EG(function_table), lcname, function_name_strlen+1, (void **) &call->fbc) == FAILURE)) {
            zend_error_noreturn(E_ERROR, "Call to undefined function %s()", function_name_strval);
        }
        efree(lcname);

        call->object = NULL;
        call->called_scope = NULL;
        call->num_additional_args = 0;
        call->is_ctor_call = 0;
        EX(call) = call;

        CHECK_EXCEPTION();
        ZEND_VM_NEXT_OPCODE();
    } else if (IS_CV != IS_CONST && IS_CV != IS_TMP_VAR &&
        EXPECTED(Z_TYPE_P(function_name) == IS_OBJECT) &&    /* Are we an object (closure) ? */

        /* code simplified and not showed here */

    } else if (IS_CV != IS_CONST &&
            EXPECTED(Z_TYPE_P(function_name) == IS_ARRAY) &&
            zend_hash_num_elements(Z_ARRVAL_P(function_name)) == 2) {  /* Are we an array ? */

    /* code simplified and not showed here */

    }
        if (UNEXPECTED(call->fbc == NULL)) {
            zend_error_noreturn(E_ERROR, "Call to undefined method %s::%s()", ce->name, Z_STRVAL_PP(method));
        }

        call->num_additional_args = 0;
        call->is_ctor_call = 0;
        EX(call) = call;

        CHECK_EXCEPTION();
        ZEND_VM_NEXT_OPCODE();
    } else {
        if (UNEXPECTED(EG(exception) != NULL)) {
            HANDLE_EXCEPTION();
        }
        zend_error_noreturn(E_ERROR, "Function name must be a string");
        ZEND_VM_NEXT_OPCODE(); /* Never reached */
    }

}</code></pre>
<p>And all this analysis code <strong>cannot be cached</strong>, because at the next time you run it (assuming that), well, your <code>$variable_that_is_a_function_name</code> could have change its type, could have disappeared, etc.</p>
<p>More generally speaking, what you have to remember is just trully common sense : <strong>the more you use dynamic features of the PHP language, the more work the executor will have to perform, and the more the overall performances of the language will drop</strong>.</p>
<p>The exact same thing happens for methods, with just one little difference, which is so important for performances : the class may not exist at runtime, and may trigger the autoload, which is a performance chasm in itself. Usage of an OPCode cache really lowers this negative impact.</p>
<h3 id="delayed-class-binding">Delayed class binding<a href="#delayed-class-binding" class="anchor">#</a></h3>
<p>This is the icing on the cake part : classes and inheritance.</p>
<p>Here again, simple words : When class A extends B, you'd better for performances have delcared B before, if not : that will be naughty at runtime.</p>
<p>Let's demonstrates :</p>
<pre><code>class Bar { }
class Foo extends Bar { }

compiled vars:  none
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   NOP                                                      
   5     1      NOP                                                      
         2      NOP                                                      
   6     3    > RETURN                                                   1</code></pre>
<p>No, there is no error : If you do things the right way, in the right order, <strong>the compiler can take care of all the heavy stuff about class declaration</strong>. You see what the executor has to run here ? NOP, and NOP, and NOP again : nothing (OPCache optimizer will even discard those super light NOPs).</p>
<p>The compiler has done the job (and <strong>declaring a class is really a heavy task for performances</strong>), and once again, because you use an OPCode cache solution, you don't suffer from the compiler time at all.</p>
<p>So, declaring classes in PHP is very light in term of execution, until you move the order of declarations :</p>
<pre><code>class Foo extends Bar { }
class Bar { }

compiled vars:  none
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   FETCH_CLASS                                   4  :0      'Bar'
         1      DECLARE_INHERITED_CLASS                                  '%00foo%2Ftmp%2Ffoo.php0x7f198b0c401d', 'foo'
   5     2      NOP                                                      
   6     3    > RETURN                                                   1</code></pre>
<p>We declared Foo as extending Bar, but at the time the declaration is read by the compiler, this one doesn't know anything about Bar. So how could it prepare the Foo class into memory for it to be fully ready for the executor to run ? It just can't : that is exactly what a compiler is, and in less dynamic languages, this code would have lead to a "Parse error : class not found" error, end of story. But PHP is more dynamic than this.</p>
<p>The compiler here once again has to delay the class declaration at runtime (something PHP allows), and believe me that class declaration is heavy for the engine, what is heavy is resolving the inheritence tree and add all the functions of all the parents to the actual class, something usually taking some compiler time, but not in our case : it will eat runtime, over, and over , and over again, for a class that will likely never change. What a silly code writing in a performance point of view.</p>
<p>Here, like always, we suffer from the very dynamic nature of PHP, allowing to use an object of a class that it has even not compiled yet ! (autoloaded ?). This is flexible, this is easy to program, but your machine will pay the price of your laziness, as often. Until you use and OPCode cache, particularly OPCache, which optimizes very nicely such cases (and I still have some PR to improve even more this specific case).</p>
<blockquote>
<p>Note that this process also happens for both traits binding, and interface implementations, as internally, classes/traits/interfaces are exactly the same structure and share many processes.</p>
</blockquote>
<p>Still not convinced ?</p>
<pre><code>class Foo { }

compiled vars:  none
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   NOP                                                      
   4     1    > RETURN                                                   1</code></pre>
<p>Nothing to do at runtime, like we already did demonstrate. Let's add a little bit of dynamism into that :</p>
<pre><code>if ($a) {
    class Foo  { }
}

compiled vars:  !0 = $a
line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  > > JMPZ                                                     !0, ->3
   4     1  >   DECLARE_CLASS                                    $0      '%00foo%2Ftmp%2Ffoo.php0x7fcef3f9701d', 'foo'
   5     2    > JMP                                                      ->3
   6     3  > > RETURN                                                   1</code></pre>
<p>You pay the price of your dynamism : the class has now to be fully declared and resolved at runtime (ZEND_DECLARE_CLASS OPCode), everytime you run the code. Naughty you !</p>
<h2 id="conclusions">Conclusions<a href="#conclusions" class="anchor">#</a></h2>
<p>This article demonstrated some deep hidden parts of the Zend virtual machine : the executor code. This is the part of PHP source code that makes the "real" job : it executes each single task (each OPCode) the PHP script has been translated to. <strong>This is the most performance critical part of PHP's source code, so it has been designed with perf in mind first</strong>.</p>
<p>That's why when you read this code and you are not really used to software virtual machine design or even low level programming, you may sometimes wonder why things have been written in such a way, that seems so complex to you. The only answer is performance. The C programming language is the only one, to my own knowledge, that allows that many thin level of optimizations, as it is directly turned into target machine assembly instructions, and its compilers are nowadays very mature, as most of them are about 40 years old.</p>
<p>Remember that the PHP virtual machine, as well as its whole source code in fact, <strong>has been worked, hacked, debugged and optimized for nearly 20 years now</strong>, so believe me, if things are done the way they are, it's not random decisions at all.
It even happens we dive one layer lower, and read the assembly code that's been generated by different C compilers when compiling the executor, and then hack the C code to make the compiler generate even more optimized code (the C compiler can usually be told many tweaks). Also, some critical parts of the Zend virtual machine are written directly in assembly (uncommon, but still happens).</p>
<p>Finally, you can play with that yourself : you must design a zend_extension. A PHP extension can also do many things, but when it comes to play with the executor and the OPArrays, it is better to do that in a zend_extension, because those have much more power than classical PHP extensions.
For exemple OPCache is a zend_extension, because it plays heavilly with the OPCodes in the OPArray, mainly to both optimize them (finding unreachable statement etc... using what's called compiler passes) and cache them to be able to reuse them at the next request, preventing the so heavy compiler to fire up.</p>
<p><a href="https://blackfire.io/">The Blackfire profiler</a> extension code I work on in my daily job, will soon be able to warn you about such idiot statement in term of performance, and many more I could not show you here ;-)</p>]]></content>
    </entry>
        <entry>
        <title>On PHP function calls (PHP 5)</title>
                <id>http://jpauli.github.io//2015/01/22/on-php-function-calls.html</id>
                <updated>2015-01-22T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2015/01/22/on-php-function-calls.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introducting-the-facts">Introducting the facts<a href="#introducting-the-facts" class="anchor">#</a></h2>
<p>This blog post is a technical explanation of a PHP optimization found with <a href="https://blackfire.io/">Blackfire profiler</a> into a PHP script.
The related post is located here : <a href="http://blog.blackfire.io/owncloud.html"></a><a href="http://blog.blackfire.io/owncloud.html">http://blog.blackfire.io/owncloud.html</a></p>
<p>Basically, it concludes with :</p>
<pre><code>if (strlen($name) > 49) {
...
}</code></pre>
<p>Beeing about 20% slower than</p>
<pre><code>if (isset($name[49])) {
...
}</code></pre>
<p>Which is perfectly normal.</p>
<p>Hang on. You were going to stop reading here, to go browse your codebase and replace <code>strlen()</code> calls by <code>isset()</code> calls. So that's why I stopped you.
If you read carefully <a href="http://blog.blackfire.io/owncloud.html">the original blog post</a>, this performance result boost of about 20% is obtained because <code>strlen()</code> was used in a loop
of about 60 to 80K iterations (60,000 to 80,000).</p>
<h2 id="why-such-a-result">Why such a result ?<a href="#why-such-a-result" class="anchor">#</a></h2>
<p>It's not the way <code>strlen()</code> computes the length that's in cause. Because the length of every PHP string is always known when <code>strlen()</code> is called. A big part of such lengths are even computed at compile time, when possible.
PHP encapsulates the length of the string into the C structure carrying a PHP string, when it creates such string into memory. So <code>strlen()</code> just reads that little info, and returns it to you as-is.
In fact, <code>strlen()</code> is probably the fastest PHP function that exists. It just does nothing in term of computation. Here is its source code:</p>
<pre><code>ZEND_FUNCTION(strlen)
{
    char *s1;
    int s1_len;

    if (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, "s", &s1, &s1_len) == FAILURE) {
        return;
    }

    RETVAL_LONG(s1_len);
}</code></pre>
<p>Knowing that <code>isset()</code> is not a function, the ~20% perf penalty of <code>strlen()</code> over <code>isset()</code> is mainly brought by the overhead of a function call in the Zend Engine.</p>
<p>There is another thing to say as well : comparing the result of <code>strlen()</code> with something, adds an extra OPCode, whereas using just an <code>isset()</code>, represents one unique OPCode.</p>
<p>Here is the <em>if(strlen())</em> construct disassembled :</p>
<pre><code>line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   SEND_VAR                                                 !0
         1      DO_FCALL                                      1  $0      'strlen'
         2      IS_SMALLER                                       ~1      42, $0
         3    > JMPZ                                                     ~1, ->5
   5     4  > > JMP                                                      ->5
   6     5  > > RETURN                                                   1</code></pre>
<p>And here is the semanticaly equivalent <em>if(isset())</em> structure disassembled :</p>
<pre><code>line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   ISSET_ISEMPTY_DIM_OBJ                       33554432  ~0      !0, 42
         1    > JMPZ                                                  ~0, ->3
   5     2  > > JMP                                                       ->3
   6     3  > > RETURN                                                     1</code></pre>
<p>As you can see, there is no function call involved into the <code>isset()</code> code (<strong>DO_FCALL</strong>), as well as there is no <strong>IS_SMALLER</strong> OPCode (just ignore the RETURN statements).
<code>isset()</code> will directly return a boolean for evaluation, whereas <code>strlen()</code> will return a temporary variable, passed to <strong>IS_SMALLER</strong> OPCode, and only this OPCode result will be evaluated by the <code>if()</code>.
That's two OPCodes for the <code>strlen()</code> code structure and only one for the <code>isset()</code> one, which lets us smell that the <code>isset()</code> structure will also be faster because of this fact. (computing two operations is usually slower that computing just one).</p>
<p>Let's now analyze how function calls work in PHP, and how they are different from <code>isset()</code>.</p>
<h2 id="php-function-calls-in-deep">PHP function calls in deep<a href="#php-function-calls-in-deep" class="anchor">#</a></h2>
<p>Let me warn you : function calls are complex in PHP. If you want to continue reading this part, you'd better fasten your seat belt ;-)
In PHP's design and source code, the most complex execution part to analyze is all that's related to function calls.
I will try to sumarize things here, so that you get enough info to understand, without all the full details related to function calls. You still can fetch them by analyzing the source code.</p>
<blockquote>
<p>Functions calls is a strongly complex subject into the engine.</p>
</blockquote>
<p>Here, we will talk about <em>runtime</em> of a function call. You should know that the <em>compile time</em> PHP function related operations are also heavy to run for the machine (I mean, really heavy), but as you use an OPCode cache, you don't suffer from anything related to compile time (that is transformation of the PHP source code into Zend VM instructions).
So here, we assume the script is compiled, and we'll analyze what happens at <em>runtime</em> only.</p>
<p>Let's just dump the OPCode of an internal function call (<code>strlen()</code>, here) :</p>
<pre><code>strlen($a);

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
3     0  >   SEND_VAR                                                 !0
      1      DO_FCALL                                      1          'strlen'</code></pre>
<p>To understand function calls, one should know those points :</p>
<ul><li>Function calls and method calls are exactly the same</li>
<li>User functions calls and internal functions calls are differently handled</li>
<li>Function calls requires the creation/destruction of a VM stack frame (a memory space where to store variables passed to the function).</li>
</ul><p>That's why I talked about an "internal" function call in my last statement, because I show an example of a call to an internal PHP function, that is a PHP function that's designed in C, here : PHP's <code>strlen()</code>. If we were dumping the OPCode of a "user" PHP function - that is a function that a programmer wrote using the PHP language - OPCode could have been different, but they could have been exactly the same as well.</p>
<p><em>This is because PHP doesn't generate the same OPCode weither at compile time it knows the function, or not.</em>
Obviously, internal PHP functions are known at compile time (because they are discovered before the compiler even starts), but that is not necessary true for user functions, which can be called without having been declared before, but after.
Also, when talking about the execution, internal PHP functions are more efficient than user PHP functions, as well as internal benefit from more validation mechanisms than user functions.</p>
<h3 id="the-zend-vm-argument-stack-frame">The Zend VM argument stack frame<a href="#the-zend-vm-argument-stack-frame" class="anchor">#</a></h3>
<p>Let's continue with the internal functions examples, and the <code>strlen()</code> one just above.
On the OPCode shown above, we can see that a function call is not managed using just one OPCode. In fact, there is a first thing you should remember when talking about functions : they own a stack.
Like in C, or in every language, when you want to call a function, you first have to build what's called a stack frame, and push onto this stack frame the arguments for the function.
Then, you call the function, and this one will most likely pop those arguments from the stack, to use them.
Once the function call is done, you have to destroy the stack frame you allocated to it.</p>
<p>This is the main rule of doing things, but PHP optimizes the stack frame creation and deletion and delays those operations.</p>
<p>When the PHP compiler compiles a script, it knows how many function calls will happen, and how many args those will need. For example, in such a code :</p>
<pre><code>function foo() { }

foo('bar', false);</code></pre>
<p>The compiler knows you are going to call foo() with two arguments (whatever number was declared in the function body). So the compiler tells the engine that the stack frame for this file will be of exactly two arguments. This number is always known by the compiler, even if you use variable argument passing.</p>
<p>The compiler does it by filling this number into the OPArray, (which is the main structure used by the executor), and when the VM will create the stack frame for this OPArray, it will know how many slots to allocate for the variables.</p>
<p>So PHP's stack frame creation for function argument passing is well optimized, there is nothing to compute at execution time, but at compile time.
Even better, the stack frame is allocated in some "permanent" memory pools. That means that when the stack frame is destroyed : when the function call ends, the engine doesn't free the argument list memory, it keeps it warm for further reuse. That prevents some memory allocation and free, back and forth, which is something really bad for a process overall performances.
A structure exists for the VM stack frame, as well as an API</p>
<pre><code>struct _zend_vm_stack {
    void **top;
    void **end;
    zend_vm_stack prev;
};

static zend_always_inline void *zend_vm_stack_alloc(size_t size TSRMLS_DC)
{
    void *ret;

    size = (size + (sizeof(void*) - 1)) / sizeof(void*);

    if (ZEND_MM_ALIGNMENT > sizeof(void*)) {
        /* ... ... */
    } else {
        ZEND_VM_STACK_GROW_IF_NEEDED((int)size);
    }
    ret = (void*)EG(argument_stack)->top;
    EG(argument_stack)->top += size;
    return ret;
}

#define ZEND_VM_STACK_GROW_IF_NEEDED(count)                         \
    do {                                                            \
        if (UNEXPECTED((count) >                                    \
            EG(argument_stack)->end - EG(argument_stack)->top)) {   \
            zend_vm_stack_extend((count) TSRMLS_CC);                \
        }                                                           \
} while (0)</code></pre>
<p>So finally, stack frame management is not that heavy in PHP, what however can be, is argument passing.</p>
<p><strong>SEND_VAR</strong> is an opcode that is responsible of pushing args onto the stack frame. The compiler inevitably generates such an OPCode before a function call. And there will be as many of them as there are variables to pass to the function. See :</p>
<pre><code>$a = '/';
setcookie('foo', 'bar', 128, $a);

line     #* I O op                           fetch          ext  return  operands
-----------------------------------------------------------------------------------
   3     0  >   ASSIGN                                                   !0, '%2F'
   4     1      SEND_VAL                                                 'foo'
         2      SEND_VAL                                                 'bar'
         3      SEND_VAL                                                 128
         4      SEND_VAR                                                 !0
         5      DO_FCALL                                      4          'setcookie'</code></pre>
<p>This shows another OPCode : <strong>SEND_VAL</strong>. In fact, there exists 4 opcodes to send something on the function stack :</p>
<ul><li><strong>SEND_VAL</strong> : sends a compile-time constant value (a string, an int, etc...)</li>
<li><strong>SEND_VAR</strong> : sends a PHP variable ($a)</li>
<li><strong>SEND_REF</strong> : sends a PHP variable beeing a reference, to a function accepting its arg by reference</li>
<li><strong>SEND_VAR_NO_REF</strong>: Optimized handler used in case of nested function calls</li>
</ul><p>We'll just foresee <strong>SEND_VAR</strong>. What does <strong>SEND_VAR</strong> do ?</p>
<pre><code>ZEND_VM_HELPER(zend_send_by_var_helper, VAR|CV, ANY)
{
    USE_OPLINE
    zval *varptr;
    zend_free_op free_op1;
    varptr = GET_OP1_ZVAL_PTR(BP_VAR_R);

    if (varptr == &EG(uninitialized_zval)) {
        ALLOC_ZVAL(varptr);
        INIT_ZVAL(*varptr);
        Z_SET_REFCOUNT_P(varptr, 0);
    } else if (PZVAL_IS_REF(varptr)) {
        zval *original_var = varptr;

        ALLOC_ZVAL(varptr);
        ZVAL_COPY_VALUE(varptr, original_var);
        Z_UNSET_ISREF_P(varptr);
        Z_SET_REFCOUNT_P(varptr, 0);
        zval_copy_ctor(varptr);
    }
    Z_ADDREF_P(varptr);
    zend_vm_stack_push(varptr TSRMLS_CC);
    FREE_OP1();  /* for string offsets */

    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>It checks if your variable is a reference or not. If it is, it separates it, creating a reference mismatch, and that's bad. <a href="http://jpauli.github.io/2014/06/27/references-mismatch.html">I explain
that in this article</a>. That increases the price to pay for function calls in PHP, argument copies because of reference mismatch are really bad for performances.
Then it adds a refcount to the variable, and pushes it onto the VM stack :</p>
<pre><code>Z_ADDREF_P(varptr);
zend_vm_stack_push(varptr TSRMLS_CC);</code></pre>
<p>Yes, everytime you call a function, you increment the refcount of every stack argument variable by one : because the function stack itself will reference the variable, not yet the function code, just the stack at the moment. Also, as you can see and would have guessed, we push pointers onto the stack, not the argument itself, that's why we add a reference to it. Remember the stack frame slots have already been reserved and just wait to be filled in by pointers to variables, by the different SEND OPCodes. If no argument mismatch happening, pushing an arg onto the stack frame is pretty light, you end-up just adding a reference to it, and copying (in C) a pointer variable.</p>
<h3 id="performing-the-function-call">Performing the function call<a href="#performing-the-function-call" class="anchor">#</a></h3>
<p>After pushing the args onto the stack, we run a <strong>DO_FCALL</strong> OPCode, and here, you'll see how many tons of code and checks are performed, allowing us to assume PHP function calls are a "slow" statement :</p>
<pre><code>ZEND_VM_HANDLER(60, ZEND_DO_FCALL, CONST, ANY)
{
    USE_OPLINE
    zend_free_op free_op1;
    zval *fname = GET_OP1_ZVAL_PTR(BP_VAR_R);
    call_slot *call = EX(call_slots) + opline->op2.num;

    if (CACHED_PTR(opline->op1.literal->cache_slot)) {
        EX(function_state).function = CACHED_PTR(opline->op1.literal->cache_slot);
    } else if (UNEXPECTED(zend_hash_quick_find(EG(function_table), Z_STRVAL_P(fname), Z_STRLEN_P(fname)+1, Z_HASH_P(fname), (void **) &EX(function_state).function)==FAILURE)) {
        SAVE_OPLINE();
        zend_error_noreturn(E_ERROR, "Call to undefined function %s()", fname->value.str.val);
    } else {
        CACHE_PTR(opline->op1.literal->cache_slot, EX(function_state).function);
    }
    call->fbc = EX(function_state).function;
    call->object = NULL;
    call->called_scope = NULL;
    call->is_ctor_call = 0;
    EX(call) = call;

    FREE_OP1();

    ZEND_VM_DISPATCH_TO_HELPER(zend_do_fcall_common_helper);
}</code></pre>
<p>As you can see, here, we perform some little checks. And many caches are used. For example, the function handler pointer is looked up at the
very first call, then it is cached into the main VM frame, so that any further call will use the cached pointer.
Many cache tricks are used into the Zend VM, for it to be as efficient as possible.</p>
<p>After that, we call <strong>zend_do_fcall_common_helper()</strong>.
I can't copy the code of this function here, as it is so huge.
I will show you what operations are done into it. Basically, many checks are done, and they all are done now : at runtime, because once more of the heavilly dynamic nature of PHP.
PHP can define new functions at runtime, and PHP can autoload files, defining classes and functions at runtime, so PHP must perform a lot of its checks at runtime, and this is bad for performance, but that's the design of a dynamic language, those are othogonal concepts.</p>
<pre><code>if (UNEXPECTED((fbc->common.fn_flags & (ZEND_ACC_ABSTRACT|ZEND_ACC_DEPRECATED)) != 0)) {
        if (UNEXPECTED((fbc->common.fn_flags & ZEND_ACC_ABSTRACT) != 0)) {
            zend_error_noreturn(E_ERROR, "Cannot call abstract method %s::%s()", fbc->common.scope->name, fbc->common.function_name);
            CHECK_EXCEPTION();
            ZEND_VM_NEXT_OPCODE(); /* Never reached */
        }
        if (UNEXPECTED((fbc->common.fn_flags & ZEND_ACC_DEPRECATED) != 0)) {
            zend_error(E_DEPRECATED, "Function %s%s%s() is deprecated",
                fbc->common.scope ? fbc->common.scope->name : "",
                fbc->common.scope ? "::" : "",
                fbc->common.function_name);
        }
    }
    if (fbc->common.scope &&
        !(fbc->common.fn_flags & ZEND_ACC_STATIC) &&
        !EX(object)) {

        if (fbc->common.fn_flags & ZEND_ACC_ALLOW_STATIC) {
            /* FIXME: output identifiers properly */
            zend_error(E_STRICT, "Non-static method %s::%s() should not be called statically", fbc->common.scope->name, fbc->common.function_name);
        } else {
            /* FIXME: output identifiers properly */
            /* An internal function assumes $this is present and won't check that. So PHP would crash by allowing the call. */
            zend_error_noreturn(E_ERROR, "Non-static method %s::%s() cannot be called statically", fbc->common.scope->name, fbc->common.function_name);
        }
    }</code></pre>
<p>See all those checks ? Let's continue, because it's far from beeing finished :</p>
<pre><code>if (fbc->type == ZEND_USER_FUNCTION || fbc->common.scope) {
    should_change_scope = 1;
    EX(current_this) = EG(This);
    EX(current_scope) = EG(scope);
    EX(current_called_scope) = EG(called_scope);
    EG(This) = EX(object);
    EG(scope) = (fbc->type == ZEND_USER_FUNCTION || !EX(object)) ? fbc->common.scope : NULL;
    EG(called_scope) = EX(call)->called_scope;
}</code></pre>
<p>You know that each function body has its own variable scope. Well it's not magical : the engine switches the scope tables before calling the function code, so that if this one asks for a variable, it will be looked for into the right table.
And as functions and methods are all the same, you can read some instructions about binding the <code>$this</code> pointer for a method. If you want to know more about <code>$this</code>, you should read <a href="http://jpauli.github.io/2015/03/24/zoom-on-php-objects.html#what-is-this">that part of the object related article</a>.
Let's keep going.</p>
<pre><code>if (fbc->type == ZEND_INTERNAL_FUNCTION) {</code></pre>
<p>I told you, internal functions (those designed in C) take a different execution path from user functions. Usually, internal function execution path is more optimized and shorter than user function one, because for internal functions, in C, we can tell the engine internal info about our function, something user designed functions cant.</p>
<pre><code>fbc->internal_function.handler(opline->extended_value, ret->var.ptr, (fbc->common.fn_flags & ZEND_ACC_RETURN_REFERENCE) ? &ret->var.ptr : NULL, EX(object), RETURN_VALUE_USED(opline) TSRMLS_CC);</code></pre>
<p>This line above is the line that calls the internal function handler. For our <code>strlen()</code> example, this above line calls to run the <code>strlen()</code> source code :</p>
<pre><code>/* PHP's strlen() source code */
ZEND_FUNCTION(strlen)
{
    char *s1;
    int s1_len;

    if (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, "s", &s1, &s1_len) == FAILURE) {
        return;
    }

    RETVAL_LONG(s1_len);
}</code></pre>
<p>And what does <code>strlen()</code> do ? It pops the argument stack using <code>zend_parse_parameters()</code>.
And this zend_parse_parameters() function is "slow", because it has to pop the stack and transform the argument to a type which is expected by the function : for <code>strlen()</code> : a string.
So whatever the programmer passed onto the stack to <code>strlen()</code>, this one could need to convert the argument to a string, which is not a light process in term of performance.
<a href="http://lxr.php.net/xref/PHP_5_5/Zend/zend_API.c#729">Read the source of zend_parse_parameters()</a> to have an idea on how many operations we ask our CPU to do, when poping the arguments from a function stack frame.</p>
<p>Let's continue into the execution, we just executed the function body code, now, let's cleanup things, starting by restoring the scope :</p>
<pre><code>if (should_change_scope) {
        if (EG(This)) {
            if (UNEXPECTED(EG(exception) != NULL) && EX(call)->is_ctor_call) {
                if (EX(call)->is_ctor_result_used) {
                    Z_DELREF_P(EG(This));
                }
                if (Z_REFCOUNT_P(EG(This)) == 1) {
                    zend_object_store_ctor_failed(EG(This) TSRMLS_CC);
                }
            }
            zval_ptr_dtor(&EG(This));
        }
        EG(This) = EX(current_this);
        EG(scope) = EX(current_scope);
        EG(called_scope) = EX(current_called_scope);
    }</code></pre>
<p>And clearing the stack :</p>
<pre><code>zend_vm_stack_clear_multiple(1 TSRMLS_CC);</code></pre>
<p>Finally, if an exception has been thrown during this function execution, <a href="http://jpauli.github.io/2015/04/09/exceptional-php.html#throwing-an-exception">we must change the VM path to run the catch block</a> (simplified) :</p>
<pre><code>if (UNEXPECTED(EG(exception) != NULL)) {
        zend_throw_exception_internal(NULL TSRMLS_CC);
        if (RETURN_VALUE_USED(opline) && EX_T(opline->result.var).var.ptr) {
            zval_ptr_dtor(&EX_T(opline->result.var).var.ptr);
        }
        HANDLE_EXCEPTION();
    }</code></pre>
<h3 id="a-conclusion-on-php-function-calls">A conclusion on PHP function calls ?<a href="#a-conclusion-on-php-function-calls" class="anchor">#</a></h3>
<p>Now, can you imagine the time your machine spends for calling a very-tiny-and-simple <code>strlen()</code> function ?
Now multiply this time, because <code>strlen()</code>is called into a loop, with 25,000 iterations, slowly, micro/milli seconds turn to seconds...
Keep in mind that I just showed you the hot path of instructions beeing run at every PHP function call. Many other things happen as well next to those mandatory steps.
Also keep in mind that here, because <code>strlen()</code> "useful work" is just one line, the overhead of the engine preparing the function call is larger than the useful function code itself, but that is generaly not the case of a big average of function calls, where the own code of the function itself will consume hopefuly more performance than the noisy surrounding engine code required to launch it.</p>
<p>You may complain about this. You have this right, but please, don't come to me complaining without proposing a valid technical solution to improve this, knowing that if you break compatibility, you'll have to show strong arguments about this ;-)</p>
<p>The PHP-function-call-related part of the code has been reworked into PHP 7 (among many things), and in PHP 7, function calls are faster than this. As you can imagine by reading this : there is lot of room for optimization yet into PHP source code, and we, as contributors, try to find ways to optimize things at every new PHP version.</p>
<p>Not only talking about PHP 7, the PHP-function-call-related code has been optimized in every version of PHP, from 5.3 to 5.4, and especially from 5.4 to 5.5, where we changed the way the stack frame is computed and created, for example (without breaking compatibility).
It is always interesting to read the readme about internals change of each PHP version. <a href="https://github.com/php/php-src/blob/PHP-5.5/UPGRADING.INTERNALS#L24">Here is the one for PHP5.5</a> talking about changes into the executor and into how function calls are performed, compared to PHP 5.4.</p>
<p>As a conclusion, remember that this is not a blame to PHP. The PHP source code has been worked for twenty years now, by many different very talented brains, so believe me : it has been thought, worked and optimized many times as of nowadays.
The proof is that you use PHP, you have some PHP code in production, and it just works and perform very well, with a nice overall performance factor in the very large majority of use cases. Am I wrong ?</p>
<h3 id="what-about-isset">What about isset() ?<a href="#what-about-isset" class="anchor">#</a></h3>
<p><code>isset()</code> is not a function. Parenthesis don't automatically mean "function call". <code>isset()</code> is compiled into a special Zend VM OPcode (<strong>ISSET_ISEMPTY</strong>), which will not trigger a function call and suffer from function call overhead we have detailed in the last chapter.</p>
<p>As <code>isset()</code> can take several parameter types, its Zend VM code is a little bit long, but just isolating the parameter-is-a-string-offset part, it leads to this :</p>
<pre><code>ZEND_VM_HELPER_EX(zend_isset_isempty_dim_prop_obj_handler, VAR|UNUSED|CV, CONST|TMP|VAR|CV, int prop_dim)
{
    USE_OPLINE zend_free_op free_op1, free_op2; zval *container; zval **value = NULL; int result = 0; ulong hval; zval *offset;

    SAVE_OPLINE();
    container = GET_OP1_OBJ_ZVAL_PTR(BP_VAR_IS);
    offset = GET_OP2_ZVAL_PTR(BP_VAR_R);

    /* ... code pruned ... */
    } else if (Z_TYPE_P(container) == IS_STRING && !prop_dim) { /* string offsets */
        zval tmp;
        /* ... code pruned ...*/
        if (Z_TYPE_P(offset) == IS_LONG) { /* we passed an integer as offset */
            if (opline->extended_value & ZEND_ISSET) {
                if (offset->value.lval >= 0 && offset->value.lval < Z_STRLEN_P(container)) {
                    result = 1;
                }
            } else /* if (opline->extended_value & ZEND_ISEMPTY) */ {
                if (offset->value.lval >= 0 && offset->value.lval < Z_STRLEN_P(container) && Z_STRVAL_P(container)[offset->value.lval] != '0') {
                    result = 1;
                }
            }
        }
        FREE_OP2();
    } else {
        FREE_OP2();
    }

    Z_TYPE(EX_T(opline->result.var).tmp_var) = IS_BOOL;
    if (opline->extended_value & ZEND_ISSET) {
        Z_LVAL(EX_T(opline->result.var).tmp_var) = result;
    } else {
        Z_LVAL(EX_T(opline->result.var).tmp_var) = !result;
    }

    FREE_OP1_VAR_PTR();

    CHECK_EXCEPTION();
    ZEND_VM_NEXT_OPCODE();
}</code></pre>
<p>Appart from many decision points (many ifs structures), the real hot computing algorithm here can be summed up in one line :</p>
<pre><code>if (offset->value.lval >= 0 && offset->value.lval < Z_STRLEN_P(container))</code></pre>
<p>If the offset is positive (you did not mean <code>isset($a[-42])</code>), and it is stricly less than the length of the string,
result will be passed 1, and then the resulting operation will be the boolean TRUE.
Don't worry about the length computation : <code>Z_STRLEN_P(container)</code> will not compute anything. Remember that PHP already knows the length
of your string, <code>Z_STRLEN_P(container)</code> just read that value in memory : very few CPU cycles are needed for that.</p>
<p>Now I think you understand that there are much much more CPU instructions involved in the PHP function call of <code>strlen()</code> than in the
use of <code>isset()</code> in the case of a string offset. You see how <code>isset()</code> is light ? Don't be scared by many if statements, they are not the heaviest parts of the C code and can be optimized in some ways by the C compiler.
The <code>isset()</code> handler code doesn't lookup hashtables, doesn't perform any complex check, doesn't push any pointer to any stack frame, to pop them back later, eventually transforming the data...
The code is way lighter than the overall code of a function call, with many less memory accesses (this is the most important part to notice). And in this particular case of a string : it leads to a huge improvement if you were iterating this code over and over again into a loop.
Of course, if you just run one iteration of comparison between <code>strlen()</code> and <code>isset()</code>, you will find the performance benefit really low, about 5ms difference, something like that. But multiplied by 50,000 iterations...</p>
<p>Notice as well, <a href="http://lxr.php.net/xref/PHP_5_5/Zend/zend_vm_def.h#4445">by reading the whole isset() source code</a>, that it is shared with the <code>empty()</code> code.
<code>empty()</code> on a string offset will differ from the same <code>isset()</code> statement by just additionnaly reading if the first character of the
string is not the '0' character.
<code>empty()</code> and <code>isset()</code> lead to the exact same code beeing run, with just one little tiny diff somewhere, so <code>empty()</code> will have the exact same performance impact that <code>isset()</code> (assuming you use both with the same parameter)</p>
<h2 id="what-can-opcache-do-for-us">What can OPCache do for us ?<a href="#what-can-opcache-do-for-us" class="anchor">#</a></h2>
<p>Short answer : Nothing.</p>
<p>OPCache optimizes your code. I talked about this many times in worldwide conferences, you may fetch my slides at <a href="http://fr.slideshare.net/jpauli/yoopee-cache-op-cache-internals"></a><a href="http://fr.slideshare.net/jpauli/yoopee-cache-op-cache-internals">http://fr.slideshare.net/jpauli/yoopee-cache-op-cache-internals</a> for example.</p>
<p>We've been asked on github if we could add an optimization pass that would switch <code>strlen()</code> to <code>isset()</code> : That's not possible.</p>
<p>Remember that OPCache optimization passes act on the OPArray before storing it into shared memory. <em>This happens at compile time and not
at runtime</em>. But at compile time, how can we know that the variable you pass to <code>strlen()</code> is a string ? We can't. That's the PHP problem,
and that's a part of how HHVM/Hack solved it. If we could type our variables in PHP, that is, supporting strong typing, then we could optimize
much more things in compiler passes (as well as into the VM).
Because of the dynamic nature of PHP, nearly nothing is known at compile time. The only thing OPCache can optimize are static, compile-time-known things.
For example, this can be optimized by OPCache :</p>
<pre><code>if (strlen("foo") > 8) {
 /* do domething */
} else {
 /* do something else */
}</code></pre>
<p>At compile time, we know here that "foo"'s string length is not above 8, and we can trash all the if() opcodes as well as the "true" part of
the if, and just run the "else" part.
But here :</p>
<pre><code>if (strlen($a) > 8) {
 /* do domething */
} else {
 /* do something else */
}</code></pre>
<p>What is in $a ? Does even $a exist here ? Is it a string ?
At the time the optimizer shows in, it just can't answer those questions, that is the VM executor role. At compile time, we end up handling abstract structure with no real type yet, type and related memory usage will be known/allocated at runtime only.</p>
<p>OPCache optimizer already optimizes many things, but by the heavilly dynamic nature of the PHP language, we can't optimize everything, at least not as much as in Java's compilers, or even C's compilers.</p>
<p>That's why when I hear proposal to add strong typing to the language, I like it, because it will boost the performance. PHP 7 added some more typing, and took benefit from it for optimizing things because now, types may be known at compile time.</p>
<p>Also, proposal such as adding a read-only hint to class property declaration :</p>
<pre><code>class Foo {
    public read-only $a = "foo";
}</code></pre>
<p>Not talking about the functionnality itself, my mind is tied to performance : such proposals are really nice in term of performance optimization, because here, when we compile such class, we know the value of $a, and we know it can't
change, so we can store its value somewhere, use a cached pointer, and strongly optimize every access to such a variable into weither
PHP compiler, or OPCache optimization passes.</p>
<p>This case really looks like managing a constant, but I think you understood the base line here : the more informations you can give to the compiler about the type and the usage of your variables or functions, the more it will be able to optimize the OPCode for the VM and the structures used, to get closer to what the CPU will need. A good tradeoff between those two concepts is called "JIT" compilation, a subject I won't talk about in this article.</p>
<h2 id="optimization-tips-and-conclusion">Optimization tips and conclusion<a href="#optimization-tips-and-conclusion" class="anchor">#</a></h2>
<p>The first tip I would like to share with you, is to not blindly change your code, everywhere you have a good feeling of it.
Profile. Profile, and see the results.
With profilers such as <a href="https://blackfire.io/">Blackfire</a>, you can immediately see the hot path of your script, because it automaticaly trashes the irrelevant
information that usually catch your eyes when you read a profile.
You then know <em>where</em> to start working, because your work costs money, and for it to be worth it, it has to be optimized as well.
That's a nice balance between the money you'll cost optimizing a script, and the money you'll save because your cloud will be smaller
and will cost you less.</p>
<p>The second tip is that PHP is fast, believe me.
For what you ask it to do, the way it does the job and the tools it represents to you : it is fast, efficient, reliable.
There is not that much room to optimize PHP scripts, at least not as if you were using lower level language like C.
The main trick is to optimize what is repeated : loops. If you use a profiler showing you the hot path of you script,
you'll happen to find that it is likely to be located into loops.
That's the same when we, as contributors, optimize PHP itself : we won't bother optimizing a part of code a few users will trigger, but better
optimize the hot path : variable accesses, engine function calls, etc... Because in here, the very little micro-second earned
will translate to final milli-seconds or even seconds, as such code is run tons of times (usually involving loops).
Except <code>foreach()</code>, in PHP, loops are the same and lead to the same OPCode. Turning a PHP's <code>while</code> loop into a <code>for</code> loop is
both useless and silly. Once more : profiling will tell you that.</p>
<p>So, about function calls, well... A language needs function calls ;-)
However, there are little tricks that can be used to prevent some function calls, because the information is available elsewhere.
Like :</p>
<pre><code>php_version() => use the PHP_VERSION constant
php_uname() => use the PHP_OS constant
php_sapi_name() => use the PHP_SAPI constant
time() => read $_SERVER['REQUEST_TIME']
session_id() => use the SID constant</code></pre>
<p>The above examples are sometimes not 100% equivalent, and I let you read the documentation to find the differences.</p>
<p>Ah ho yes, let me tell it because we still see such things nowadays (uncommonly) : prevent silly things, like :</p>
<pre><code>function foo() {
    bar();
}</code></pre>
<p>Or even worse :</p>
<pre><code>function foo() {
    call_user_func_array('bar', func_get_args());
}</code></pre>
<p>Basically, don't stop working, don't stop using PHP, don't optimize something "because you heard that", "because someone told you that", and don't design your application by performance, but keep doing it by features.</p>
<p>However, profile your script, often, and verify every assumptions by yourself, do not blindly apply some performance patch assuming that...? Check by yourself.</p>
<p>We, at Blackfire engineer team, spend many time finding interesting metrics to show our PHP users. We use our deep knowledge of the PHP
engine to gather many items showing you what's happening into the deepness of your PHP scripts.
Even if the GUI doesn't show it yet, Blackfire probe extension measures many things, like when the garbage collector has been triggered, what it does, how many objects you created/destroyed in your functions, how many reference mismatch you performed when calling your functions, and even deeper metrics, such as session serialization time, <code>foreach()</code> bad behaviors (there are many things to say about foreach())... basicaly, everything that may help a developer find performance spots, and how to fix them.</p>
<p>Also, don't forget that you will at some point hit the limits of the language. Then it will probably be time to switch it.
PHP is not the right language to build an ORM, to make a video game, to create an HTTP server, to batch process some text based files or to create a parser of any kind.
It can do it, but it can't do it efficiently, under a high load. You'll hit a limit that is really close compared to
the one a better suitable language for such tasks will show, aka Java, Go or probably the most efficient language in the world nowadays, should you really well use it : C/C++ (Both Java and Go are also written in C/C++).</p>]]></content>
    </entry>
        <entry>
        <title>PHP output buffer in deep</title>
                <id>http://jpauli.github.io//2014/12/19/php-output-buffer-in-deep.html</id>
                <updated>2014-12-19T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2014/12/19/php-output-buffer-in-deep.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="first-words">First words<a href="#first-words" class="anchor">#</a></h2>
<p>Everybody is aware of the "output buffering" layer in PHP. This blog post is about how it works, how it's been
implemented in PHP source code, and how to interact with it from PHP. This layer is not complex, but often misunderstood,
or at least, not fully mastered by PHP developers.
Let's try to fix that together. We'll talk about PHP >=5.4, should you know that many things have changed starting 5.4
about the OB layer, in fact, it has been completely rewritten and broke compatibility in some ways with PHP 5.3 (documented).</p>
<h2 id="what-is-the-output-buffer">What is the output buffer ?<a href="#what-is-the-output-buffer" class="anchor">#</a></h2>
<p>PHP's output stream contains bytes, usually text that the developer asks PHP to display, often using <code>echo</code> statements or <code>printf()</code>.
The first thing you should know is that any function outputing something will use the output buffer, this, from PHP land. When you
live into the extension land, you may access functions that writes directly into SAPI preventing any OB layer above.
The C API is documented into <a href="http://lxr.php.net/xref/PHP_5_5/main/php_output.h">main/php_output.h</a> and as usual gives us many informations,
such as the default buffer size f.e.</p>
<p>The second thing to know is that the output buffer layer is one layer among others (there is not just one solo layer
buffering your output).
And the last thing to remember is that the output buffer layer behaves differently in accordance with the SAPI you are using
(web or cli).
Let's first draw the main picture that explains everything</p>
<p><img src="../../../img/ob/ob_main.png" alt="PHP ob layers"></p>
<p>Like you can see, we can distinguish between 3 logical layers of buffer for the output management into PHP.
2 of them belong to the famous "output buffering", and one last lives into the SAPI.
Those are the PHP layers, when the flow of output bytes leaves PHP to enter the bottom layer in the main architecture,
here again, buffers may appear (terminal buffer, fast-cgi buffer, web server buffer, OS buffers, TCP/IP stack buffers and
we'll stop here).
Don't forget this, beside the fact that we'll only talk about the PHP part in this article, many other pieces of software in
the whole stack may retain information before passing them to the below layer before hitting the end user.</p>
<p>One particular note about the CLI SAPI, so that's done. CLI disables any default PHP output buffer, by forcing the INI setting
<em>output_buffering</em> to 0. So, by default, until you play manually with ob_() functions, in CLI, when you output something, it
directly hits the SAPI layer. Moreover, in CLI, <em>implicit_flush</em> is also hardcoded to the value 1.
<em>Implicit_flush</em> setting is always misunderstood, in fact
<a href="http://lxr.php.net/xref/PHP_5_5/main/output.c#1095">the source code is really eloquent about it</a> : when <em>implicit_flush</em> is turned
on, the SAPI layer buffer is asked to be flushed anytime it is written to.
To conclude : anytime you write any output with the CLI SAPI, it will be asked to be immediately thrown to the bottom layer, which
is the stdout pipe <a href="http://lxr.php.net/xref/PHP_5_5/sapi/cli/php_cli.c#273">beeing write()en</a> and then
<a href="http://lxr.php.net/xref/PHP_5_5/sapi/cli/php_cli.c#328">fflush()ed</a>. Easy.</p>
<h2 id="default-php-output-buffer-layer">Default PHP output buffer layer<a href="#default-php-output-buffer-layer" class="anchor">#</a></h2>
<p>So far so good, if you use a SAPI different from CLI, for example PHP-FPM, you'll be able to play with those 3 buffer-related INI settings :</p>
<ul><li>output_buffering</li>
<li>implicit_flush</li>
<li>output_handler</li>
</ul><p>Before understanding those, you should note that using <code>ini_set()</code> with them will have no effect, as their effect is analyzed at PHP startup, that is before
PHP may run any script. So when it meets an <code>ini_set()</code> about one of those 3 settings, it effectively changes the value, but this new value won't be used anywhere
as it is too late : the output buffer layer is already started and active.
Change those by editing php.ini or using the <em>-d</em> switch to the PHP binary.</p>
<p>Ok, so by default, the php.ini shipped with the actual PHP distribution gives <em>output_buffering</em> the value of "4096" (bytes). If you don't use any php.ini
(or start PHP with the <em>-n</em> switch), the default will be <em>"0"</em>, aka disabled.
If you hardcode the value to <em>"On"</em>, then the <a href="http://lxr.php.net/xref/PHP_5_5/main/php_output.h#91">default output buffer size</a> will be used
(16Kb).
As you may have guessed, having a buffer for any output, in web environment, is a good thing for performance. The default 4Kb is a good setting,
this means you may write up to 4096 ASCII characters until PHP actually communicates with the below SAPI layer.
And in a web context, telling a socket to send bytes on a byte-by-byte basis is not very nice in term of performance. It is way better for your
server machine to send the content all at once, or big-chunks-by-big-chunks. The less often the layers communicate, the better for performance.
You should always keep an output buffer. PHP will send it at the end of the request, you don't have to do anything.</p>
<p>You already know about <em>implicit_flush</em> as we talked about it in the previous chapter regarding CLI. For any other SAPI, implicit flush is by default
set to <em>off</em>, which is a good value, as flushing the SAPI just after having written into it is probably not the behavior you expect. For the FastCGI
protocol, flushing is about ending and sending a FastCGI packet after every write, it may however be better to fullfill the FastCGI buffers before sending
FastCGI packets.
If you want to manually flush the SAPI buffers, use PHP's <code>flush()</code> function.
If you want it to be flushed after any write, use <em>implicit_flush</em> INI setting or call the PHP function <code>ob_implicit_flush()</code> once.</p>
<p>The <em>output_handler</em> is a callback that may be applied to the content of the buffer, before it gets flushed. There exists many callbacks, provided by
PHP extensions (user may also write callbacks, we'll talk about this in the next chapter).</p>
<ul><li>ob_gzhandler : output compression using ext/zlib</li>
<li>mb_output_handler : character encoding translation using ext/mbstring</li>
<li>ob_iconv_handler : character encoding translation using ext/iconv</li>
<li>ob_tidyhandler : HTML output tidying using ext/tidy</li>
<li>ob_[inflate/deflate]_handler : output compression using ext/http</li>
<li>ob_etaghandler : HTTP etag automatic generation using ext/http</li>
</ul><p>The callback you'll choose (only one possible) will be sent the buffer content and will perform some transformations about it, something which is very
nice. Remember that if you want to be able to see anything that PHP is to write back to the webserver and then to the user, use an output buffer callback,
that's the way to do such things.
Also remember that by "output" , we mean any headers and body. HTTP headers are also part of the OB layer.</p>
<h3 id="headers-and-body">Headers and body<a href="#headers-and-body" class="anchor">#</a></h3>
<p>At the time you use an output buffer (weither a user one, or the default PHP one), you may send HTTP headers and content the way you want.
You know that any protocol require to send headers before body (thus the term "header"), but when you use an ouput buffer layer, PHP will take care of
this for you.
Any PHP function playing with output headers (<code>header()</code>, <code>setcookie()</code>, <code>session_start()</code>) will in fact use the internal
<a href="http://lxr.php.net/xref/PHP_5_5/main/SAPI.c#667">sapi_header_op()</a> function which just fills in the headers buffer.
When you then write output, using say printf(), it writes into the output buffer (assuming one).
When the output buffer is to be sent, PHP starts sending the headers first, and then the body. PHP takes care of everything for you.
If you dont like this behavior, you have no other choice than disabling any output buffer layer.</p>
<h2 id="user-output-buffers">User output buffers<a href="#user-output-buffers" class="anchor">#</a></h2>
<p>Let's show some examples of how this works and what you can do.
Remember that if you want to play with the dafult PHP output buffer layer, you may then not used CLI, as it disables such a layer.
Here is an example playing with PHP default output buffer layer, using PHP internal webserver SAPI:</p>
<pre><code>/* launched via php -doutput_buffering=32 -dimplicit_flush=1 -S127.0.0.1:8080 -t/var/www */

echo str_repeat('a', 31);
sleep(3);
echo 'b';
sleep(3);
echo 'c';</code></pre>
<p>So we start PHP with a default output buffering layer of 32 bytes, and we immediately write 31 bytes to it before sleeping. Here, as expected,
nothing is sent yet, blank screen.
Then the sleep finishes and we write one more byte, fulfilling the buffer wich then immediately flushes itself into the SAPI layer buffer, itself
flushing immediately to the output, as we put implicit_flush to 1. The string 'aaaaaaaaaa{31times}b' then appears on the screen, and we start another
sleep. After this last sleep, the empty 31-byte-size buffer is filled-in with only one byte, but PHP then ends, and flushes back this buffer immediately.
The 'c' character appears.</p>
<p>We just showed how <strong>the default PHP buffer</strong> works, without calling any ob related functions yet. Keep in mind that this default buffer is here,
it is present (in non-CLI mode) and you may not forget about it.</p>
<p>We may now start user buffers, calling <code>ob_start()</code>, and we may stack as many buffers as we want (until we run out of memory).
Every buffer will stack onto the preceding one, and will flush itself into the immediately next one, eventually fulfilling it and make it overflow, etc...</p>
<pre><code>ob_start(function($ctc) { static $a = 0; return $a++ . '- ' . $ctc . "\n";}, 10);
ob_start(function($ctc) { return ucfirst($ctc); }, 3);

echo "fo";
sleep(2);
echo 'o';
sleep(2);
echo "barbazz";
sleep(2);
echo "hello";

/* 0- FooBarbazz\n 1- Hello\n */</code></pre>
<h2 id="output-buffering-internals">Output buffering internals<a href="#output-buffering-internals" class="anchor">#</a></h2>
<p>Since 5.4, the entire output buffering layer has been rewritten (by Michael Wallner). The code was a mess before, and many things were hard to do and buggy.
Read on <a href="http://marc.info/?l=php-internals&m=114104110826804&w=2"></a><a href="http://marc.info/?l=php-internals&m=114104110826804&w=2">http://marc.info/?l=php-internals&m=114104110826804&w=2</a> for more informations.
PHP 5.4 starts with a new code base, which is much more clean and designed, offers new features and has little breaks against 5.3. Nice !</p>
<p>One of the nicest feature added then is the possibility for extensions to declare their output buffer callback as conflicting with another one provided
by another extension. Before that, it was impossible -when designing an extension playing with the output buffer- to fully master the impact knowing
other extensions could declare callbacks as well.</p>
<p>Here is a quick-and-dirty little example showing how to register a callback that <code>strtoupper()</code> its content.</p>
<pre><code>#ifdef HAVE_CONFIG_H
#include "config.h"
#endif

#include "php.h"
#include "php_ini.h"
#include "main/php_output.h"
#include "php_myext.h"

static int myext_output_handler(void **nothing, php_output_context *output_context)
{
    char *dup = NULL;

    dup = estrndup(output_context->in.data, output_context->in.used);
    php_strtoupper(dup, output_context->in.used);

    output_context->out.data = dup;
    output_context->out.used = output_context->in.used;
    output_context->out.free = 1;

    return SUCCESS;
}

PHP_RINIT_FUNCTION(myext)
{
    php_output_handler *handler;

    handler = php_output_handler_create_internal("myext handler", sizeof("myext handler") -1, myext_output_handler, /* PHP_OUTPUT_HANDLER_DEFAULT_SIZE */ 128, PHP_OUTPUT_HANDLER_STDFLAGS);

    php_output_handler_start(handler);

    return SUCCESS;
}

zend_module_entry myext_module_entry = {
    STANDARD_MODULE_HEADER,
    "myext",
    NULL, /* Function entries */
    NULL,
    NULL, /* Module shutdown */
    PHP_RINIT(myext), /* Request init */
    NULL, /* Request shutdown */
    NULL, /* Module information */
    "0.1", /* Replace with version number for your extension */
    STANDARD_MODULE_PROPERTIES
};

#ifdef COMPILE_DL_MYEXT
ZEND_GET_MODULE(myext)
#endif</code></pre>
<h2 id="gotchas">Gotchas<a href="#gotchas" class="anchor">#</a></h2>
<p>The gotchas are mainly documented. Some are logical, some are hidden.
The logical, obvious ones are that you should not call any buffer functions from whithin an output buffer callback, nor should you write some output from there.</p>
<p>The less obvious ones are that some PHP functions use internally the output buffer for themselves, stacking another buffer, filling it then flushing or returning it.
Examples of such functions are <code>print_r()</code>, <code>highlight_file()</code> and <code>SoapServer::handle()</code>.
You should not use such functions from within an output buffer callback. The behavior may be undefined, or at least not what you'd expect.</p>
<h2 id="ending">Ending<a href="#ending" class="anchor">#</a></h2>
<p>The output layer is a layer of nets, catching any output "leak" that may come from PHP, and saving it in a sized buffer. When the buffer is full, it is flushed (written)
into the bottom layer if any, or at least into the bottom logical layer : the SAPI buffer.
End users have control over the number of buffers, their size and the operation that may be permitted on each layer of buffer (cleanable, flushable or removable).
This is very flexible and for example, allows library/framework designers to gain full control of their own output flow by catching it and treating it into a global buffer.
By output, we suppose any output stream bytes and any output HTTP headers , PHP taking care of sending them in the right order.</p>
<p>The output buffer also provides by default one buffer, controlled by 3 INI settings, that is designed to prevent smalls regulars writes from hitting the SAPI layer too often, and thus the
network too often, which is poor for performances.
PHP extensions may also declare callbacks to be run on every buffer, for example to perform data compression, string substitution, HTTP headers management and many other things.</p>]]></content>
    </entry>
        <entry>
        <title>PHP and MySQL communication, mysqlnd</title>
                <id>http://jpauli.github.io//2014/07/21/php-and-mysql-communication-mysqlnd.html</id>
                <updated>2014-07-21T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2014/07/21/php-and-mysql-communication-mysqlnd.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>Appeared with PHP5.3, mysqlnd is an unknown part of PHP. Yet, this extension is a must-have if your system relies heavily on the MySQL database server. We'll see what mysqlnd is, what it brings to PHP
and how to use it.</p>
<h2 id="foresee">Foresee<a href="#foresee" class="anchor">#</a></h2>
<p>PHP communicates with MySQL through a connector. 2 of them exist : libmysql or mysqlnd. libmysql is licenced by Oracle, while mysqlnd is under the PHP licence. Both code bases are mostly maintained by Oracle employees.
If a user wants to communicate with MySQL using the PHP language, this latter publishes 3 APIs in this goal : ext/mysql, ext/mysqli and ext/pdo_mysql.</p>
<p><img src="../../../img/php-mysql-com/php-arch-libmysql.png" alt="libmysql"><img src="../../../img/php-mysql-com/php-arch-mysqlnd.png" alt="mysqlnd"></p>
<h3 id="connectors">Connectors<a href="#connectors" class="anchor">#</a></h3>
<h4 id="libmysql">libmysql<a href="#libmysql" class="anchor">#</a></h4>
<p>Historicaly, PHP needed the MySQL server C connector to be able to talk with it. This connector is also known as "libmysql", and may be installed on your system with a command like <code>apt-get install libmysql</code>. This connector implements the MySQL communication API, let's see an example :</p>
<pre><code>#include <stdio.h>
#include <stdlib.h>
#include <mysql/mysql.h>
#include "mysql_example.h" /* Pour MYSQL_HOST, MYSQL_USER, MYSQL_PASS */

int main(int argv, char *argc[])
{
    MYSQL_RES *results = NULL; MYSQL_ROW row; MYSQL *db = NULL;

    db = (MYSQL *)malloc(sizeof(MYSQL));
    mysql_init(db);
    mysql_options(db, MYSQL_INIT_COMMAND, "SET NAMES UTF8;");
    if(!mysql_real_connect(db, MYSQL_HOST, MYSQL_USER, MYSQL_PASS, NULL, 0, NULL, 0)) {
        fprintf(stderr, "Failed to connect to host %s (%s)", MYSQL_HOST, mysql_error(db));
        exit(EXIT_FAILURE);
    }

    mysql_set_character_set(db, "utf8");
    mysql_select_db(db, "my_database");
    mysql_query(db , "SELECT user_id AS id FROM users WHERE user_description='member' LIMIT 10000");
    results = mysql_use_result(db);

    while(row = mysql_fetch_row(results)) {
        printf("%s\n", row[0]);
    }

    mysql_free_result(results);
    exit(EXIT_SUCCESS);
}</code></pre>
<p>You can run this code by linking your binary with libmysql, GCC's switch "-lmysql".
The libmysql documentation is detailed, and online, at <a href="http://dev.mysql.com/doc/refman/5.0/en/c-api.html"></a><a href="http://dev.mysql.com/doc/refman/5.0/en/c-api.html">http://dev.mysql.com/doc/refman/5.0/en/c-api.html</a></p>
<p>As you could have noticed, the PHP extensions "mysql" and "mysqli" borrow this C API to publish it to PHP land. This is one of the PHP way of doing things : when an extension creator embeds a C API
into PHP's source to publish it to PHP user land, usually he gives it the same API as the C one, this way when you know one of them, you are not lost getting hands into the second one.</p>
<p>libmysql however could bring some problems to your architecture :</p>
<ul><li>The licencing is complex. For example, if you wish to build a closed-source commercial product on top of libmysql, you'll need to pay for a licence. <a href="http://www.mysql.com/about/legal/licensing/oem/">Details about libmysql licencing here</a>.</li>
<li>Updating libmysql involves updating the MySQL server in certain distros, which sometimes is not what you want in your upgrading strategies.</li>
</ul><h4 id="mysqlnd">mysqlnd<a href="#mysqlnd" class="anchor">#</a></h4>
<p>As of PHP5.3, the PHP developers rewrote entirely the libmysql source code, into a PHP extension named "mysqlnd". mysql native driver. This connector is licenced under the PHP licence, which is more appropriate than the Oracle's licences as all stay under the same PHP licence.</p>
<p>Also, rewriting the code of a library that was not part of PHP (libmysql) was also the way to improve many things in the MySQL-PHP communication. We'll detail how mysqlnd can improve your application performance drastically, especially if this one runs big select queries (batch scripts are the appropriate use case here).</p>
<p>Just keep in mind that mysqlnd is a PHP extension that does not publish any class or function to PHP (this in not totally right, we'll get back to that point later on), it however can serve as a big basis for other PHP extensions mysql,mysqli and pdo_mysql to rely on when communicating with MySQL servers.</p>
<p>mysqlnd is to be activated at compile time in PHP 5.3 (--with-pdo-mysql=mysqlnd switch, for pdo_mysql example), and it is proposed <em>as the default connector</em> starting from PHP 5.4.</p>
<h3 id="extensions">Extensions<a href="#extensions" class="anchor">#</a></h3>
<p>PHP publishes 3 extensions for the PHP user to talk to MySQL servers.</p>
<h4 id="mysql">mysql<a href="#mysql" class="anchor">#</a></h4>
<p>This very old extension was the first one published. It was contributed by the MySQL authors back before year 2000. It publishes the <em>mysql_</em> functions in PHP by adopting the underlying C API.
This extension borrows the MySQL server 3.23 API, so for today, it is not to be used as it is too old. It's still here for compatibility purposes, throws E_DEPRECATED errors in latest PHP versions and is meant to die sooner or later. Please, don't use it for your recent projects.</p>
<h4 id="mysqli">mysqli<a href="#mysqli" class="anchor">#</a></h4>
<p>mysqli is written with an end "i" which stands for "improved". This extension appeared in PHP5.0, and is meant to replace the old ext/mysql API, because it is internally based or more recent MySQL server API : 4.1 or later. It then supports stored procedure, secured authentification protocol, prepared statements and much more.
It also publishes an object oriented API to the PHP user, together with a procedural API.</p>
<p>PHP contributors designed this extension so that it has a very common API shared with ext/mysql, and migrations from ext/mysql to ext/mysqli should really be painless.</p>
<p>We'll detail ext/mysqli API in a few moment to introduce not well understood but critical concepts such as buffered/unbuffered queries and prepared statements.</p>
<h4 id="pdo">PDO<a href="#pdo" class="anchor">#</a></h4>
<p>PDO is different from mysql/mysqli because it has been designed to support other RDBMS than MySQL. In this fact, this extension is imperfect and tries to guess many things from the user, which could lead to strange behaviors. Let me explain.</p>
<p>PDO ships with an SQL parser which is to emulate prepared statements if the underlying RDBMS doesn't support them. The problem is that this layer behaves differently from the RDBMS' one, when present.
If you take the MySQL case, the PDO emulation layer is active by default when you prepare a query, and this one will never hit MySQL prepared statement layer which is probably not what you want. In fact, PDO's code will parse and build your query, never communicating with MySQL about this (by default). This is weird. Turn this emulation layer off as soon as you can :</p>
<pre><code>/* Disable PDO prepared statements emulation */
$pdo->setAttribute(PDO::ATTR_EMULATE_PREPARES, 0);

/* This is exactly the same, take care, we really pass 0 here and not 1 */
$pdo->setAttribute(PDO::MYSQL_ATTR_DIRECT_QUERY, 0);</code></pre>
<p>When the emulation layer is disabled, you rely with a true prepared statement. When it is enabled, PDO will take care of constructing the query for you, and will send a traditionnal normal query to the RDBMS. This has lots of drawbacks and can lead to strange behaviors. As PDO doesn't know anything about tables' columns, its emulation layer will quote every parameter when bound to an emulated prepared statement, even the parameter of integer type, which don't need such quoting. This leads to errors :</p>
<pre><code>$stmt = $pdo->prepare("SELECT user_id FROM users LIMIT :limit");
$stmt->bindValue('limit', 10);
$stmt->execute();

$result = $stmt->fetch();
var_dump($result);

/*
PHP Fatal error:  Uncaught exception 'PDOException' with message 'SQLSTATE[42000]: Syntax error or access violation: 1064 You have an error in your SQL syntax;
check the manual that corresponds to your MySQL server version for the right syntax to use near ''10'' 
*/</code></pre>
<p>We see from this error message that PDO escaped my 'limit' parameter quoting it wrongly, as it is an integer and doesn't need that.
Let's try again with no emulation layer, relying only on the RDBMS layer (MySQL here):</p>
<pre><code>$pdo->setAttribute(PDO::ATTR_EMULATE_PREPARES, 0); /* Disable prepared statement emulation layer */
$stmt = $pdo->prepare("SELECT user_id FROM users LIMIT :limit"); /* A true prepare() will be sent to the RDBMS, it has to support it */
$stmt->bindValue('limit', 10);
$stmt->execute();

$result = $stmt->fetch();
var_dump($result);
/*
array(4) {
  ["user_id"]=>
  string(7) "18"
  [0]=>
  string(7) "18"
}
*/</code></pre>
<p>Things now work.
If you would want to still use the emulation layer, you'd then need to precise to PDO that your parameter is of type integer, like this :</p>
<pre><code> /* Tells the PDO prepared statement emulation layer that this column is of type integer (SQL type) */
$stmt->bindValue('limit', 10, PDO::PARAM_INT);</code></pre>
<p>And here you don't have the whole story.</p>
<p>Whereas we explicitely disabled the prepared statement emulation layer in PDO, this one is still a little active. The layer is still triggered for parameter parsing. You know about the two parameter syntax : anonymous parameters, implemented as "?" in your query for placeholders, or the named parameters, as ":myparam". Those two syntaxes are not supported by every RDBMS, and guess what ? MySQL doesn't support the named parameters one, only the question-mark-based one.
However, our preceding query still completed fine... This is because the PDO query analyzer is still active, even with prepared statement emulation layer tured off. It stepped in and replaced every named parameter by an anonymous one, because it asked the RDBMS (MySQL here) about its capabilities to support those syntaxes, and MySQL answered it did not support the named parameters syntax. PDO then replaced every ":myparamname" by a "?".
Tricky isn't it ?</p>
<p>By trying to satisfy every soul on earth, PDO created an API that is full of trade-offs. It is in fact well designed, and eases the PHP developers life in a huge majority of cases, but hidding complexity is a double-edged sword. If you hit the bogus case, your are then in trouble if you don't know what happens in the lower layers.</p>
<h2 id="zoom-on-the-mysqli-extension">Zoom on the mysqli extension<a href="#zoom-on-the-mysqli-extension" class="anchor">#</a></h2>
<p>mysqli is a nice extension, really. Nowadays, everybody uses PDO, the main argument about this is if you were to switch from one RDBMS to an other, this would ease many things. I don't know you, but I've never met such a situation. If you use MySQL RDBMS, and you are pretty unlikely to change (in production), which usually is the case : don't use PDO, you'll lose many things and suffer from one more layer of abstraction which can't offer everything the RDBMS can offer. Have a look at mysqli API and notice how rich it is :</p>
<p><img src="../../../img/php-mysql-com/mysqli-api.jpg" alt="mysqli"></p>
<p>First of all, mysqli has always been blamed for not generating exceptions but PHP errors. This is wrong.</p>
<pre><code>mysqli_report(MYSQLI_REPORT_ERROR | MYSQLI_REPORT_STRICT);

try {
    $db = mysqli_connect('myserver', 'myuser', 'secret', 'unknown_database');
} catch (mysqli_sql_exception $e) {
    exit($e->getMessage());
}
try {
    mysqli_query($db, "SELECT foo FROM bar");
    /* ... */
} catch(mysqli_sql_exception $e) { }</code></pre>
<p>You see ?</p>
<p>mysqli can even tell you when you miss an index :</p>
<pre><code>mysqli_report(MYSQLI_REPORT_INDEX);
$db = mysqli_connect('myserver', 'myuser', 'secret', 'my_database');

mysqli_query($db, "SELECT photo FROM Users WHERE source ='web' LIMIT 1000");

/* PHP Warning:  mysqli_query(): (00000/0): No index used in query/prepared statement ... */</code></pre>
<p>MySQL communicates many things with its client (PHP in our case). For more information, you should read the <a href="http://dev.mysql.com/doc/internals/en/client-server-protocol.html">MySQL client/server protocol documentation</a></p>
<p>Second thing : mysqli provides a function to change the character set : <code>mysqli_set_character_name()</code>. You should never use "SET NAMES" query, because the escaping strategies won't use it.
You can read more info about this at <a href="http://php.net/mysqlinfo.concepts.charset.php"></a><a href="http://php.net/mysqlinfo.concepts.charset.php">http://php.net/mysqlinfo.concepts.charset.php</a> or <a href="http://dev.mysql.com/doc/refman/5.7/en/charset-connection.html"></a><a href="http://dev.mysql.com/doc/refman/5.7/en/charset-connection.html">http://dev.mysql.com/doc/refman/5.7/en/charset-connection.html</a></p>
<p>Now, let's talk about buffered queries, which is a very obscur part.
When you query MySQL for results, so usually when you use SELECT queries, a resultset will be created and results will be in. Buffered resultsets is the concept about where to store the resultset ? Should it be stored into the client memory (buffered query), or stay on the MySQL side (unbuffered query) ? That's all.</p>
<p>Please, note that we are talking about direct queries and not prepared statements, which are not the same at all. We'll give a word about prepared statements later on.</p>
<p>By default, every direct query issued from mysqli to MySQL is buffered, this means that at the time you issue a <code>mysqli_query()</code> call, all the resultset is transmitted over the wire, back to PHP memory, and freed from the MySQL side. As the resultset resides on the PHP part, you can count it : <code>mysqli_num_rows()</code>, you can seek into it at any place : <code>mysqli_data_seek()</code> and you can issue another query() while the resultset is not freed yet. Let's show an example :</p>
<pre><code>$mysqli = mysqli_connect(/*...*/);

/* By default, the resultset will be buffered into the client : PHP */
$result = mysqli_query($mysqli, "SELECT id, nom, email FROM members");
$line1 = mysqli_fetch_row($result);
mysqli_data_seek($result, mysqli_num_rows($result)); /* Let's jump to the last result */
$last_result = mysqli_fetch_row($result); /* Let's fetch that last result */

/* Should we not need this resultset anymore, let's free it, which will free memory :*/
mysqli_free_result($result);</code></pre>
<p>This is classical and default case. Remember that the whole resultset is immediately transmitted by MySQL to PHP, so if you expect it to be big, like if you selected very large blob columns or a lot of results, PHP's memory footprint will increase proportionally. However, you will not be able to see this memory footprint using <code>memory_get_usage()</code> nor will it be accounted into <em>memory_limit</em> until you use mysqlnd as low level connector. We'll detail this later.</p>
<p>If you'd like to issue the same request using non buffered result set, you'll use the <em>MYSQLI_USE_RESULT</em> flag. But be carefull, if you use a non buffered resultset, this means that the resultset will be allocated on the MySQL side (into the MySQL process memory) for your connection, and MySQL can only store one resultset by connection, which means you won't be able to re-issue another direct query on this connection until you freed the resultset. Also, as the resultset is not stored on the PHP side, it is not possible you seek into it, nor you count how many results are in :</p>
<pre><code>$mysqli = mysqli_connect(/*...*/);

/* The resultset will be allocated on the MySQL side this time */
$result = mysqli_query($mysqli, "SELECT id, email FROM members", MYSQLI_USE_RESULT);

$line1 = mysqli_fetch_row($result); /* This may trigger the network to fetch a result from the resultset */

/* This leads to an error, you cant seek a resultset which is not "yours",
it is still located into MySQL memory */
mysqli_data_seek($result, mysqli_num_rows($result));

/* This leads to an error, you can't issue another unbuffered query if you did not
free the last resultset */
$result2 = mysqli_query($mysqli, "SELECT name FROM membres", MYSQLI_USE_RESULT);</code></pre>
<p><code>mysqli_free_result()</code> frees the resultset, should it be stored on the PHP side or MySQL side.
By default, any direct query is issued in buffered mode because the MySQL server has other things to do than allocating memory to store every of its clients' resultsets.</p>
<p>Now, let's talk about prepared statements.</p>
<p>Prepared statements are very different from traditionnal direct queries :</p>
<ul><li>Prepared statements don't use the same underlying protocol as direct queries. The protocol is called the binary protocol, it is very optimized and offers many things such as true data type bindings.</li>
<li>Prepared statements resultsets are not buffered by default. This is the opposite as direct queries resultsets.</li>
</ul><p>Let's start by dumping the protocol for a direct query :</p>
<pre><code>$m = mysqli_connect(/* params */);
$q = mysqli_query($m, 'SELECT * FROM Users LIMIT 1');
while($r = mysqli_fetch_row($q)) {
    /* do something */
}
mysqli_free_result($r);</code></pre>
<p><img src="../../../img/php-mysql-com/mysql-simple-dump.png" alt="mysql text protocol"></p>
<p>As you can see on the picture, this is a textual protocol, this means that the data that MySQL sends back to PHP is only text. You asked for an integer column in your query ? you'll be given some text. Ouch ! That first means that MySQL has some additionnal work to do to turn the data types from its columns into texts. And that also means that on the PHP side, you'll only be able to retrieve PHP strings, even if your asked columns store different types.</p>
<p>Here we go for the same query as prepared statement :</p>
<pre><code>$m = mysqli_connect(/* params */);
$ps = mysqli_prepare($m, 'SELECT * FROM Users LIMIT 1');
mysqli_stmt_execute($ps);
while(mysqli_stmt_fetch($ps)) {
    /*  */
}
mysqli_stmt_close($ps);</code></pre>
<p><img src="../../../img/php-mysql-com/mysql-ps-dump.png" alt="mysql binary protocol"></p>
<p>The protocol image shows that this time, there are more communications. Every bind (not done on our example) and every fetch will trigger MySQL to receive or transmit data on the wire.
However, we can't see that on the picture but the protocol used was binary, that means that every column type is respected and transmetted as-is : an integer will be sent as an integer, and not a string
anymore. Should you remember your type sizes, transmitting for example a TINYINT 200 will weigh one byte on the network whereas it would have used 4 bytes if turned to text. The binary protocol is then lighter from this point of view, but there are also more network interchange for signaling.</p>
<pre><code>$m = mysqli_connect(/* params */);
$ps = mysqli_prepare($m, 'SELECT id FROM Users LIMIT 10'); /* 'id 'column is of type INTEGER */
mysqli_stmt_execute($ps);
mysqli_stmt_bind_result($ps, $id); /* let's bind the result column on $id */
while(mysqli_stmt_fetch($ps)) {
    var_dump($id);
}
/*
int(62)
int(64)
*/</code></pre>
<p>The example above shows clearly that PHP recovers integers, not strings any more.</p>
<p>It is however possible to keep types using the text protocol. This will need the client (PHP) to transtype the received strings ito the right expected types, and as you'd have guessed, only mysqlnd can do that, libmysql will be no help :</p>
<pre><code>$m = mysqli_connect(/* */);
$q = mysqli_query($m, 'SELECT id FROM users LIMIT 10';

while($r = mysqli_fetch_row($q)) {
    var_dump($r[0]);
}
/*
string(2) "62"
string(2) "64"
*/

$m = mysqli_connect(/* */);
mysqli_options($m, MYSQLI_OPT_INT_AND_FLOAT_NATIVE, true); /* This is only available using mysqlnd */
$q = mysqli_query($m, 'SELECT id FROM users LIMIT 10');

while($r = mysqli_fetch_row($q)) {
    var_dump($r[0]);
}
/*
int(62)
int(64)
*/</code></pre>
<p>If we talk about the resultset of a prepared statement, it is not buffered by default, every fetch() operation will trigger a network communication. You may however buffer those resultsets, using <code>mysqli_stmt_store_result()</code>.</p>
<pre><code>$m = mysqli_connect(/* */);
$ps = mysqli_prepare($m, 'SELECT id, name FROM Users LIMIT 1000');
mysqli_stmt_execute($ps);
mysqli_stmt_bind_result($ps, $id, $name);

/* Store every result into PHP in one call */
mysqli_stmt_store_result($ps);

while(mysqli_stmt_fetch($ps)) {
    /* do something with $id and $name */
}
mysqli_stmt_close($ps);</code></pre>
<p>We've seen we still can buffer the resultset if we want to, but with prepared statements it is necessary to bind every result column to a PHP variable to be able to read some useful data.
Once more, if you use mysqlnd, you'll have access to <code>mysqli_stmt_get_result()</code>, which will turn a prepared statement resultset into a mysqli_result, and you'll be back using a direct-query-like API, but with prepared statements :</p>
<pre><code>$m = mysqli_connect(/* params */);
$ps = mysqli_prepare($m, 'SELECT id, name FROM Users LIMIT 1000');
mysqli_stmt_execute($ps);

/* Turn the result set into a mysqli_result */
$r = mysqli_stmt_get_result($ps); /* Only available under mysqlnd */

while($result = mysqli_fetch_row($r)) { /* direct query API */
    /* do something */
}
mysqli_free_result($r);
mysqli_stmt_close($ps);</code></pre>
<h2 id="zoom-on-mysqlnd">Zoom on mysqlnd<a href="#zoom-on-mysqlnd" class="anchor">#</a></h2>
<p>We've seen so far that mysqlnd acts as a hidden extension which adds many features to the existing APIs, especially mysqli (this is true for PDO as well but lesser).
Let's now detail other parts of mysqlnd.</p>
<h3 id="memory-savings">Memory savings<a href="#memory-savings" class="anchor">#</a></h3>
<p>To understand this part, we need to recall some points :</p>
<ul><li>A buffered query fetches all the results from MySQL to PHP memory</li>
<li>The buffered result set is created by the library which is used to communicate, weither libmysql or mysqlnd</li>
<li>A resultset is not directly usable from PHP land, it has to be turned into a PHP structure such as an array, this operation is called a "fetch"</li>
</ul><p>Here we go.</p>
<p>Doing this is silly, and wastes a huge part of memory :</p>
<pre><code>$db  = mysqli_connect(/* */);
$result = mysqli_query($db, "SELECT very_huge_blob_column, lots, of, columns FROM foobar"); /* big query generating a huge heavy resultset */

while($results[] = mysqli_fetch_row($result)) { }
mysqli_free_result($result); /* This step is often forgotten, which is even worse! */
foreach($results as $foo) { /* do something */ }</code></pre>
<p>Let's prove what we say :</p>
<pre><code>function memory_usage()
{
    $pid = getmypid();
    $r = explode(':',shell_exec("grep VmData /proc/$pid/status"));
    return '->'.trim($r[1])."\n";
}
$db = mysqli_connect(/* */);

echo "initial memory " . memory_usage();
$result = mysqli_query($db,"SELECT very_huge_blob_column FROM foobar");
echo "resultSet stored " . memory_usage();
while($results[] = mysqli_fetch_row($result)) { }
echo "query result saved " . memory_usage();
mysqli_free_result($result);
echo "resultSet freed " . memory_usage();
unset($results);
echo "saved result freed " . memory_usage();
unset($db);
echo "Db closed " . memory_usage();</code></pre>
<p>With libmysql, here are the numbers :</p>
<pre><code>> phplibmysql/bin/php poc_mysqli.php
initial memory ->3348 kB
resultSet stored ->72724 kB
query result saved ->149012 kB
resultSet freed ->81156 kB
saved result freed ->25348 kB
Db closed ->24260 kB</code></pre>
<p>As you can see, as soon as the <code>mysqli_query()</code> is executed, all the resultset is transmitted into PHP's memory. On this example, the memory raises from 3Mb to 70Mb ! (this is a true, real life example).
This is normal behavior as by default, direct queries are in buffered mode. What is important to understand here is that the resultset memory buffer <strong>has been allocated by the communication library : libmysql</strong>. And when it comes to turn this resultset to something PHP can use, fetch it into an array, <strong>the entire data into the resultset will be duplicated in memory</strong>, resulting in an enormous waste.</p>
<p>As the resultset buffer is allocated by libmysql, it wont show into <code>memory_get_usage()</code>, but you'll need to monitor your process heap to see that (like its done in the example using <em>/proc</em>).</p>
<p>So transforming the whole data from a resultset into a PHP variable blows up the memory. At this stage, libmysql buffer is still allocated and the data is fully duplicated into buckets of a PHP array, thus we are consuming now about 140Mb. Let's convince ourselves about those allocation by running valgrind memory analyzer with massif :</p>
<pre><code>99.92% (257,473,815B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->52.90% (136,314,880B) 0x69A01E: _zend_mm_alloc_int (zend_alloc.c:1908)
| ->52.60% (135,528,448B) 0x69A1DE: _estrndup (zend_alloc.c:2503)
| | ->52.60% (135,528,448B) 0x533BCE: php_mysqli_fetch_into_hash (mysqli.c:1191)
| |   ->52.60% (135,528,448B) 0x53F2E1: zif_mysqli_fetch_row (mysqli_nonapi.c:352)
| |     ->52.60% (135,528,448B) 0x70186A: zend_do_fcall_common_helper_SPEC (zend_vm_execute.h:320)
| |       ->52.60% (135,528,448B) 0x6D9D96: execute (zend_vm_execute.h:107)
| |         ->52.60% (135,528,448B) 0x6B4B98: zend_execute_scripts (zend.c:1236)
| |           ->52.60% (135,528,448B) 0x663D0C: php_execute_script (main.c:2308)
| |             ->52.60% (135,528,448B) 0x73BCDC: main (php_cli.c:1184)
| |               
| ->00.31% (786,432B) in 1+ places, all below ms_print's threshold (01.00%)
| 
->45.85% (118,130,675B) 0x52DD010: my_malloc (my_malloc.c:37)
| ->45.84% (118,112,344B) 0x52E0583: alloc_root (my_alloc.c:219)
| | ->45.83% (118,096,024B) 0x5307A40: cli_read_rows (client.c:1418)
| | | ->45.83% (118,096,024B) 0x5305955: mysql_store_result (client.c:2957)
| | |   ->45.83% (118,096,024B) 0x53EF09: zif_mysqli_query (mysqli_nonapi.c:540)
| | |     ->45.83% (118,096,024B) 0x70186A: zend_do_fcall_common_helper_SPEC (zend_vm_execute.h:320)
| | |       ->45.83% (118,096,024B) 0x6D9D96: execute (zend_vm_execute.h:107)
| | |         ->45.83% (118,096,024B) 0x6B4B98: zend_execute_scripts (zend.c:1236)
| | |           ->45.83% (118,096,024B) 0x663D0C: php_execute_script (main.c:2308)
| | |             ->45.83% (118,096,024B) 0x73BCDC: main (php_cli.c:1184)</code></pre>
<p>my_malloc() is libmysql's allocator on top of malloc.</p>
<p>To free the resultset libmysql's keeping warm, you must call <code>mysqli_free_result()</code>. We can see that we fall back to about 70Mb after this call, and then, when we finally free the PHP array containing a copy of the resultset, we drop back to initial memory usage (on average, some cache systems may trigger, this is not leaked memory).</p>
<p>This duplication from libmysql's buffer to PHP memory can be prevented using mysqlnd. mysqlnd will benefit from the copy on write behavior of PHP zvals to save those copies. Let's show that :</p>
<pre><code>> phpmysqlnd/bin/php poc_mysqli.php
initial memory ->3208 kB
resultSet stored ->70452 kB
query result saved ->71220 kB
resultSet freed ->81148 kB
saved result freed ->19196 kB
Db closed ->19196 kB</code></pre>
<p>As you can see, when the buffered resultset is fetched into a PHP array, the memory does not move. Far from beeing multiplied by two hun ?
Only at the time you'll start writing into this array (should you write into it), thus modifying the fetched results, PHP will duplicate the result on a case by case basis, which is really cool for memory usage. If you stay with a read-only approach, then you'll save lots of memory.
Also, mysqlnd used the PHP memory allocator to store the resultset into its own buffer, the memory usage is shared with PHP, and <code>memory_get_usage()</code> will show this memory and you could also hit the <em>memory_limit</em> PHP setting.</p>
<p>Knowing that apps mainly SELECT data, then fetches them to usually display them (read only), it is a pure waste to still use libmysql as low level communication for such use cases.
And I don't talk about batch scripts, written in PHP, treating lots of data from MySQL, and from where people often complain about memory usage... It's not PHP's fault you know ;-)</p>
<p>Another approach would also be to prevent any "fetch all" operation. PDO's got such an API : <code>$stmt->fetchAll()</code>, which transforms all the resultset into a PHP variable. It is way better for memory usage to seek into the resultset and consume the actual data, then loop to the next one, than looping once and turning any row into a PHP array bucket. <em>PDOStatement</em> even implements <em>Traversable</em>, and is then usable using foreach, same for mysqli_result.</p>
<h3 id="statistics">Statistics<a href="#statistics" class="anchor">#</a></h3>
<p>As mysqlnd act between any PHP Mysql layer, and the MySQL server, it sees everything : every single byte exchanged between both parts is seen, and can be counted to collect very useful statistics.
Let's have a look at some of them :</p>
<p><img src="../../../img/php-mysql-com/mysqlnd-stats-phpinfo.png" alt="mysqlnd statistics"></p>
<p>Here are some useful questions mysqlnd can answer very easily without requiring monitoring plugins, which are always heavy to setup and live on server side :</p>
<ul><li>How many MySQL active connections do I have ?</li>
<li>How many MySQL connection errors PHP met so far ?</li>
<li>How many queries have been prepared, but not executed (which is a waste of performance) ?</li>
<li>How many queries have been prepared, but used only once (prepared statements are useful if you reuse them, if not, its often a waste of bandwidth)</li>
<li>How many queries have queried for columns but have not fetched them (waste of bandwidth and memory )?</li>
<li>How many MySQL slow queries happened so far ?</li>
<li>How many queries not using an index ?</li>
</ul><p>mysqlnd can answer all those questions. Let's see :</p>
<pre><code>$db = mysqli_connect(/* */);

$result = mysqli_query($db,"SELECT user_id, email FROM users LIMIT 5");
mysqli_data_seek($result, 5);
$data = mysqli_fetch_row($result);
do_something($data);
mysqli_free_result($result);
var_dump(mysqli_get_connection_stats($db)); /* only available under mysqlnd */

/*
["buffered_sets"]=>
  string(1) "1"
["rows_fetched_from_server_normal"]=>
  string(1) "5"
["rows_buffered_from_client_normal"]=>
  string(1) "5"
["rows_fetched_from_client_normal_buffered"]=>
  string(1) "1"
["connect_success"]=>
  string(1) "1"
["connect_failure"]=>
  string(1) "0"
["connection_reused"]=>
  string(1) "0"
["reconnect"]=>
  string(1) "0"
["active_connections"]=>
  string(1) "1"
*/</code></pre>
<p>The above code queries for 5 results, seeks into the resultset directly to the 5th, fetches it, uses it and frees all the resultset. Why so query for 5 results and only use one ?
We can see from the statistics array that <em>rows_fetched_from_server_normal</em> shows we queried 5 results and MySQL sent us 5 of them, they were all here, but <em>rows_fetched_from_client_normal_buffered</em> shows we only effectively fetched one result from the stored resultset. We then wasted bandwidth, MySQL CPU and PHP memory.</p>
<p>Let's extend MySQLi class to have a simple log about this waste :</p>
<pre><code>class JPMysqli extends Mysqli
{
    public function __destruct()
    {
        $stats = $this->get_connection_stats();
        $this->close();
        if($diff = $stats["rows_fetched_from_server_normal"] - ($stats["rows_fetched_from_client_normal_unbuffered"] + $stats["rows_fetched_from_client_normal_buffered"])) {
            trigger_error("You didn't use *$diff* selected results", E_USER_NOTICE);
        }
    }
}

$db = new JPMysqli(/* */);

$result = mysqli_query($db,"SELECT user_id, email FROM users LIMIT 5");
mysqli_data_seek($result, 5);
$data = mysqli_fetch_row($result);
do_something($data);
exit();
/*
Notice : "You didn't use *4* selected results"
*/</code></pre>
<p>Nice, knowing that this particular behavior is really common is userland. So many applications run queries selecting tons of result, but only effectively using part of them.</p>
<p>If you are using Symfony2 applications, you may use <a href="https://packagist.org/packages/js/mysqlnd-bundle"></a><a href="https://packagist.org/packages/js/mysqlnd-bundle">https://packagist.org/packages/js/mysqlnd-bundle</a> or <a href="https://packagist.org/packages/js/mysqlnd-analytics"></a><a href="https://packagist.org/packages/js/mysqlnd-analytics">https://packagist.org/packages/js/mysqlnd-analytics</a></p>
<h3 id="plugins">Plugins<a href="#plugins" class="anchor">#</a></h3>
<p>mysqlnd is a so nice extension... It is even extensible !
This means that it's been thought to be extensible without further changing its source code. mysqlnd is plugable, and one may activate other PHP extensions which are in fact plugins for mysqlnd which will add new features.
Plugins may be developed in C and some already exist :</p>
<p>mysqlnd_qc : Query cache. This plugin allow you to cache SQL query resultsets into different backend and reuse them later. Why the hell do people reinvent such a system in PHP land ?</p>
<p>mysqlnd_ms : Master Slave balancer which is able to select the right server depending on the query sent. This is totally transparent to userland. Why the hell do people reinvent such a system in PHP land ?</p>
<p>mysqlnd_uh : UserHandler Hooks : Write your own plugin using PHP (and not C). Branch on different hooks into the low level mysqlnd layer, and implement whatever you want : SQL injection protections, load balancers, loggers, etc...</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" class="anchor">#</a></h2>
<p>So, I hope you know have a better understanding on how PHP communicates with MySQL servers. I also hope you noticed how mysqlnd can help you implementing so many ideas, and how its licence allows you to do the same things you'd do using just PHP and the PHP licence.</p>
<p>Special thanks to Ulf Wendel, Andrey Hristov, Georg Richter and Johannes Schlter ; main mysqlnd creators.</p>]]></content>
    </entry>
        <entry>
        <title>PHP memory and Zend Memory Manager (PHP 5)</title>
                <id>http://jpauli.github.io//2014/07/02/php-memory.html</id>
                <updated>2014-07-02T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2014/07/02/php-memory.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>This blog post is gonna introduce you the dynamic memory management layer PHP relies on : Zend Memory Manager (ZendMM). We'll detail why we need such a layer, what it does, how to customize it, how to interact with it from PHP land.</p>
<h2 id="recall-on-c-memory-management">Recall on C memory management<a href="#recall-on-c-memory-management" class="anchor">#</a></h2>
<p>C has several allocation storage classes :</p>
<ul><li>automatic allocation ;</li>
<li>static allocation ;</li>
<li>dynamic allocation.</li>
</ul><p>Auto allocation is about function received arguments, or any variable declared into a function body. The compiler has all informations it needs to figure out how many bytes to allocate, and it will automatically free the memory by itself, when the container becomes out of scope. You cannot get your hands on such automatic feature, especially you can't reallocate this memory zone (because you'd need more memory that the compiler computed for you, or less).</p>
<p>Static allocation is about global or static variables. Like with automatic allocation, the compiler allocates memory depending on variable type, but this time it will never free it until the program ends. Here again, you cannot get into that process to customize it.</p>
<p>Finally dynamic allocation is where the programmer (you) will declare himself how much bytes of memory he needs. You can reallocate the memory, meaning you can enlarge it, or shrink it, whenever you want. This is necessary as many things in a program lifetime are not known at compile time, and evolve within the program lifetime. So you can do whatever you want with dynamic allocation, but there is a duty you have to accept : free the memory zone whenever you don't need it anymore, because absolutely noone will do it for you. If you forget, you create what's called a <em>memory leak</em>, that means you allocated some memory for your program, but you never released it back to the OS so that it may use it for any other program which may need it. That's bad.</p>
<p><img src="../../../img/php-memory/os-memory.png" alt="OS memory"></p>
<p>Here is an example :</p>
<pre><code>#include <stdio.h>
#include <stdlib.h>

/* Static allocation, global variable
   the compiler takes care of everything, but won't free
   this bloc of memory */
int myint;

char *myfunction(int i)
{
    /* Static allocation, static variable
   the compiler takes care of everything, but won't free
   this bloc of memory */
    static char *my_static = "Foo";

    if (myint == i) {
        my_static = "Bar";
    }
    return my_static;
}

int main(int argc, char *argv[])
{
    /* Automatic allocation, the compiler takes care of allocation
    and will free this memory bloc when the function will end */
    int *p_int;
    int i;

    myint = 18;

    /* Dynamic allocation. The programmer asks himself to allocate
       10*sizeof(int) bytes in memory, he will have to free it by himself */
    p_int = (int *)malloc(10 * sizeof(int));

    for (i=0; i<10; i++) {
        *(p_int + i) = i*myint;
        myfunction(*p_int);
    }

    /* Free of dynamic memory bloc. Forgetting this stage creates a real
      memory leak */
    free(p_int);

    return 0;
}</code></pre>
<blockquote>
<p>We stop here. Just note that depending on the allocation class, the memory area will differ.
An automatic allocation is done on the stack, a dymanic allocation on the heap and a static is done in the BSS or Data segment of your ELF binary.</p>
</blockquote>
<p>Dynamic allocation is really frequently used, as many data are not known at the time the program is run, thus no memory size can yet be figured out, and will only be at runtime. PHP uses lots of dynamic allocation, just by the dynamic nature of the language itself : it doesn't know when you compile it, what size your variables will be, for example.
Dynamic allocation is available through libc's <code>malloc()</code> and <code>free()</code> functions, themselves being wrappers over the OS Kernel user-land memory services, like <code>sbrk()</code> or <code>mmap()</code>.
As PHP is a long-living process, often a daemon (FastCGI, PHP-FPM or Apache's mod_php), any memory leak will hurt not only PHP but the whole system.
Because PHP is designed into hundreds of thousands of lines of C code, generating a leak in dynamic memory allocation is really really easy. There must be a solution to prevent leaks or help tracking them, and PHP's got a layer that is dedicated in
dynamic memory management and leak tracking : Zend Memory Manager (ZendMM).</p>
<h2 id="dynamic-memory-allocation-problems-regarding-php">Dynamic memory allocation problems regarding PHP<a href="#dynamic-memory-allocation-problems-regarding-php" class="anchor">#</a></h2>
<h3 id="os-differences">OS differences<a href="#os-differences" class="anchor">#</a></h3>
<p>Libc's is a wrapper over the Kernel services, and the Kernel is really different according to the OS. Windows and Linux for example, are really different. Unix flavours as well.</p>
<p><img src="../../../img/php-memory/zendMM.png" alt="ZendMM"></p>
<h3 id="heap-fragmentation">Heap fragmentation<a href="#heap-fragmentation" class="anchor">#</a></h3>
<p>To understand heap fragmentation, you should write your own memory manager in C. This is an exercize you usually have to deal with in your studies.
<code>malloc()</code> manages a heap that it cuts into blocs. When you free a bloc, you create a hole in the heap. As any bloc in the heap is managed into binary trees or linked lists, the more holes you
create, the more CPU cycles will be needed for the next <code>malloc()</code> call to succeed (best-fit algorithm). It also happens that a call to <code>free()</code> triggers a heap compacting algorithm, which is usually very CPU intensive as well.
Those are well known problems, and any "serious" software have dealed with them by creating a (usually very complex and big) layer over malloc/free duo, and the program asks for dynamic memory
using this specific layer.</p>
<blockquote>
<p>As an example, you may read the <a href="http://apr.apache.org/docs/apr/0.9/group__apr__pools.html">Apache server's dynamic memory library</a>. Big projects such as Firefox or MySQL have even more complex and exciting layers.</p>
</blockquote>
<p>Zend Memory Manager (ZendMM) is PHP's dynamic allocation layer. It's been designed to offer good performances for the PHP case, by managing an internal heap over the process heap. You know that PHP is share-nothing-architecture designed, that means that at the end of one web request, PHP will discard any memory allocation done during the request so that it cleans the room for the next request to come.
This is done using the Zend Memory Manager.</p>
<p>For more information about malloc/free internals, you may start your readings by <a href="http://phrack.org/issues/57/9.html">Once uppon a free()</a> or <a href="http://www.gnu.org/software/libc/manual/html_node/Unconstrained-Allocation.html">the Glibc manual</a></p>
<h3 id="managing-memory-leaks">Managing memory leaks<a href="#managing-memory-leaks" class="anchor">#</a></h3>
<p>Ah... memory leaks... a whole story every programmer knows about. Fortunately, there exists tools to track them, and they work pretty nicely. valgrind, mtrace, ccmalloc, electric fence...
Let's see how valgrind does the job :</p>
<pre><code>#include <stdlib.h>
#include <string.h>

#define MYSTRING "Hello, world ; I'm gonna leak some memory"

int main(int argc, char *argv[])
{
    char *p_char = (char *)malloc(sizeof(MYSTRING));
    char string[] = MYSTRING;
    memcpy(p_char, string, sizeof(string));
    return 0;
}

$ valgrind --tool=memcheck --leak-check=full ./leak
==9488== Memcheck, a memory error detector
==9488== Copyright (C) 2002-2010, and GNU GPL'd, by Julian Seward et al.
==9488== Using Valgrind-3.6.0.SVN-Debian and LibVEX; rerun with -h for copyright info
==9488== Command: ./leak
==9488== 
==9488== 
==9488== HEAP SUMMARY:
==9488==     in use at exit: 42 bytes in 1 blocks
==9488==   total heap usage: 1 allocs, 0 frees, 42 bytes allocated
==9488== 
==9488== 42 bytes in 1 blocks are definitely lost in loss record 1 of 1
==9488==    at 0x4C2815C: malloc (vg_replace_malloc.c:236)
==9488==    by 0x4005DB: main (leak.c:8)
==9488== 
==9488== LEAK SUMMARY:
==9488==    definitely lost: 42 bytes in 1 blocks
==9488==    indirectly lost: 0 bytes in 0 blocks
==9488==      possibly lost: 0 bytes in 0 blocks
==9488==    still reachable: 0 bytes in 0 blocks
==9488==         suppressed: 0 bytes in 0 blocks
==9488== 
==9488== For counts of detected and suppressed errors, rerun with: -v
==9488== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 4 from 4)</code></pre>
<p>Valgrind is a very powerful tool. It tracks leaks, but also invalid accesses which may be dangerous about program security (null pointer dereference, write out of alloc'ed bounds, memory leaks, overlaping zones, etc...).</p>
<p>Whatever tool you use, the tool helps you track the problem but won't make it disappear magically : this is your work.
As the program gets bigger, it becomes more and more difficult to track the leaks. A solution is to rely on a layer that embeds some checks about leaks or security. Zend Memory Manager does that for PHP, and trully helps a lot designing extensions or patching PHP itself.</p>
<p>Here is a quick example of ZendMM usage :</p>
<pre><code>PHP_FUNCTION(make_leak)
{
    void *leak = emalloc(200); /* emalloc is ZendMM's "malloc" */
    RETURN_NULL(); /* return, forgeting to free the previously allocated buffer */
}

$> php /tmp/leak_check.php

[Thu Apr  7 17:48:07 2011]  Script:  '/tmp/leak_check.php'
/usr/local/src/php/ext/leak/leak.c(172) :  Freeing 0x01DBB2E0 (200 bytes), script=/tmp/leak_check.php
=== Total 1 memory leaks detected ===</code></pre>
<p>You can easilly see the stderr output : it tells you're leaking some memory, and it tells you in which place in your code (in the example : leak.c line 172).
What you have to do is to use ZendMM specific alloc functions in place of the default libc's ones; ZendMM will then track any allocation you ask for, and checks that you effectively free them until the end of the current web request.
It will also implement guards (known as <em>canaries</em>) to inform you if you write past the allocated blocks, which is a very nice feature to count on as well because forgetting a +1 or -1 in an allocation is really frequent.</p>
<blockquote>
<p>Reminder : ZendMM only complains about leaks and overlaps if PHP's been built in debug mode (--enable-debug), so this is not the case for any "traditionnal" PHP build. Also, ZendMM only takes care of request-bound allocations; most of them are of this kind, but some allocations may need to "persist" through different requests. Those latter are not managed using ZendMM but traditionnal libc calls (mainly).</p>
</blockquote>
<h2 id="introduction-to-zend-memory-manager">Introduction to Zend Memory Manager<a href="#introduction-to-zend-memory-manager" class="anchor">#</a></h2>
<h3 id="goals">Goals<a href="#goals" class="anchor">#</a></h3>
<ul><li>Prevent heap fragmentation by reimplementing a custom heap onto the process' heap. Segmentation, pools and alignment features are in ;</li>
<li>Scream at your face about memory leaks or overlaps in the current web request ;</li>
<li>Automatically free leaked memory at request shutdown ;</li>
<li>Monitor and limit memory usage into all PHP (<em>memory_limit</em>) ;</li>
<li>Allow to choose the low level allocation stack (depends on OS) ;</li>
<li>Allow beeing disabled, so that any memory check tool like valgrind is not hindered by ZendMM.</li>
</ul><p>Zend Memory Manager appeared in PHP 4 and has been fully redesigned in PHP 5.2 and in PHP 7.0</p>
<h3 id="configuration">Configuration<a href="#configuration" class="anchor">#</a></h3>
<p>Zend Memory Manager (ZendMM) is enabled by default, and can be disabled (it will still be here, but skirted). It will however change its behavior depending on your compilation options.
A debug PHP build will have a ZendMM telling you about leaks on stderr, if <em>report_memleaks=1</em> in php.ini.</p>
<p><img src="../../../img/php-memory/zendMM-phpinfo.png" alt="ZendMM-phpinfo"></p>
<p>Then come four environment variables to set up ZendMM at runtime : <strong>USE_ZEND_ALLOC</strong>, <strong>ZEND_MM_MEM_TYPE</strong>, <strong>ZEND_MM_SEG_SIZE</strong> and <strong>ZEND_MM_COMPACT</strong>.
If <strong>USE_ZEND_ALLOC</strong> is set to 0, ZendMM is disabled and any call to its functions will be proxied to the OS's low level call, usually malloc/free. <code>phpinfo()</code> will then tell you Zend Memory Manager is disabled. We use this to short-circuit ZendMM and run PHP under valgrind, f.e.</p>
<p><strong>ZEND_MM_MEM_TYPE</strong> defines the low level implementation ZendMM should rely on. Default is "malloc", but you can choose between "mmap_anon" - "mmap_zero" - or "win32".</p>
<p><strong>ZEND_MM_SEG_SIZE</strong> defines the allocation step. Its like Kernel's PAGESIZE, the minimum allocation unit to use. Default is 256Kb which is a good value. More on that later.</p>
<pre><code>$ USE_ZEND_ALLOC=0 valgrind --tool=memcheck php /tmp/small.php 
==6861== Memcheck, a memory error detector
==6861== Copyright (C) 2002-2010, and GNU GPL'd, by Julian Seward et al.
==6861== Using Valgrind-3.6.0.SVN-Debian and LibVEX; rerun with -h for copyright info
==6861== Command: ./php /tmp/small.php
==6861== 

==6861== HEAP SUMMARY:
==6861==     in use at exit: 0 bytes in 0 blocks
==6861==   total heap usage: 9,697 allocs, 9,697 frees, 2,686,147 bytes allocated
==6861== 
==6861== All heap blocks were freed -- no leaks are possible
==6861== 
==6861== For counts of detected and suppressed errors, rerun with: -v
==6861== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 4 from 4)

$ valgrind --tool=memcheck ./php /tmp/small.php
==6866== Memcheck, a memory error detector
==6866== Copyright (C) 2002-2010, and GNU GPL'd, by Julian Seward et al.
==6866== Using Valgrind-3.6.0.SVN-Debian and LibVEX; rerun with -h for copyright info
==6866== Command: ./php /tmp/small.php
==6866== 

==6866== HEAP SUMMARY:
==6866==     in use at exit: 0 bytes in 0 blocks
==6866==   total heap usage: 7,854 allocs, 7,854 frees, 2,547,726 bytes allocated
==6866== 
==6866== All heap blocks were freed -- no leaks are possible
==6866== 
==6866== For counts of detected and suppressed errors, rerun with: -v
==6866== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 4 from 4)</code></pre>
<blockquote>
<p>Reminder : PHP memory consumption depends on the run script, and also on PHP extensions which can allocate many memory.
ZendMM only measures and manages request-bound memory allocations ; every "permanent" alloc done using directly malloc() is not accounted here.</p>
</blockquote>
<p>PHP memory consumption is weaker when ZendMM is enabled. Also, PHP is faster when ZendMM is enabled.
This is obvious as ZendMM has been designed to fit PHP's memory needs : it preallocates known-size blocs and manages internal lists about them more efficiently than malloc would do. It also prevents many <code>malloc()</code> calls, as the valgrind output shows (above).</p>
<pre><code>$> ZEND_MM_SEG_SIZE=8k php /tmp/my_script.php</code></pre>
<p>Here, ZendMM will ask the underneath layer for 8Kb allocs.</p>
<p><strong>ZEND_MM_MEM_TYPE</strong> lets you choose the underneath layer to use. Libc's <code>malloc()</code> is used by default.</p>
<p><strong>ZEND_MM_COMPACT</strong> tells ZendMM the size from which it must compact the internal heap. This feature is not enabled under Unix OSes.</p>
<h2 id="how-does-zendmm-work">How does ZendMM work ?<a href="#how-does-zendmm-work" class="anchor">#</a></h2>
<p>ZendMM is an allocator, so its operation is close to any memory allocator. Here are its structures :</p>
<ul><li><em>zend_mm_heap</em> : the heap ;</li>
<li><em>zend_mm_mem_handlers</em> : the bottom allocators available handlers (malloc, mmap_anon, win32...) ;</li>
<li><em>zend_mm_segment</em> : memory segments. Linked list ;</li>
<li><em>zend_mm_block</em> & <em>zend_mm_free_block</em> : memory blocs (usefull blocs), pluggued into segments.</li>
</ul><p>I wont detail too much ZendMM as it may become very complex if you are not comfortable with memory allocators, and such details are useless here.</p>
<h3 id="noticeable-structures">Noticeable structures<a href="#noticeable-structures" class="anchor">#</a></h3>
<p><em>zend_mm_mem_handlers</em> is the low-level allocator to be used by ZendMM, it is then full of function pointers. malloc-based allocator is defined into the <strong>ZEND_MM_MEM_MALLOC_DSC</strong> macro.</p>
<pre><code>typedef struct _zend_mm_mem_handlers {
    const char *name;
    zend_mm_storage* (*init)(void *params);
    void (*dtor)(zend_mm_storage *storage);
    void (*compact)(zend_mm_storage *storage);
    zend_mm_segment* (*_alloc)(zend_mm_storage *storage, size_t size);
    zend_mm_segment* (*_realloc)(zend_mm_storage *storage, zend_mm_segment *ptr, size_t size);
    void (*_free)(zend_mm_storage *storage, zend_mm_segment *ptr);
} zend_mm_mem_handlers;

struct _zend_mm_storage {
    const zend_mm_mem_handlers *handlers;
    void *data;
};

#define ZEND_MM_MEM_MALLOC_DSC {"malloc", zend_mm_mem_dummy_init, zend_mm_mem_dummy_dtor, zend_mm_mem_dummy_compact, zend_mm_mem_malloc_alloc, zend_mm_mem_malloc_realloc, zend_mm_mem_malloc_free}</code></pre>
<p><em>zend_mm_segment</em> is a memory segment (the base unit ZendMM will use when allocating from the OS). It's size may be changed using the <strong>ZEND_MM_SEG_SIZE</strong> env. The allocator will use this size to allocate a buffer, place a <em>zend_mm_segment</em> as head and return the leaving buffer which will be itself cut into blocs linked with each other.</p>
<pre><code>typedef struct _zend_mm_segment {
    size_t size;
    struct _zend_mm_segment *next_segment;
} zend_mm_segment;

typedef struct _zend_mm_free_block {
    zend_mm_block_info info;
#if ZEND_DEBUG
    unsigned int magic;
# ifdef ZTS
    THREAD_T thread_id;
# endif
#endif
    struct _zend_mm_free_block *prev_free_block;
    struct _zend_mm_free_block *next_free_block;

    struct _zend_mm_free_block **parent;
    struct _zend_mm_free_block *child[2];
} zend_mm_free_block;</code></pre>
<p><em>zend_mm_heap</em> is the shared heap. It's shared as a global variable into PHP, but you will usually never use it directly (except if you design extensions that plays with PHP memory in any way).</p>
<pre><code>struct _zend_mm_heap {
    int                 use_zend_alloc;
    void               *(*_malloc)(size_t);
    void                (*_free)(void*);
    void               *(*_realloc)(void*, size_t);
    size_t              free_bitmap;
    size_t              large_free_bitmap;
    size_t              block_size;
    size_t              compact_size;
    zend_mm_segment    *segments_list;
    zend_mm_storage    *storage;
    size_t              real_size;
    size_t              real_peak;
    size_t              limit;
    size_t              size;
    size_t              peak;
    size_t              reserve_size;
    void               *reserve;
    int                 overflow;
    int                 internal;
#if ZEND_MM_CACHE
    unsigned int        cached;
    zend_mm_free_block *cache[ZEND_MM_NUM_BUCKETS];
#endif
    zend_mm_free_block *free_buckets[ZEND_MM_NUM_BUCKETS*2];
    zend_mm_free_block *large_free_buckets[ZEND_MM_NUM_BUCKETS];
    zend_mm_free_block *rest_buckets[2];
#if ZEND_MM_CACHE_STAT
    struct {
        int count;
        int max_count;
        int hit;
        int miss;
    } cache_stat[ZEND_MM_NUM_BUCKETS+1];
#endif
};</code></pre>
<p>As you can see, compiling PHP with the debug flag enables many things into those low level structures.</p>
<h3 id="published-functions">Published functions<a href="#published-functions" class="anchor">#</a></h3>
<p>ZendMM API is mainly used when designing PHP internals (extensions or core development), for every request-bound allocation. For this goal, it publishes some functions the developer must use instead of traditionnal libc functions.
Those published functions are very intuitive and easy to use, let's have a look:</p>
<pre><code>void *emalloc(size_t size);
void *pemalloc(size_t size, char persistent)
void *ecalloc(size_t size);
void *pecmalloc(size_t size, char persistent)
void *erealloc(void *ptr, size_t size);
void *perealloc(void *ptr, size_t size, char persistent)
void *estrdup(void *ptr)
void *pestrdup(void *ptr, char persistent)  void *strdup(void *ptr)
void efree(void *ptr)
void pefree(void *ptr, char persistent) void free(void *ptr)</code></pre>
<p>As you can see, they share the same API as malloc/free/strdup etc... from libc. A quick word on "p" functions. "p" stands for "persitent", this means that the allocation will persist through requests.
In reality, those "persitent" functions directly proxy to the bottom layer (malloc/free), one should use them for every allocation that is not request bound, meaning that ZendMM won't warn you about possible leaks for them, simply because they can't really leak from request to request and will anyway be cleaned when PHP shuts down.</p>
<h3 id="from-php-land">From PHP land<a href="#from-php-land" class="anchor">#</a></h3>
<p>PHP allows you, as a PHP developer, to interact with it. Functions <code>memory_get_usage()</code> and <code>memory_get_peak_usage()</code> are published, as well as the ini setting <em>memory_limit</em>.
As most of dynamic allocation request from PHP go through the ZendMM layer, it is very easy for it to count the number of bytes asked so far, and bail out in case of reaching a limit : the <em>memory_limit</em>.</p>
<pre><code>zend_mm_safe_error(heap, "Allowed memory size of %ld bytes exhausted (tried to allocate %ld bytes)", heap->limit, size);</code></pre>
<p>To know PHP dynamic memory usage at a given moment, <code>memory_get_usage()</code> may be used. This function returns the size used into the allocated segments. This means that it is less than the real usage of PHP.
To know the real usage, aka the memory to fit the segments in it, pass 1 to the function : <code>memory_get_usage(1)</code>;</p>
<pre><code>ini_set('memory_limit', -1); // unlimited memory

function show_memory($real = false) {
    printf("%.2f Kb\n", memory_get_usage($real) / 1024);
}

show_memory();
show_memory(1);

$a = str_repeat('a', 1024*1024*10); // 10Mb

echo "\n";

show_memory();
show_memory(1);

$> php /tmp/mem.php
621.62Kb
768.00 Kb

10861.83 Kb
11264.00 Kb</code></pre>
<p><code>memory_get_peak_usage()</code> returns the peak ZendMM recorded in its life.</p>
<blockquote>
<p>Important : Nothing forces the C developers to use ZendMM. Anyone developing an extension (for example) could absolutely not use ZendMM and rely directly on malloc/free, thus allocating dynamic memory that will not be seen by ZendMM and <code>memory_get_usage()</code>, <em>memory_limit</em> etc... Here, you may use your OS to monitor this. Obviously, C developers know that and heavily rely on ZendMM, but still.</p>
<p><code>memory_get_usage()</code> give an average information, often accurate, but not 100% accurate on a byte-basis. Use your OS for that.</p>
</blockquote>
<h3 id="tuning">Tuning<a href="#tuning" class="anchor">#</a></h3>
<h4 id="zend-mm-seg-size-sizing-zendmm-heap-allocations">ZEND_MM_SEG_SIZE, sizing ZendMM heap allocations<a href="#zend-mm-seg-size-sizing-zendmm-heap-allocations" class="anchor">#</a></h4>
<p>To understand segments and why this is important, imagine a PHP with 256Kb segment size (default). If it has to consume say 320Kb, ZendMM will allocate onto its heap 2 segments, thus using from the OS 512Kb, filled at 320Kb. This is a cursor, and this is where ZendMM gives performances : it allocates more than what is really used, thus it allocates less often, it then prevents the process heap from fragmentation.</p>
<pre><code>// /tmp/mem.php is the code shown in the above example

$> ZEND_MM_SEG_SIZE=1048576 php /tmp/mem.php 
625.67 Kb
1024.00 Kb

10865.88 Kb
12288.00 Kb</code></pre>
<p>It is clear here. PHP consumes 625.67Kb, ZendMM allocated 1Mb segments, so one segment to fit the usage. The real usage is then 1Mb, and the usage is only 625.67Kb.
We then create a 10Mb string, so the memory consumption raises to 10865.88Kb and the real reaches 12288Kb : 12 segments of 1Mb each (1024Kb).</p>
<blockquote>
<p>ZEND_MM_SEG_SIZE must obviously be power-of-two aligned</p>
</blockquote>
<pre><code>ini_set('memory_limit', -1); // unlimited memory

function get_mem_stats() {
    printf("Memory usage %.2f Kb\n", memory_get_usage() / 1024);
    if ($segSize = getenv('ZEND_MM_SEG_SIZE') {
        printf("Heap segmentation : %d segments of %d bytes (%d Kb used)\n", memory_get_usage(1)/$segSize, $segSize, memory_get_usage(1)/1024);
    }
}

get_mem_stats();

$a = str_repeat('a', 1024*1024*10); // 10 Mb

echo "\n";

get_mem_stats();

$> ZEND_MM_SEG_SIZE=2048 php /tmp/mem.php
Memory usage 630.97 Ko
Heap segmentation : 325 segments of 2048 bytes (650 Kb used)

Memory usage 10871.18 Ko
Heap segmentation : 5446 segments of 2048 bytes (10892 Kb used)</code></pre>
<p>We can then say that the more tiny the segments are, the more the heap close to real memory usage (economical) but the more often it has to create segments.
This is why, by default, the segment size is 256Kb. With such a value, ZendMM will have to allocate few segments to fit the needs, which are usually around 5Mb. Sure, a framework based app (much more greedy in memory) may benefit from a tunning of the allocator. Look at that :</p>
<pre><code>get_mem_stats();

/* This is the date component from ZF1. This class is known beeing huge
    https://github.com/zendframework/zf1/blob/master/library/Zend/Date.php */
require 'Zend/Date.php';

echo "\n";
get_mem_stats();

$> ZEND_MM_SEG_SIZE=2048 php /tmp/mem.php 
Memory usage 630.35 Ko
Heap segmentation : 325 segments of 2048 bytes (650 Kb used)

Memory usage 4994.70 Ko
Heap segmentation : 2687 segments of 2048 bytes (5374 Kb used)</code></pre>
<p>Yeah, we raise from 630Kb to about 5Mb just by making PHP parse the <code>Zend/Date.php</code>, which contains a huge class. We even did not make any use of this class, just parsed it.
Remember that in PHP objects are really tiny and very well designed to be thrifty, but all the weight is passed back to the class. In PHP, a class is something consuming memory, a fortiori a big class. You may read more about classes, objects and memory, <a href="http://jpauli.github.io/2015/03/24/zoom-on-php-objects.html">in the dedicated article</a>.</p>
<p>To well tune segment size, you must know the average PHP memory consumption of your app, so that with well sized segments, the allocator won't create and free too many segments too often.
A bad thing for performance is having an application oscillate around a segment, forcing the ZendMM to call the underlying allocator.</p>
<p><img src="../../../img/php-memory/mm.png" alt="memory_get_usage"><img src="../../../img/php-memory/mm2.png" alt="memory_get_usage"></p>
<h4 id="zend-mm-mem-type-choosing-the-underlying-allocator">ZEND_MM_MEM_TYPE : choosing the underlying allocator<a href="#zend-mm-mem-type-choosing-the-underlying-allocator" class="anchor">#</a></h4>
<p>As we've seen so far, the underlying allocator ZendMM will rely on is configurable. By default, it is set to 'malloc' ('win32' under Windows).</p>
<pre><code>#define ZEND_MM_MEM_WIN32_DSC {"win32", zend_mm_mem_win32_init, zend_mm_mem_win32_dtor, zend_mm_mem_win32_compact, zend_mm_mem_win32_alloc, zend_mm_mem_win32_realloc, zend_mm_mem_win32_free}

#define ZEND_MM_MEM_MALLOC_DSC {"malloc", zend_mm_mem_dummy_init, zend_mm_mem_dummy_dtor, zend_mm_mem_dummy_compact, zend_mm_mem_malloc_alloc, zend_mm_mem_malloc_realloc, zend_mm_mem_malloc_free}</code></pre>
<p>You can choose also <em>mmap_anon</em> or <em>mmap_zero</em>. <em>mmap_anon</em> will create a new anonymous memory mapping in your process mapping table :</p>
<pre><code>zend_mm_segment *ret = (zend_mm_segment*)mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);</code></pre>
<p><em>mmap_zero</em> is the same, but using <em>/dev/zero</em> descriptor (usually BSD based Unixes) :</p>
<pre><code>zend_mm_dev_zero_fd = open("/dev/zero", O_RDWR, S_IRUSR | S_IWUSR);
zend_mm_segment *ret = (zend_mm_segment*)mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE, zend_mm_dev_zero_fd, 0);</code></pre>
<p>Using <em>mmap_anon</em> or <em>mmap_zero</em> is better if you don't want to suffer from your libc's malloc overhead :</p>
<pre><code>ini_set('memory_limit', -1);

function heap() {
return shell_exec(sprintf('grep "VmData:" /proc/%s/status', getmypid()));
}

printf ("Original heap status: %s\n", heap());

$a = range(1, 1024*1024); /* A very big array */

printf("I'm now eating heap memory: %s\n", heap());
unset($a); /* Free the memory */
printf("Memory should now have been freed: %s\n", heap());</code></pre>
<p>This code gets information about the process heap usage using the VmData field provided by the Linux Kernel. Here is the output with malloc :</p>
<pre><code>> php leak.php

Original heap status: VmData:         4504 kB
I'm now eating heap memory: VmData:    152232 kB
Memory should now have been freed: VmData:    143780 kB</code></pre>
<p>mmm, seems like there is something strange. Seems like memory is heavily leaking because it does not reach back its original value when I destroy the very big array that did ask for mush memory from the heap. What's happening ?</p>
<p>Let's launch this script again, but now choosing <em>mmap_anon</em> as underlying allocator for ZendMM :</p>
<pre><code>>ZEND_MM_MEM_TYPE=mmap_anon php leak.php 

Original heap status: VmData:         4404 kB
I'm now eating heap memory: VmData:   152116 kB
Memory should now have been freed: VmData:      4916 kB</code></pre>
<p>Aha, seems much better. In this particular case, we've been hit by malloc implementation details. When we freed the memory, ZendMM did call <code>free()</code>, but <code>free()</code> itself did not free the memory back to the OS, but prefered keeping the blocks in a heat area to serve them back later. This is good if you don't use an overlay, like ZendMM. But using ZendMM, which itself implements a heat zone an reusage of pointers, it is silly to suffer from libc's malloc implementation details (which may vary a lot depending on how <code>malloc()</code> has been compiled on your system, you should read your system manual to know about this).</p>
<p>So using <em>mmap_anon</em>, if you know what this is, ZendMM will call <code>munmap()</code>, which is a Kernel service (system call) which will mark the physical pages as freed, thus unpaging them from your process memory image : your memory consumption will then drop.</p>
<blockquote>
<p>It is better to not use "malloc" as underlying allocator. If you use "malloc", you'll end having two heap managers (ZendMM and malloc) on top of each other, and you'll then suffer from the bottom (malloc) management operations, such as compaction algorithm firing, or blocks not freed when requested.</p>
</blockquote>
<h2 id="a-quick-word-on-the-garbage-collector">A quick word on the Garbage Collector<a href="#a-quick-word-on-the-garbage-collector" class="anchor">#</a></h2>
<p>Let me clarify. Zend Memory Manager has nothing to share with ZendGC. ZendGC, appeared in PHP 5.3, is about clearing circular references in PHP variables and that's absolutely all it does. It then acts far on top of ZendMM, for PHP variables containing themselves (circular references). PHP has always freed back the request-bound memory when it has not used it anymore (request finished), and this is ZendMM role</p>
<p><img src="../../../img/php-memory/zendgc.png" alt="ZendGC"></p>
<h2 id="deeper-example">Deeper example<a href="#deeper-example" class="anchor">#</a></h2>
<p>We're gonna trace every dynamic memory allocation from a PHP process, just to have an idea of how PHP uses the heap memory. We're gonna use Valgrind-Massif for that.</p>
<p>Here is the very simple script we'll benchmark :</p>
<pre><code>echo "hello world";</code></pre>
<p>With such a script, there is no chance we use lots of memory from PHP land, as echoing a tiny string is something trivial for memory usage</p>
<pre><code>> valgrind --tool=massif --massif-out-file=massif.out --max-snapshots=1000 --stacks=yes php /tmp/void.php && ms_print massif.out > massif.txt

    MB
4.189^                                                                  #     
     |                                                                 @#@    
     |                                                               ::@#@:   
     |                                                              :::@#@@   
     |                                                             @:::@#@@@  
     |                                                            :@:::@#@@@  
     |                                                           @:@:::@#@@@  
     |                                                          @@:@:::@#@@@: 
     |                                                        ::@@:@:::@#@@@@ 
     |                                            @@@@@@:@@@@@@:@@:@:::@#@@@@ 
     |                                          @:@@@@@@:@@@@@@:@@:@:::@#@@@@ 
     |                                         @@:@@@@@@:@@@@@@:@@:@:::@#@@@@ 
     |                                        @@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                        @@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                   @:::@@@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                   @:::@@@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                   @:::@@@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                   @:::@@@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                   @:::@@@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
     |                                   @:::@@@@:@@@@@@:@@@@@@:@@:@:::@#@@@@:
   0 +----------------------------------------------------------------------->Mi
     0                                                                   27.69

Number of snapshots: 589
 Detailed snapshots: [14, 19, 24, 27, 40, 44, 52, 59, 71, 77, 81, 82, 95, 113, 117, 154, 170, 172, 188, 192, 218, 221, 264, 268, 270, 299, 307, 317, 323, 324, 325, 338, 343, 351, 361, 364, 375, 390, 396, 400, 403, 406, 414, 423, 438, 442, 443, 446, 458, 461, 462, 492, 498 (peak), 508, 518, 528, 538, 548, 558, 568, 578, 588]</code></pre>
<p>The max memory usage is (about) 4Mb, and 588 snapshots have been taken. Be warned that this represents the memory usage of my PHP, on my platform etc...
If you have another OS or architecture, the numbers will vary. Also, if you activate more or less PHP extensions, those numbers will vary as well.</p>
<pre><code>--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
265     14,029,321              640               37            19          584
266     14,097,959              848               37            19          792
267     14,152,209           10,064            3,841           751        5,472
268     14,194,235        1,336,904        1,328,911         1,913        6,080
99.40% (1,328,911B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->78.43% (1,048,576B) 0x83F90B: zend_interned_strings_init (zend_string.c:48)
| ->78.43% (1,048,576B) 0x81E0AC: zend_startup (zend.c:744)
|   ->78.43% (1,048,576B) 0x7BDA18: php_module_startup (main.c:2055)
|     ->78.43% (1,048,576B) 0x8CFA9B: php_cli_startup (php_cli.c:417)
|       ->78.43% (1,048,576B) 0x445AA6: main (php_cli.c:1358)
|         
->19.61% (262,144B) 0x7F75FB: _zend_mm_alloc_int (zend_alloc.c:1982)
| ->19.61% (262,144B) 0x7F8750: zend_mm_startup_ex (zend_alloc.c:1126)
|   ->19.61% (262,144B) 0x7F8888: zend_mm_startup (zend_alloc.c:1221)
|     ->19.61% (262,144B) 0x7F9306: start_memory_manager (zend_alloc.c:2733)
|       ->19.61% (262,144B) 0x81DD8A: zend_startup (zend.c:649)
|         ->19.61% (262,144B) 0x7BDA18: php_module_startup (main.c:2055)
|           ->19.61% (262,144B) 0x8CFA9B: php_cli_startup (php_cli.c:417)
|             ->19.61% (262,144B) 0x445AA6: main (php_cli.c:1358)
|               
->01.36% (18,191B) in 20 places, all below massif's threshold (01.00%)</code></pre>
<p>At timeslot 268, we can notice that 1.3Mb have been allocated, of which <code>zend_interned_string_init()</code> uses 1Mb, and <code>_zend_mm_alloc_int()</code> uses 256Kb.
<code>zend_interned_string_init()</code> is the interned string buffer used for string interning. By default, it is 1Mb size and can only be changed
at PHP compilation. If you are interested in the way PHP manages strings internally, <a href="http://jpauli.github.io/2015/09/18/php-string-management.html">there is a dedicated article about that</a>.</p>
<p><code>_zend_mm_alloc_int()</code> allocated 256Kb, yes, this is our underlying allocator call, to allocate one segment of memory, the very first one (default is 256Kb), PHP is actually starting and we are very soon in that process at timeslot 268.
Let's keep going :</p>
<pre><code>--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
300     15,909,135        1,406,104        1,377,534        12,882       15,688
301     15,963,752        1,407,088        1,378,252        13,196       15,640
302     16,018,604        1,407,112        1,378,248        13,176       15,688
303     16,089,865        1,408,296        1,379,153        13,503       15,640
304     16,144,629        1,407,288        1,386,986        14,806        5,496
305     16,183,971        1,743,384        1,720,538        16,886        5,960
306     16,248,952        1,771,944        1,746,686        19,298        5,960
307     16,288,999        1,790,200        1,763,176        20,960        6,064
98.49% (1,763,176B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->58.57% (1,048,576B) 0x83F90B: zend_interned_strings_init (zend_string.c:48)
| ->58.57% (1,048,576B) 0x81E0AC: zend_startup (zend.c:744)
|   ->58.57% (1,048,576B) 0x7BDA18: php_module_startup (main.c:2055)
|     ->58.57% (1,048,576B) 0x8CFA9B: php_cli_startup (php_cli.c:417)
|       ->58.57% (1,048,576B) 0x445AA6: main (php_cli.c:1358)
|         
->17.88% (320,000B) 0x83D6F5: gc_init (zend_gc.c:124)
| ->17.88% (320,000B) 0x81DA5F: OnUpdateGCEnabled (zend.c:81)
|   ->17.88% (320,000B) 0x833883: zend_register_ini_entries (zend_ini.c:208)
|     ->17.88% (320,000B) 0x7BDFC7: php_module_startup (main.c:2191)
|       ->17.88% (320,000B) 0x8CFA9B: php_cli_startup (php_cli.c:417)
|         ->17.88% (320,000B) 0x445AA6: main (php_cli.c:1358)
|           
->14.64% (262,144B) 0x7F75FB: _zend_mm_alloc_int (zend_alloc.c:1982)
| ->14.64% (262,144B) 0x7F8750: zend_mm_startup_ex (zend_alloc.c:1126)
|   ->14.64% (262,144B) 0x7F8888: zend_mm_startup (zend_alloc.c:1221)
|     ->14.64% (262,144B) 0x7F9306: start_memory_manager (zend_alloc.c:2733)
|       ->14.64% (262,144B) 0x81DD8A: zend_startup (zend.c:649)
|         ->14.64% (262,144B) 0x7BDA18: php_module_startup (main.c:2055)
|           ->14.64% (262,144B) 0x8CFA9B: php_cli_startup (php_cli.c:417)
|             ->14.64% (262,144B) 0x445AA6: main (php_cli.c:1358)
|               
->03.43% (61,493B) in 42 places, all below massif's threshold (01.00%)
| 
->02.72% (48,640B) 0x82B9B2: _zend_hash_quick_add_or_update (zend_alloc.h:95)
| ->02.52% (45,136B) 0x824F74: zend_register_functions (zend_API.c:2139)
| | ->02.52% (45,136B) 0x8257C6: zend_register_module_ex (zend_API.c:1946)
| |   ->01.79% (31,992B) 0x7BD8B3: php_register_extensions (main.c:1924)
| |   | ->01.79% (31,992B) 0x7BE020: php_module_startup (main.c:2213)
| |   |   ->01.79% (31,992B) 0x8CFA9B: php_cli_startup (php_cli.c:417)
| |   |     ->01.79% (31,992B) 0x445AA6: main (php_cli.c:1358)
| |   |       
| |   ->00.73% (13,144B) in 1+ places, all below ms_print's threshold (01.00%)
| |   
| ->00.20% (3,504B) in 1+ places, all below ms_print's threshold (01.00%)</code></pre>
<p>Interesting. At timeslot 307, the snapshot starts showing the famous garbage collector impact. The circular garbage collector, to be able to run and do its job, needs not less than 320Kb of memory, which is not trivial.  <code>php_module_startup()</code> is the call to start every PHP extensions, which will start registering some classes, some functions etc... 48Kb so far</p>
<p>Etc... We could detail all the snapshot if you wish to have a full night reading this article ;-)</p>
<h2 id="end">End<a href="#end" class="anchor">#</a></h2>
<p>Zend Memory Manager (ZendMM) is a layer sitting on top of every PHP request-related heap allocation. It has been designed to improve PHP performances, as PHP started becoming more and more complex and heap dependent. As you know now, you must compile a debug build of PHP to activate all the interesting parts of ZendMM. ZendMM roles are multiple, but the main ones are to control and free memory blocks between each web request PHP has to treat, effectively implementing a heap manager over the default system one (malloc).</p>
<p>In any case, PHP is build with ZendMM, so you benefit from it, from its very complex lines of codes, without having noticing it yet. Am I wrong ? Memory allocation in a programm can easilly turn to nightmare when you want to take in consideration all the parts : leaks, performance, thread safety, etc...</p>
<p>You can read many articles about allocators (low level ones) on the web, starting by <a href="http://locklessinc.com/benchmarks_allocator.shtml">Benchmarks of the Lockless Memory Allocator</a> or <a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919">Scalable memory allocation using jemalloc</a>.</p>]]></content>
    </entry>
        <entry>
        <title>realpath_cache</title>
                <id>http://jpauli.github.io//2014/06/30/realpath-cache.html</id>
                <updated>2014-06-30T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2014/06/30/realpath-cache.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="introduction">Introduction<a href="#introduction" class="anchor">#</a></h2>
<p>Do you know those PHP functions, <code>realpath_cache_get()</code>, <code>realpath_cache_size()</code> ?
php.ini setting <em>realpath_cache</em> ?</p>
<p>Realpath cache is a really important concept to know about, especially when it comes to play with symbolic links, a situation
some meet when they deploy code.
This setting is about performance and IO reduction of your server. It has been introducted in PHP 5.1 , when frameworks started
to show in the PHP scene.</p>
<h3 id="a-recall-on-the-stat-system-call">A recall on the stat system call<a href="#a-recall-on-the-stat-system-call" class="anchor">#</a></h3>
<p>Ok, so, you know how your system works don't you ? Let me refresh your mind.
When one want to play with a <em>path</em>, the Kernel and the filesystem must know exactly what you talk about.
So, whenever you'll use a path to access a file (in the Unix meaning), you or your library or at least your Kernel will
have to resolve it.
Resolving a path is getting information about it : basically is it a file ? is it a directory or is it link ?</p>
<p>The way to do this is by asking the system about the file type, and, in case of a symbolic link, the final file target.
Whenever you use relative paths, such as <em>"../hey/./you/../foobar"</em>, you have to resolve them to full paths, and then resolve
those full paths to file entities (Unix sense of "file", so a true file of any type or a directory or a link).</p>
<p>Usually, for relative paths, you're gonna call the <a href="http://repo.or.cz/w/glibc.git/blob/edea402804bce917cfd7cd1af76212e6364c23db:/stdlib/canonicalize.c#l43">realpath() C function</a>. As you can see, <a href="http://repo.or.cz/w/glibc.git/blob/edea402804bce917cfd7cd1af76212e6364c23db:/stdlib/canonicalize.c#l161">it will lead to</a> a stat() system call.</p>
<p>Calling stat() is heavy, first because this is a system call, needing a Kernel trap and a context switch, and also because it most likely asks the disk about metadata.
The kernel source for stat() is at <a href="http://lxr.free-electrons.com/source/fs/stat.c#L190"></a><a href="http://lxr.free-electrons.com/source/fs/stat.c#L190">http://lxr.free-electrons.com/source/fs/stat.c#L190</a>. Not surprinsingly, it leads to a FileSystem call (inode->getattr()).
Usually, the kernel uses <a href="http://www.faqs.org/docs/linux_admin/buffer-cache.html">its buffer caches</a>, so the impact is really
tiny, but the buffer cache on a very busy server may not contain your information, thus an IO, which is something you'd prefer
preventing as much as possible.</p>
<h2 id="what-php-does">What PHP does ?<a href="#what-php-does" class="anchor">#</a></h2>
<p>In PHP projects, we use many files. Nowadays, we use tons of classes, meaning tons of files (assuming one class per file).
So, autoload or not, we'll have to include those files, we'll have to read them, we'll have to ask the Kernel for stat informations about them.
That's why whenever you access a file in PHP, PHP tries to resolve the paths, resolve the links, get file informations; all this using the <code>stat()</code> system call, and then caches the result from this call into what is called the <strong>realpath cache</strong>.
Many other softwares use a stat cache, read their source code and you'll notice that ;-)</p>
<p>PHP will cache the result of the call, but only about the realpath. Any other information (owner, access rights, times ...) won't be
cached in this cache, but in the last file access cache.</p>
<p>As usual, we find the solution by having a look at the source code.
Whenever you access a file in PHP, <a href="http://lxr.php.net/xref/PHP_5_5/main/fopen_wrappers.c#473">php_resolve_path()</a> is used.
This function quickly calls <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#1925">tsrm_reapath()</a> which itself
calls <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#1151">virtual_file_ex()</a> and finally, <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#750">tsrm_realpath_r()</a>.</p>
<p>That's where things get interested. Functions like <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#830">realpath_cache_find()</a> are called, to lookup in a table if the stat informations have already been asked and cached for this
specific path.</p>
<p>A <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.h#211">realpath_cache_bucket</a> structure is used, which encapsulates many things :</p>
<pre><code>typedef struct _realpath_cache_bucket {
    unsigned long                  key;
    char                          *path;
    int                            path_len;
    char                          *realpath;
    int                            realpath_len;
    int                            is_dir;
    time_t                         expires;
#ifdef PHP_WIN32
    unsigned char                  is_rvalid;
    unsigned char                  is_readable;
    unsigned char                  is_wvalid;
    unsigned char                  is_writable;
#endif
    struct _realpath_cache_bucket *next;
} realpath_cache_bucket;</code></pre>
<p>If the bucket is not found, <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.h#139">php_sys_lstat()</a> will be called, this function is a proxy to <code>lstat()</code>. Then finally, the bucket is <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#1139">saved into the realpath cache</a>.</p>
<h2 id="php-settings-and-customization">PHP Settings and customization<a href="#php-settings-and-customization" class="anchor">#</a></h2>
<p>So, in PHP, you have several things to know about realpath cache.
First, the INI settings :</p>
<ul><li><a href="http://www.php.net/manual/en/ini.core.php#ini.realpath-cache-size">realpath_cache_size</a></li>
<li><a href="http://www.php.net/manual/en/ini.core.php#ini.realpath-cache-ttl">realpath_cache_ttl</a></li>
</ul><p>The manual warns you, if you use files that are not modified often (production servers), you should increase the
TTL.
Also, the default size is ridiculously weak. 16K are gonna be filled in one web request, assuming a framework usage like Symfony2.
Monitor your <code>realpath_cache_get()</code> return, you'll see that you hit the default 16K limit very soon. You'd better increase this value to something like 512K or even a megabyte.
If your realpath cache is full, there is no space for other entries, and then PHP will start abusing the <code>stat()</code> call because of cache
misses, stressing your Kernel even more.
The size is hard to compute theoretically. As we can see from the source code <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#643">in here</a>, each entry consume sizeof(realpath_cache_bucket) + the total number of characters of the resolved path + 1.
To me (LP64), sizeof(realpath_cache_bucket) = 56 bytes.</p>
<p>There is another trick. PHP resolves <strong>every paths it meets</strong> and splits every path part, resolving it.
I explain : if you access the file "/home/julien/www/fooproject/app/web/entry.php", PHP is gonna split this path into as many single units
as can fit. PHP is gonna resolve "/home", creating an entry for it into the cache. Then "/home/julien", then "/home/julien/www", etc..
Why this ? Well, first this is used to check access at every level of directory. Secondly, because many PHP users tend to build their
pathnames using string concatenations, PHP may have a chance to have checked simple parts, it will then know if the user may access
it or not, by asking the realpath cache for details. A cache hit is very cheap.
The source code of <a href="http://lxr.php.net/xref/PHP_5_5/TSRM/tsrm_virtual_cwd.c#750">tsrm_realpath_r()</a> details the procedure. this is a recursive function which gets called for every subpath entry, by default.</p>
<p>As you can see from the preceding paragraph, better have a cache !</p>
<p>This also shows that priming the cache by hitting few URLs from your website before opening it to public just after a new deploy is important here as well. This will not only prime your OPcode cache, but also the realpath cache, and your Kernel's page cache as well.</p>
<p>How to clear this cache ? The function is hidden in PHP. <code>realpath_cache_clear()</code> ? No, it doesn't exist, too bad :-)
Welcome <code>clearstatcache(true)</code>.
The true parameter is very important, it is named <em>$clear_realpath_cache</em>, so yes, obviously this is what we want to do.</p>
<h2 id="an-example">An example<a href="#an-example" class="anchor">#</a></h2>
<p>So here is an example.</p>
<pre><code>$f = @file_get_contents('/tmp/bar.php');

echo "hello";

var_dump(realpath_cache_get());</code></pre>
<p>And here is the result :</p>
<pre><code>hello
array(5) {
  ["/home/julien.pauli/www/realpath_example.php"]=>
  array(4) {
    ["key"]=>
    float(1.7251638834424E+19)
    ["is_dir"]=>
    bool(false)
    ["realpath"]=>
    string(43) "/home/julien.pauli/www/realpath_example.php"
    ["expires"]=>
    int(1404137986)
  }
  ["/home"]=>
  array(4) {
    ["key"]=>
    int(4353355791257440477)
    ["is_dir"]=>
    bool(true)
    ["realpath"]=>
    string(5) "/home"
    ["expires"]=>
    int(1404137986)
  }
  ["/home/julien.pauli"]=>
  array(4) {
    ["key"]=>
    int(159282770203332178)
    ["is_dir"]=>
    bool(true)
    ["realpath"]=>
    string(18) "/home/julien.pauli"
    ["expires"]=>
    int(1404137986)
  }
  ["/tmp"]=>
  array(4) {
    ["key"]=>
    float(1.6709564980243E+19)
    ["is_dir"]=>
    bool(true)
    ["realpath"]=>
    string(4) "/tmp"
    ["expires"]=>
    int(1404137986)
  }
  ["/home/julien.pauli/www"]=>
  array(4) {
    ["key"]=>
    int(5178407966190555102)
    ["is_dir"]=>
    bool(true)
    ["realpath"]=>
    string(22) "/home/julien.pauli/www"
    ["expires"]=>
    int(1404137986)</code></pre>
<p>What we can see, is that the full path to my example PHP file has been resolved, parts by parts.
Then, as <em>/tmp/bar.php</em> doesn't exist on my disk, this entry is obviously missing from the cache. However, we can see that PHP
resolved <em>/tmp</em>, so it now knows that it can access to /tmp, and any further resolution behind <em>/tmp</em> will be cheaper than the first one. </p>
<p>In the array returned by <code>realpath_cache_get()</code>, you can see important information, such as the expires timestamp.
This has been computed related to the <em>realpath_cache_ttl</em> setting, and the time the file has been accessed.
The key field is a hash of the resolved path, a variant of <a href="http://www.isthe.com/chongo/tech/comp/fnv/index.html">FNV hash</a> is used, this
is an internal information you shouldn't really need though (which may be integer or float, depending on your integer max size).</p>
<p>Now, if you'd call <code>clearstatcache(true)</code>, you'd reset this array and force PHP to <code>stat()</code> any new file access that was previously cached.</p>
<h2 id="the-opcode-caches-case">The OPcode caches case<a href="#the-opcode-caches-case" class="anchor">#</a></h2>
<p>Ready for another trick ?</p>
<p><strong>The realpath cache is process bound, and not shared into shared memory</strong></p>
<p>This means that anytime a cache entry expires, changes, or you empty the cache manually, you have to do this <strong>for every process in your pool</strong>.
This is usually why people fail at deploying code using OPCode caches solutions.
What people usually do when deploying, is changing a symlink from say /www/deploy-a to /www/deploy-b. What they usually forget is that opcode cache solutions (at least OPCache and APC) rely on the internal realpath cache from PHP.
So those opcode cache solutions won't notice the link change, and worse, they're gonna start noticing it little by little, as the realpath cache of every entry slowly expires. You know the result.</p>
<p>What I find beeing the best solution for deployment to prevent this uncool mechanism to happen, is to prepare a totally new PHP worker pool, and load balance your FastCgi Handler onto it, giving up with the old one when all old workers have finished.</p>
<p>This solution has many advantages : deploy A runs on memory pool A, and deploy B runs on memory pool B. End of story. We use memory image isolation to be absolutely sure that nothing will be shared between two deploys. Realpath cache, OPCode cache, etc... Everything is new.
FastCGI pools load balancing is possible at least with Lighttpd and Nginx :-)
I experienced this solution on production, and it is rock solid !</p>
<h1 id="end">End<a href="#end" class="anchor">#</a></h1>
<p>I've been asked to write some lines about realpath cache, probably because people had bad experience about it (I think at code deployment). Well, now you know how it works, why it's here and how and why to customize it. Did I forget anything ?</p>]]></content>
    </entry>
        <entry>
        <title>Reference mismatch in PHP function calls</title>
                <id>http://jpauli.github.io//2014/06/27/references-mismatch.html</id>
                <updated>2014-06-27T00:00:00+00:00</updated>
        <author>
            <name>Julien Pauli</name>
            <email>jpauli@php.net</email>
        </author>
        <link rel="alternate" type="text/html" href="http://jpauli.github.io//2014/06/27/references-mismatch.html"/>
        <content type="html" xml:lang="en"><![CDATA[<h2 id="a-recall-on-references">A recall on references<a href="#a-recall-on-references" class="anchor">#</a></h2>
<p>Once again, a coworker just pinged me about a huge memory usage in a Symfony2 based project.
What is bad about Symfony2 ecosystem, is that people tend to use everyone else's code, because it
seems to fit the <strong>usage</strong> need. This is not bad as-is, but wait, what about the performance of the piece of code you're gonna
heavily use ? Nowadays we want fast things, treating much more data than 10 years ago. I think it's time for programmers
who ignore performance to start learning about it.</p>
<p>Tons of PHP programmers are very nice technical guys
at creating functionnal code, and what they call "nice code", you know, with tons of objects and interfaces everywhere...
Fine, right ! But when it comes to write critical parts of code, where performance
trully matter, here suddenly, noone stays on the scene.
This is simply because unfortunately, many people just ignore how PHP works, let me refresh your mind ;-)</p>
<p>So, usually the main problem comes about memory usage. When I hear "my code is eating a gigabyte of
memory" , I just wonder if it has been designed to solve a problem as huge as its memory impact, or what ?
Seriously...</p>
<p>Memory usage, in PHP code, is not really hard to understand. PHP uses a reference counting mechanism
to track variable usages, just like any other language, or even the Kernel itself to manage lists of ... many things.
Reference counting is a really really common basic computer programming trick to save memory.</p>
<p>PHP is very well designed (I'm serious). It tries to do its best to save memory while running your code.
But should you know how reference counting works, you should know there are some situations you should avoid.</p>
<p>I'm gonna talk about reference mismatch in PHP function calls here.</p>
<h2 id="what-to-do-or-not-to-do">What to do or not to do ?<a href="#what-to-do-or-not-to-do" class="anchor">#</a></h2>
<p>What you should do is not use references (&) , until you really master what you do.</p>
<p>More seriously, you should absolutely avoid <strong>reference mismatch</strong> when calling functions.
This is absolutely awfull for PHP, as any mismatch will make it duplicate the variable's memory.
If the variable is big (a very long string, a very complex array), then you're gonna start feeling it.
Worse, you're gonna complain against PHP, which has nothing to do with that. The problem is you, and the
code you are using.</p>
<h2 id="what-is-a-reference-mismatch">What is a reference mismatch ?<a href="#what-is-a-reference-mismatch" class="anchor">#</a></h2>
<p>A reference mismatch is when you call a function whose argument is expected to be passed by reference, and
you pass it a non-reference, or the opposite case.</p>
<p>Here are few examples :</p>
<pre><code>function foo($arg) { }

$a = "some var";
$b = &$a; /* turn $a and $b into references */

foo($a); /* Reference mismatch */
foo($b); /* idem */</code></pre>
<p>!</p>
<pre><code>function foo(&$arg) { } /* this function accepts an arg by reference */

$a = "some var";
$b = $a; /* increment $a refcount so that the content is bound to two different variables */

foo($a); /* reference mismatch */
foo($b); /* idem */</code></pre>
<p>So those both examples are things you should avoid. PHP will duplicate the memory of the argument before
passing it to the function (this is true for every argument).</p>
<h2 id="what-about-the-objects">What about the objects ?<a href="#what-about-the-objects" class="anchor">#</a></h2>
<p>Objects are a special case. Let me be really clear : PHP never, ever, ever, duplicates an object in memory
until you explicitely tells it to do so. And you only have one way to tell it to do so : the <strong>clone</strong> keyword.</p>
<p>This is really easy to demonstrate :</p>
<pre><code>function wow($arg) { var_dump('in function wow : ', memory_get_usage()); }

$big = range(1, 1024*1024); /* This consumes lots of memory */
$big2 = &$big; /* $big and $big2 are both references to the same memory slot */

var_dump('original memory', memory_get_usage());
wow($big); /* $big is a reference, but the function accepts a non-reference : mismatch : duplicate memory */
var_dump('final memory', memory_get_usage());</code></pre>
<p>Result :</p>
<pre><code>string(15) "original memory"
int(151223288)
string(18) "in function wow : "
int(251886800)
string(12) "final memory"
int(151224488)</code></pre>
<p>Here, there is a classical reference mismatch on a non-object, so PHP will duplicate the passed argument,
which is a big array, so memory usage will raise significantely because PHP will duplicate (shallow copy) a very huge array
(and this burns many CPU cycles as well). Sure, if you don't use the variable elsewhere, when the function call
is finished, PHP destroys the function stack and cleans the dup memory. This, I repeat, if you don't use the argument
elsewhere. This is just a <a href="http://en.wikipedia.org/wiki/Reference_counting">refcount strategy</a></p>
<p>What about now using an object as passed arg ?</p>
<pre><code>function wow($arg) { var_dump('in function wow : ', memory_get_usage()); }

$big = range(1, 1024*1024); /* This consumes lots of memory */
$obj = new StdClass; /* Create a basic object */
$obj->big = $big; /* Turn this object into a BIG object by affecting one of its property to a huge var */
$obj2 = &$obj; /* Turn $obj into a reference, by linking it by reference to another variable */

var_dump('original memory', memory_get_usage());
wow($obj);
var_dump('final memory', memory_get_usage());</code></pre>
<p>Result:</p>
<pre><code>string(15) "original memory"
int(151223928)
string(18) "in function wow : "
int(151224040)
string(15) "final memory"
int(151223992)</code></pre>
<p>This is a confirmation : PHP doesn't duplicate objects, because objects are internally reference counted themselves.
Here, PHP just adds one more reference to the object, something that can't be done for other types.
So yes : usually, using objects in PHP tend to decrease global memory usage, because if you were using references at some
places, for objects, PHP won't duplicate memory container.</p>
<p>This can easilly be spoted into PHP source code. Have a look at <a href="http://lxr.php.net/xref/PHP_5_5/Zend/zend_variables.c#106">zval_copy_ctor()</a>
,the function called when PHP duplicate a variable. We can see that in the special case of an object,
PHP just increments a counter, whereas for any other types, it really duplicates memory of the variable, which usually is
not a bad thing as you don't use very big memory variables everytime, but cases happen where you'll carry a big array (with
lots of slots) or a huge string (a result of a file_get_contents() for example).</p>
<p>If you were curious about the duplication of arguments when a function is called, you should have a look at the
<a href="http://lxr.php.net/xref/PHP_5_5/Zend/zend_vm_def.h#3182">ZEND_SEND_VAR</a> and <a href="http://lxr.php.net/xref/PHP_5_5/Zend/zend_vm_def.h#3145">ZEND_SEND_REF</a> opcodes.
The <a href="http://jpauli.github.io/2015/01/22/on-php-function-calls.html">On PHP function calls</a> article may also be worth reading if you get interested in such concepts.</p>
<h2 id="other-use-cases">Other use cases<a href="#other-use-cases" class="anchor">#</a></h2>
<p>Any mismatch in function calls is bad. This is true also for internal functions, and some of them accept
parameters by references, like <code>array_shift()</code> for example.
When you use such functions, make sure to respect the references as well.</p>
<p>But there are other tricks, which I consider not tricks, but just normal and logical behaviors.
The case of <code>func_get_args()</code> is interesting :</p>
<pre><code>function foo()
{
    var_dump('Before func_get_args()', memory_get_usage());
    $args = func_get_args();
    var_dump('After func_get_args()', memory_get_usage());
}

/*
An example output with some big input variables could be :

string(22) "Before func_get_args()"
int(151222120)
string(21) "After func_get_args()"
int(251885904)
*/</code></pre>
<p>What you should know is that <code>func_get_args()</code> will duplicate all the passed variables to the function, ignoring references or not.
It has to do so, because PHP has no way to know if you're gonna modify the variables later-on.
You all agree that modifying a variable in $args here should not modify the passed arg right ?
Example:</p>
<pre><code>function foo()
{
    $args = func_get_args();
    $args[0] = 'foo';
}

$str = 'bar';
foo($str);

// here, $str still owns the string 'bar', and not 'foo'</code></pre>
<p>So PHP has to duplicate every variable passed on the function stack, when you call <code>func_get_args()</code>.</p>
<h2 id="end">End<a href="#end" class="anchor">#</a></h2>
<p>Well, as I said, usually you don't carry over huge variables in PHP scripts. This is a pretty uncommon use case, however,
as time pass and we ask PHP to build more and more complex systems, managing more and more data; knowing what happens
behind the scene becomes more and more valuable.
Scripting languages show advantages and drawbacks, and one should really master them all before choosing the right language.
For example, I will not make PHP the first choice when talking about designing a language grammar parser.</p>]]></content>
    </entry>
    </feed>
